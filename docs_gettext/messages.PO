# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2023, Harrison Chase
# This file is distributed under the same license as the ðŸ¦œðŸ”— LangChain package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: ðŸ¦œðŸ”— LangChain 0.0.150\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2023-04-27 12:46+0000\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#: ../docs/deployments.md:1
msgid "Deployments"
msgstr ""

#: ../docs/deployments.md:3
msgid ""
"So you've made a really cool chain - now what? How do you deploy it and make "
"it easily sharable with the world?"
msgstr ""

#: ../docs/deployments.md:5
msgid ""
"This section covers several options for that. Note that these are meant as "
"quick deployment options for prototypes and demos, and not for production "
"systems. If you are looking for help with deployment of a production system, "
"please contact us directly."
msgstr ""

#: ../docs/deployments.md:9
msgid ""
"What follows is a list of template GitHub repositories aimed that are "
"intended to be very easy to fork and modify to use your chain. This is far "
"from an exhaustive list of options, and we are EXTREMELY open to "
"contributions here."
msgstr ""

#: ../docs/deployments.md:13
msgid "[Streamlit](https://github.com/hwchase17/langchain-streamlit-template)"
msgstr ""

#: ../docs/deployments.md:15
msgid ""
"This repo serves as a template for how to deploy a LangChain with Streamlit. "
"It implements a chatbot interface. It also contains instructions for how to "
"deploy this app on the Streamlit platform."
msgstr ""

#: ../docs/deployments.md:19
msgid ""
"[Gradio (on Hugging Face)](https://github.com/hwchase17/langchain-gradio-"
"template)"
msgstr ""

#: ../docs/deployments.md:21
msgid ""
"This repo serves as a template for how deploy a LangChain with Gradio. It "
"implements a chatbot interface, with a \"Bring-Your-Own-Token\" approach "
"(nice for not wracking up big bills). It also contains instructions for how "
"to deploy this app on the Hugging Face platform. This is heavily influenced "
"by James Weaver's [excellent examples](https://huggingface.co/JavaFXpert)."
msgstr ""

#: ../docs/deployments.md:26
msgid ""
"[Beam](https://github.com/slai-labs/get-beam/tree/main/examples/langchain-"
"question-answering)"
msgstr ""

#: ../docs/deployments.md:28
msgid ""
"This repo serves as a template for how deploy a LangChain with [Beam]"
"(https://beam.cloud)."
msgstr ""

#: ../docs/deployments.md:30
msgid ""
"It implements a Question Answering app and contains instructions for "
"deploying the app as a serverless REST API."
msgstr ""

#: ../docs/deployments.md:32
msgid "[Vercel](https://github.com/homanp/vercel-langchain)"
msgstr ""

#: ../docs/deployments.md:34
msgid "A minimal example on how to run LangChain on Vercel using Flask."
msgstr ""

#: ../docs/deployments.md:36
msgid "[Fly.io](https://github.com/fly-apps/hello-fly-langchain)"
msgstr ""

#: ../docs/deployments.md:38
msgid ""
"A minimal example of how to deploy LangChain to [Fly.io](https://fly.io/) "
"using Flask."
msgstr ""

#: ../docs/deployments.md:40
msgid ""
"[Digitalocean App Platform](https://github.com/homanp/digitalocean-langchain)"
msgstr ""

#: ../docs/deployments.md:42
msgid ""
"A minimal example on how to deploy LangChain to DigitalOcean App Platform."
msgstr ""

#: ../docs/deployments.md:44
msgid "[Google Cloud Run](https://github.com/homanp/gcp-langchain)"
msgstr ""

#: ../docs/deployments.md:46
msgid "A minimal example on how to deploy LangChain to Google Cloud Run."
msgstr ""

#: ../docs/deployments.md:48
msgid "[SteamShip](https://github.com/steamship-core/steamship-langchain/)"
msgstr ""

#: ../docs/deployments.md:50
msgid ""
"This repository contains LangChain adapters for Steamship, enabling "
"LangChain developers to rapidly deploy their apps on Steamship. This "
"includes: production ready endpoints, horizontal scaling across "
"dependencies, persistant storage of app state, multi-tenancy support, etc."
msgstr ""

#: ../docs/deployments.md:53
msgid "[Langchain-serve](https://github.com/jina-ai/langchain-serve)"
msgstr ""

#: ../docs/deployments.md:55
msgid ""
"This repository allows users to serve local chains and agents as RESTful, "
"gRPC, or Websocket APIs thanks to [Jina](https://docs.jina.ai/). Deploy your "
"chains & agents with ease and enjoy independent scaling, serverless and "
"autoscaling APIs, as well as a Streamlit playground on Jina AI Cloud."
msgstr ""

#: ../docs/deployments.md:57
msgid "[BentoML](https://github.com/ssheng/BentoChain)"
msgstr ""

#: ../docs/deployments.md:59
msgid ""
"This repository provides an example of how to deploy a LangChain application "
"with [BentoML](https://github.com/bentoml/BentoML). BentoML is a framework "
"that enables the containerization of machine learning applications as "
"standard OCI images. BentoML also allows for the automatic generation of "
"OpenAPI and gRPC endpoints. With BentoML, you can integrate models from all "
"popular ML frameworks and deploy them as microservices running on the most "
"optimal hardware and scaling independently."
msgstr ""

#: ../docs/deployments.md:61
msgid "[Databutton](https://databutton.com/home?new-data-app=true)"
msgstr ""

#: ../docs/deployments.md:63
msgid ""
"These templates serve as examples of how to build, deploy, and share "
"LangChain applications using Databutton. You can create user interfaces with "
"Streamlit, automate tasks by scheduling Python code, and store files and "
"data in the built-in store. Examples include Chatbot interface with "
"conversational memory, Personal search engine, and a starter template for "
"LangChain apps. Deploying and sharing is one click."
msgstr ""

#: ../docs/ecosystem.rst:2 ../docs/index.rst:127
msgid "LangChain Ecosystem"
msgstr ""

#: ../docs/ecosystem.rst:4 ../docs/index.rst:129
msgid "Guides for how other companies/products can be used with LangChain"
msgstr ""

#: ../docs/ecosystem.rst:7
msgid "Groups"
msgstr ""

#: ../docs/ecosystem.rst:9
msgid "LangChain provides integration with many LLMs and systems:"
msgstr ""

#: ../docs/ecosystem.rst:11
msgid "`LLM Providers <./modules/models/llms/integrations.html>`_"
msgstr ""

#: ../docs/ecosystem.rst:12
msgid "`Chat Model Providers <./modules/models/chat/integrations.html>`_"
msgstr ""

#: ../docs/ecosystem.rst:13
msgid ""
"`Text Embedding Model Providers <./modules/models/text_embedding.html>`_"
msgstr ""

#: ../docs/ecosystem.rst:14
msgid ""
"`Document Loader Integrations <./modules/indexes/document_loaders.html>`_"
msgstr ""

#: ../docs/ecosystem.rst:15
msgid "`Text Splitter Integrations <./modules/indexes/text_splitters.html>`_"
msgstr ""

#: ../docs/ecosystem.rst:16
msgid "`Vectorstore Providers <./modules/indexes/vectorstores.html>`_"
msgstr ""

#: ../docs/ecosystem.rst:17
msgid "`Retriever Providers <./modules/indexes/retrievers.html>`_"
msgstr ""

#: ../docs/ecosystem.rst:18
msgid "`Tool Providers <./modules/agents/tools.html>`_"
msgstr ""

#: ../docs/ecosystem.rst:19
msgid "`Toolkit Integrations <./modules/agents/toolkits.html>`_"
msgstr ""

#: ../docs/ecosystem.rst:22
msgid "Companies / Products"
msgstr ""

#: ../docs/ecosystem/ai21.md:1
msgid "AI21 Labs"
msgstr ""

#: ../docs/ecosystem/ai21.md:3
msgid ""
"This page covers how to use the AI21 ecosystem within LangChain. It is "
"broken into two parts: installation and setup, and then references to "
"specific AI21 wrappers."
msgstr ""

#: ../docs/ecosystem/ai21.md:6 ../docs/ecosystem/apify.md:18
#: ../docs/ecosystem/atlas.md:6 ../docs/ecosystem/bananadev.md:6
#: ../docs/ecosystem/cerebriumai.md:6 ../docs/ecosystem/chroma.md:6
#: ../docs/ecosystem/cohere.md:6 ../docs/ecosystem/deepinfra.md:6
#: ../docs/ecosystem/deeplake.md:15 ../docs/ecosystem/forefrontai.md:6
#: ../docs/ecosystem/google_search.md:6 ../docs/ecosystem/gooseai.md:6
#: ../docs/ecosystem/gpt4all.md:5 ../docs/ecosystem/graphsignal.md:5
#: ../docs/ecosystem/hazy_research.md:6 ../docs/ecosystem/huggingface.md:6
#: ../docs/ecosystem/jina.md:6 ../docs/ecosystem/llamacpp.md:6
#: ../docs/ecosystem/milvus.md:6 ../docs/ecosystem/modal.md:6
#: ../docs/ecosystem/myscale.md:18 ../docs/ecosystem/nlpcloud.md:6
#: ../docs/ecosystem/openai.md:6 ../docs/ecosystem/opensearch.md:6
#: ../docs/ecosystem/petals.md:6 ../docs/ecosystem/pinecone.md:6
#: ../docs/ecosystem/predictionguard.md:6 ../docs/ecosystem/promptlayer.md:6
#: ../docs/ecosystem/qdrant.md:6 ../docs/ecosystem/replicate.md:4
#: ../docs/ecosystem/runhouse.md:6 ../docs/ecosystem/rwkv.md:6
#: ../docs/ecosystem/searx.md:6 ../docs/ecosystem/serpapi.md:6
#: ../docs/ecosystem/stochasticai.md:6 ../docs/ecosystem/unstructured.md:12
#: ../docs/ecosystem/weaviate.md:19 ../docs/ecosystem/wolfram_alpha.md:6
#: ../docs/ecosystem/writer.md:6 ../docs/ecosystem/zilliz.md:7
msgid "Installation and Setup"
msgstr ""

#: ../docs/ecosystem/ai21.md:7
msgid ""
"Get an AI21 api key and set it as an environment variable (`AI21_API_KEY`)"
msgstr ""

#: ../docs/ecosystem/ai21.md:9 ../docs/ecosystem/apify.md:25
#: ../docs/ecosystem/atlas.md:10 ../docs/ecosystem/bananadev.md:65
#: ../docs/ecosystem/cerebriumai.md:10 ../docs/ecosystem/chroma.md:8
#: ../docs/ecosystem/cohere.md:10 ../docs/ecosystem/deepinfra.md:10
#: ../docs/ecosystem/deeplake.md:18 ../docs/ecosystem/forefrontai.md:9
#: ../docs/ecosystem/google_search.md:11 ../docs/ecosystem/google_serper.md:10
#: ../docs/ecosystem/gooseai.md:16 ../docs/ecosystem/hazy_research.md:9
#: ../docs/ecosystem/huggingface.md:17 ../docs/ecosystem/jina.md:10
#: ../docs/ecosystem/llamacpp.md:10 ../docs/ecosystem/milvus.md:8
#: ../docs/ecosystem/modal.md:59 ../docs/ecosystem/myscale.md:43
#: ../docs/ecosystem/nlpcloud.md:10 ../docs/ecosystem/openai.md:11
#: ../docs/ecosystem/opensearch.md:8 ../docs/ecosystem/petals.md:10
#: ../docs/ecosystem/pgvector.md:15 ../docs/ecosystem/pinecone.md:8
#: ../docs/ecosystem/promptlayer.md:13 ../docs/ecosystem/qdrant.md:8
#: ../docs/ecosystem/searx.md:32 ../docs/ecosystem/serpapi.md:10
#: ../docs/ecosystem/stochasticai.md:10 ../docs/ecosystem/unstructured.md:28
#: ../docs/ecosystem/weaviate.md:21 ../docs/ecosystem/wolfram_alpha.md:13
#: ../docs/ecosystem/writer.md:9 ../docs/ecosystem/zilliz.md:9
msgid "Wrappers"
msgstr ""

#: ../docs/ecosystem/ai21.md:11 ../docs/ecosystem/bananadev.md:67
#: ../docs/ecosystem/cerebriumai.md:12 ../docs/ecosystem/cohere.md:12
#: ../docs/ecosystem/deepinfra.md:12 ../docs/ecosystem/forefrontai.md:11
#: ../docs/ecosystem/gooseai.md:18 ../docs/ecosystem/hazy_research.md:11
#: ../docs/ecosystem/huggingface.md:19 ../docs/ecosystem/llamacpp.md:12
#: ../docs/ecosystem/modal.md:61 ../docs/ecosystem/nlpcloud.md:12
#: ../docs/ecosystem/openai.md:13 ../docs/ecosystem/petals.md:12
#: ../docs/ecosystem/promptlayer.md:15 ../docs/ecosystem/stochasticai.md:12
#: ../docs/ecosystem/writer.md:11
msgid "LLM"
msgstr ""

#: ../docs/ecosystem/ai21.md:13
msgid "There exists an AI21 LLM wrapper, which you can access with"
msgstr ""

#: ../docs/ecosystem/aim_tracking.ipynb:10002
msgid "Aim"
msgstr ""

#: ../docs/ecosystem/aim_tracking.ipynb:10004
msgid ""
"Aim makes it super easy to visualize and debug LangChain executions. Aim "
"tracks inputs and outputs of LLMs and tools, as well as actions of agents."
msgstr ""

#: ../docs/ecosystem/aim_tracking.ipynb:10006
msgid "With Aim, you can easily debug and examine an individual execution:"
msgstr ""

#: ../docs/ecosystem/aim_tracking.ipynb:10008
msgid ""
"![](https://user-images.githubusercontent."
"com/13848158/227784778-06b806c7-74a1-4d15-ab85-9ece09b458aa.png)"
msgstr ""

#: ../docs/ecosystem/aim_tracking.ipynb:10010
msgid ""
"Additionally, you have the option to compare multiple executions side by "
"side:"
msgstr ""

#: ../docs/ecosystem/aim_tracking.ipynb:10012
msgid ""
"![](https://user-images.githubusercontent.com/13848158/227784994-699b24b7-"
"e69b-48f9-9ffa-e6a6142fd719.png)"
msgstr ""

#: ../docs/ecosystem/aim_tracking.ipynb:10014
msgid ""
"Aim is fully open source, [learn more](https://github.com/aimhubio/aim) "
"about Aim on GitHub."
msgstr ""

#: ../docs/ecosystem/aim_tracking.ipynb:10016
msgid "Let's move forward and see how to enable and configure Aim callback."
msgstr ""

#: ../docs/ecosystem/aim_tracking.ipynb:30002
msgid ""
"In this notebook we will explore three usage scenarios. To start off, we "
"will install the necessary packages and import certain modules. "
"Subsequently, we will configure two environment variables that can be "
"established either within the Python script or through the terminal."
msgstr ""

#: ../docs/ecosystem/aim_tracking.ipynb:60002
msgid ""
"Our examples use a GPT model as the LLM, and OpenAI offers an API for this "
"purpose. You can obtain the key from the following link: https://platform."
"openai.com/account/api-keys ."
msgstr ""

#: ../docs/ecosystem/aim_tracking.ipynb:60004
msgid ""
"We will use the SerpApi to retrieve search results from Google. To acquire "
"the SerpApi key, please go to https://serpapi.com/manage-api-key ."
msgstr ""

#: ../docs/ecosystem/aim_tracking.ipynb:80002
msgid ""
"The event methods of `AimCallbackHandler` accept the LangChain module or "
"agent as input and log at least the prompts and generated results, as well "
"as the serialized version of the LangChain module, to the designated Aim run."
msgstr ""

#: ../docs/ecosystem/aim_tracking.ipynb:100002
msgid ""
"The `flush_tracker` function is used to record LangChain assets on Aim. By "
"default, the session is reset rather than being terminated outright."
msgstr ""

#: ../docs/ecosystem/analyticdb.md:1
msgid "AnalyticDB"
msgstr ""

#: ../docs/ecosystem/analyticdb.md:3
msgid "This page covers how to use the AnalyticDB ecosystem within LangChain."
msgstr ""

#: ../docs/ecosystem/analyticdb.md:5 ../docs/ecosystem/atlas.md:12
#: ../docs/ecosystem/chroma.md:10 ../docs/ecosystem/deeplake.md:20
#: ../docs/ecosystem/milvus.md:10 ../docs/ecosystem/myscale.md:55
#: ../docs/ecosystem/opensearch.md:10 ../docs/ecosystem/pgvector.md:17
#: ../docs/ecosystem/pinecone.md:10 ../docs/ecosystem/qdrant.md:10
#: ../docs/ecosystem/weaviate.md:23 ../docs/ecosystem/zilliz.md:11
msgid "VectorStore"
msgstr ""

#: ../docs/ecosystem/analyticdb.md:7
msgid ""
"There exists a wrapper around AnalyticDB, allowing you to use it as a "
"vectorstore, whether for semantic search or example selection."
msgstr ""

#: ../docs/ecosystem/analyticdb.md:10 ../docs/ecosystem/atlas.md:22
#: ../docs/ecosystem/chroma.md:15 ../docs/ecosystem/deeplake.md:24
#: ../docs/ecosystem/milvus.md:15 ../docs/ecosystem/myscale.md:60
#: ../docs/ecosystem/opensearch.md:16 ../docs/ecosystem/pgvector.md:22
#: ../docs/ecosystem/pinecone.md:15 ../docs/ecosystem/qdrant.md:15
#: ../docs/ecosystem/weaviate.md:28 ../docs/ecosystem/zilliz.md:16
msgid "To import this vectorstore:"
msgstr ""

#: ../docs/ecosystem/analyticdb.md:15
msgid ""
"For a more detailed walkthrough of the AnalyticDB wrapper, see [this "
"notebook](../modules/indexes/vectorstores/examples/analyticdb.ipynb)"
msgstr ""

#: ../docs/ecosystem/apify.md:1
msgid "Apify"
msgstr ""

#: ../docs/ecosystem/apify.md:3
msgid ""
"This page covers how to use [Apify](https://apify.com) within LangChain."
msgstr ""

#: ../docs/ecosystem/apify.md:5 ../docs/use_cases/code.md:3
msgid "Overview"
msgstr ""

#: ../docs/ecosystem/apify.md:7
msgid ""
"Apify is a cloud platform for web scraping and data extraction, which "
"provides an [ecosystem](https://apify.com/store) of more than a thousand "
"ready-made apps called *Actors* for various scraping, crawling, and "
"extraction use cases."
msgstr ""

#: ../docs/ecosystem/apify.md:11
msgid "[![Apify Actors](../_static/ApifyActors.png)](https://apify.com/store)"
msgstr ""

#: ../docs/ecosystem/apify.md:11
msgid "Apify Actors"
msgstr ""

#: ../docs/ecosystem/apify.md:13
msgid ""
"This integration enables you run Actors on the Apify platform and load their "
"results into LangChain to feed your vector indexes with documents and data "
"from the web, e.g. to generate answers from websites with documentation, "
"blogs, or knowledge bases."
msgstr ""

#: ../docs/ecosystem/apify.md:20
msgid "Install the Apify API client for Python with `pip install apify-client`"
msgstr ""

#: ../docs/ecosystem/apify.md:21
msgid ""
"Get your [Apify API token](https://console.apify.com/account/integrations) "
"and either set it as an environment variable (`APIFY_API_TOKEN`) or pass it "
"to the `ApifyWrapper` as `apify_api_token` in the constructor."
msgstr ""

#: ../docs/ecosystem/apify.md:27 ../docs/ecosystem/google_search.md:13
#: ../docs/ecosystem/google_serper.md:12 ../docs/ecosystem/searx.md:34
#: ../docs/ecosystem/serpapi.md:12 ../docs/ecosystem/wolfram_alpha.md:15
msgid "Utility"
msgstr ""

#: ../docs/ecosystem/apify.md:29
msgid "You can use the `ApifyWrapper` to run Actors on the Apify platform."
msgstr ""

#: ../docs/ecosystem/apify.md:35
msgid ""
"For a more detailed walkthrough of this wrapper, see [this notebook](../"
"modules/agents/tools/examples/apify.ipynb)."
msgstr ""

#: ../docs/ecosystem/apify.md:38
msgid "Loader"
msgstr ""

#: ../docs/ecosystem/apify.md:40
msgid ""
"You can also use our `ApifyDatasetLoader` to get data from Apify dataset."
msgstr ""

#: ../docs/ecosystem/apify.md:46
msgid ""
"For a more detailed walkthrough of this loader, see [this notebook](../"
"modules/indexes/document_loaders/examples/apify_dataset.ipynb)."
msgstr ""

#: ../docs/ecosystem/atlas.md:1
msgid "AtlasDB"
msgstr ""

#: ../docs/ecosystem/atlas.md:3
msgid ""
"This page covers how to use Nomic's Atlas ecosystem within LangChain. It is "
"broken into two parts: installation and setup, and then references to "
"specific Atlas wrappers."
msgstr ""

#: ../docs/ecosystem/atlas.md:7
msgid "Install the Python package with `pip install nomic`"
msgstr ""

#: ../docs/ecosystem/atlas.md:8
msgid ""
"Nomic is also included in langchains poetry extras `poetry install -E all`"
msgstr ""

#: ../docs/ecosystem/atlas.md:14
msgid ""
"There exists a wrapper around the Atlas neural database, allowing you to use "
"it as a vectorstore. This vectorstore also gives you full access to the "
"underlying AtlasProject object, which will allow you to use the full range "
"of Atlas map interactions, such as bulk tagging and automatic topic "
"modeling. Please see [the Atlas docs](https://docs.nomic.ai/atlas_api.html) "
"for more detailed information."
msgstr ""

#: ../docs/ecosystem/atlas.md:27
msgid ""
"For a more detailed walkthrough of the AtlasDB wrapper, see [this notebook]"
"(../modules/indexes/vectorstores/examples/atlas.ipynb)"
msgstr ""

#: ../docs/ecosystem/bananadev.md:1
msgid "Banana"
msgstr ""

#: ../docs/ecosystem/bananadev.md:3
msgid ""
"This page covers how to use the Banana ecosystem within LangChain. It is "
"broken into two parts: installation and setup, and then references to "
"specific Banana wrappers."
msgstr ""

#: ../docs/ecosystem/bananadev.md:8
msgid "Install with `pip install banana-dev`"
msgstr ""

#: ../docs/ecosystem/bananadev.md:9
msgid ""
"Get an Banana api key and set it as an environment variable "
"(`BANANA_API_KEY`)"
msgstr ""

#: ../docs/ecosystem/bananadev.md:11
msgid "Define your Banana Template"
msgstr ""

#: ../docs/ecosystem/bananadev.md:13
msgid ""
"If you want to use an available language model template you can find one "
"[here](https://app.banana.dev/templates/conceptofmind/serverless-template-"
"palmyra-base). This template uses the Palmyra-Base model by [Writer](https://"
"writer.com/product/api/). You can check out an example Banana repository "
"[here](https://github.com/conceptofmind/serverless-template-palmyra-base)."
msgstr ""

#: ../docs/ecosystem/bananadev.md:17
msgid "Build the Banana app"
msgstr ""

#: ../docs/ecosystem/bananadev.md:19
msgid ""
"Banana Apps must include the \"output\" key in the return json.  There is a "
"rigid response structure."
msgstr ""

#: ../docs/ecosystem/bananadev.md:27
msgid "An example inference function would be:"
msgstr ""

#: ../docs/ecosystem/bananadev.md:63
msgid ""
"You can find a full example of a Banana app [here](https://github.com/"
"conceptofmind/serverless-template-palmyra-base/blob/main/app.py)."
msgstr ""

#: ../docs/ecosystem/bananadev.md:69
msgid "There exists an Banana LLM wrapper, which you can access with"
msgstr ""

#: ../docs/ecosystem/bananadev.md:75
msgid "You need to provide a model key located in the dashboard:"
msgstr ""

#: ../docs/ecosystem/cerebriumai.md:1
msgid "CerebriumAI"
msgstr ""

#: ../docs/ecosystem/cerebriumai.md:3
msgid ""
"This page covers how to use the CerebriumAI ecosystem within LangChain. It "
"is broken into two parts: installation and setup, and then references to "
"specific CerebriumAI wrappers."
msgstr ""

#: ../docs/ecosystem/cerebriumai.md:7
msgid "Install with `pip install cerebrium`"
msgstr ""

#: ../docs/ecosystem/cerebriumai.md:8
msgid ""
"Get an CerebriumAI api key and set it as an environment variable "
"(`CEREBRIUMAI_API_KEY`)"
msgstr ""

#: ../docs/ecosystem/cerebriumai.md:14
msgid "There exists an CerebriumAI LLM wrapper, which you can access with"
msgstr ""

#: ../docs/ecosystem/chroma.md:1
msgid "Chroma"
msgstr ""

#: ../docs/ecosystem/chroma.md:3
msgid ""
"This page covers how to use the Chroma ecosystem within LangChain. It is "
"broken into two parts: installation and setup, and then references to "
"specific Chroma wrappers."
msgstr ""

#: ../docs/ecosystem/chroma.md:7
msgid "Install the Python package with `pip install chromadb`"
msgstr ""

#: ../docs/ecosystem/chroma.md:12
msgid ""
"There exists a wrapper around Chroma vector databases, allowing you to use "
"it as a vectorstore, whether for semantic search or example selection."
msgstr ""

#: ../docs/ecosystem/chroma.md:20
msgid ""
"For a more detailed walkthrough of the Chroma wrapper, see [this notebook]"
"(../modules/indexes/vectorstores/getting_started.ipynb)"
msgstr ""

#: ../docs/ecosystem/clearml_tracking.ipynb:10002
msgid "ClearML Integration"
msgstr ""

#: ../docs/ecosystem/clearml_tracking.ipynb:10004
msgid ""
"In order to properly keep track of your langchain experiments and their "
"results, you can enable the ClearML integration. ClearML is an experiment "
"manager that neatly tracks and organizes all your experiment runs."
msgstr ""

#: ../docs/ecosystem/clearml_tracking.ipynb:20002
msgid "Getting API Credentials"
msgstr ""

#: ../docs/ecosystem/clearml_tracking.ipynb:20004
msgid ""
"We'll be using quite some APIs in this notebook, here is a list and where to "
"get them:"
msgstr ""

#: ../docs/ecosystem/clearml_tracking.ipynb:20006
msgid "ClearML: https://app.clear.ml/settings/workspace-configuration"
msgstr ""

#: ../docs/ecosystem/clearml_tracking.ipynb:20007
msgid "OpenAI: https://platform.openai.com/account/api-keys"
msgstr ""

#: ../docs/ecosystem/clearml_tracking.ipynb:20008
msgid "SerpAPI (google search): https://serpapi.com/dashboard"
msgstr ""

#: ../docs/ecosystem/clearml_tracking.ipynb:40002
msgid "Setting Up"
msgstr ""

#: ../docs/ecosystem/clearml_tracking.ipynb:70002
msgid "Scenario 1: Just an LLM"
msgstr ""

#: ../docs/ecosystem/clearml_tracking.ipynb:70004
msgid ""
"First, let's just run a single LLM a few times and capture the resulting "
"prompt-answer conversation in ClearML"
msgstr ""

#: ../docs/ecosystem/clearml_tracking.ipynb:90002
msgid ""
"At this point you can already go to https://app.clear.ml and take a look at "
"the resulting ClearML Task that was created."
msgstr ""

#: ../docs/ecosystem/clearml_tracking.ipynb:90004
msgid ""
"Among others, you should see that this notebook is saved along with any git "
"information. The model JSON that contains the used parameters is saved as an "
"artifact, there are also console logs and under the plots section, you'll "
"find tables that represent the flow of the chain."
msgstr ""

#: ../docs/ecosystem/clearml_tracking.ipynb:90006
msgid ""
"Finally, if you enabled visualizations, these are stored as HTML files under "
"debug samples."
msgstr ""

#: ../docs/ecosystem/clearml_tracking.ipynb:100002
msgid "Scenario 2: Creating an agent with tools"
msgstr ""

#: ../docs/ecosystem/clearml_tracking.ipynb:100004
msgid ""
"To show a more advanced workflow, let's create an agent with access to "
"tools. The way ClearML tracks the results is not different though, only the "
"table will look slightly different as there are other types of actions taken "
"when compared to the earlier, simpler example."
msgstr ""

#: ../docs/ecosystem/clearml_tracking.ipynb:100006
msgid ""
"You can now also see the use of the `finish=True` keyword, which will fully "
"close the ClearML Task, instead of just resetting the parameters and prompts "
"for a new conversation."
msgstr ""

#: ../docs/ecosystem/clearml_tracking.ipynb:120002
msgid "Tips and Next Steps"
msgstr ""

#: ../docs/ecosystem/clearml_tracking.ipynb:120004
msgid ""
"Make sure you always use a unique `name` argument for the `clearml_callback."
"flush_tracker` function. If not, the model parameters used for a run will "
"override the previous run!"
msgstr ""

#: ../docs/ecosystem/clearml_tracking.ipynb:120006
msgid ""
"If you close the ClearML Callback using `clearml_callback.flush_tracker(..., "
"finish=True)` the Callback cannot be used anymore. Make a new one if you "
"want to keep logging."
msgstr ""

#: ../docs/ecosystem/clearml_tracking.ipynb:120008
msgid ""
"Check out the rest of the open source ClearML ecosystem, there is a data "
"version manager, a remote execution agent, automated pipelines and much more!"
msgstr ""

#: ../docs/ecosystem/cohere.md:1
msgid "Cohere"
msgstr ""

#: ../docs/ecosystem/cohere.md:3
msgid ""
"This page covers how to use the Cohere ecosystem within LangChain. It is "
"broken into two parts: installation and setup, and then references to "
"specific Cohere wrappers."
msgstr ""

#: ../docs/ecosystem/cohere.md:7
msgid "Install the Python SDK with `pip install cohere`"
msgstr ""

#: ../docs/ecosystem/cohere.md:8
msgid ""
"Get an Cohere api key and set it as an environment variable "
"(`COHERE_API_KEY`)"
msgstr ""

#: ../docs/ecosystem/cohere.md:14
msgid "There exists an Cohere LLM wrapper, which you can access with"
msgstr ""

#: ../docs/ecosystem/cohere.md:19 ../docs/ecosystem/huggingface.md:36
#: ../docs/ecosystem/jina.md:12 ../docs/ecosystem/llamacpp.md:20
#: ../docs/ecosystem/openai.md:28 ../docs/reference/modules/embeddings.rst:2
msgid "Embeddings"
msgstr ""

#: ../docs/ecosystem/cohere.md:21
msgid "There exists an Cohere Embeddings wrapper, which you can access with"
msgstr ""

#: ../docs/ecosystem/cohere.md:25
msgid ""
"For a more detailed walkthrough of this, see [this notebook](../modules/"
"models/text_embedding/examples/cohere.ipynb)"
msgstr ""

#: ../docs/ecosystem/comet_tracking.ipynb:10002
msgid "Comet"
msgstr ""

#: ../docs/ecosystem/comet_tracking.ipynb:20002
msgid ""
"![](https://user-images.githubusercontent.com/7529846/230328046-"
"a8b18c51-12e3-4617-9b39-97614a571a2d.png)"
msgstr ""

#: ../docs/ecosystem/comet_tracking.ipynb:30002
msgid ""
"In this guide we will demonstrate how to track your Langchain Experiments, "
"Evaluation Metrics, and LLM Sessions with [Comet](https://www.comet.com/"
"site/?utm_source=langchain&utm_medium=referral&utm_campaign=comet_notebook)."
msgstr ""

#: ../docs/ecosystem/comet_tracking.ipynb:30008
msgid ""
"**Example Project:** [Comet with LangChain](https://www.comet.com/examples/"
"comet-example-langchain/view/b5ZThK6OFdhKWVSP3fDfRtrNF/panels?"
"utm_source=langchain&utm_medium=referral&utm_campaign=comet_notebook)"
msgstr ""

#: ../docs/ecosystem/comet_tracking.ipynb:50002
msgid "Install Comet and Dependencies"
msgstr ""

#: ../docs/ecosystem/comet_tracking.ipynb:70002
msgid "Initialize Comet and Set your Credentials"
msgstr ""

#: ../docs/ecosystem/comet_tracking.ipynb:80002
msgid ""
"You can grab your [Comet API Key here](https://www.comet.com/signup?"
"utm_source=langchain&utm_medium=referral&utm_campaign=comet_notebook) or "
"click the link after initializing Comet"
msgstr ""

#: ../docs/ecosystem/comet_tracking.ipynb:100002
msgid "Set OpenAI and SerpAPI credentials"
msgstr ""

#: ../docs/ecosystem/comet_tracking.ipynb:110002
msgid ""
"You will need an [OpenAI API Key](https://platform.openai.com/account/api-"
"keys) and a [SerpAPI API Key](https://serpapi.com/dashboard) to run the "
"following examples"
msgstr ""

#: ../docs/ecosystem/comet_tracking.ipynb:130002
msgid "Scenario 1: Using just an LLM"
msgstr ""

#: ../docs/ecosystem/comet_tracking.ipynb:150002
msgid "Scenario 2: Using an LLM in a Chain"
msgstr ""

#: ../docs/ecosystem/comet_tracking.ipynb:170002
msgid "Scenario 3: Using An Agent with Tools"
msgstr ""

#: ../docs/ecosystem/comet_tracking.ipynb:190002
msgid "Scenario 4: Using Custom Evaluation Metrics"
msgstr ""

#: ../docs/ecosystem/comet_tracking.ipynb:200002
msgid ""
"The `CometCallbackManager` also allows you to define and use Custom "
"Evaluation Metrics to assess generated outputs from your model. Let's take a "
"look at how this works."
msgstr ""

#: ../docs/ecosystem/comet_tracking.ipynb:200005
msgid ""
"In the snippet below, we will use the [ROUGE](https://huggingface.co/spaces/"
"evaluate-metric/rouge) metric to evaluate the quality of a generated summary "
"of an input prompt."
msgstr ""

#: ../docs/ecosystem/databerry.md:1 ../docs/ecosystem/databerry.md:9
msgid "Databerry"
msgstr ""

#: ../docs/ecosystem/databerry.md:3
msgid ""
"This page covers how to use the [Databerry](https://databerry.ai) within "
"LangChain."
msgstr ""

#: ../docs/ecosystem/databerry.md:5
msgid "What is Databerry?"
msgstr ""

#: ../docs/ecosystem/databerry.md:7
msgid ""
"Databerry is an [open source](https://github.com/gmpetrov/databerry) "
"document retrievial platform that helps to connect your personal data with "
"Large Language Models."
msgstr ""

#: ../docs/ecosystem/databerry.md:9
msgid "![Databerry](../_static/DataberryDashboard.png)"
msgstr ""

#: ../docs/ecosystem/databerry.md:11 ../docs/ecosystem/helicone.md:11
#: ../docs/ecosystem/metal.md:11
msgid "Quick start"
msgstr ""

#: ../docs/ecosystem/databerry.md:13
msgid "Retrieving documents stored in Databerry from LangChain is very easy!"
msgstr ""

#: ../docs/ecosystem/deepinfra.md:1
msgid "DeepInfra"
msgstr ""

#: ../docs/ecosystem/deepinfra.md:3
msgid ""
"This page covers how to use the DeepInfra ecosystem within LangChain. It is "
"broken into two parts: installation and setup, and then references to "
"specific DeepInfra wrappers."
msgstr ""

#: ../docs/ecosystem/deepinfra.md:7
msgid ""
"Get your DeepInfra api key from this link [here](https://deepinfra.com/)."
msgstr ""

#: ../docs/ecosystem/deepinfra.md:8
msgid ""
"Get an DeepInfra api key and set it as an environment variable "
"(`DEEPINFRA_API_TOKEN`)"
msgstr ""

#: ../docs/ecosystem/deepinfra.md:14
msgid "There exists an DeepInfra LLM wrapper, which you can access with"
msgstr ""

#: ../docs/ecosystem/deeplake.md:1
msgid "Deep Lake"
msgstr ""

#: ../docs/ecosystem/deeplake.md:2
msgid "This page covers how to use the Deep Lake ecosystem within LangChain."
msgstr ""

#: ../docs/ecosystem/deeplake.md:4
msgid "Why Deep Lake?"
msgstr ""

#: ../docs/ecosystem/deeplake.md:5
msgid ""
"More than just a (multi-modal) vector store. You can later use the dataset "
"to fine-tune your own LLM models."
msgstr ""

#: ../docs/ecosystem/deeplake.md:6
msgid ""
"Not only stores embeddings, but also the original data with automatic "
"version control."
msgstr ""

#: ../docs/ecosystem/deeplake.md:7
msgid ""
"Truly serverless. Doesn't require another service and can be used with major "
"cloud providers (AWS S3, GCS, etc.)"
msgstr ""

#: ../docs/ecosystem/deeplake.md:9
msgid "More Resources"
msgstr ""

#: ../docs/ecosystem/deeplake.md:10
msgid ""
"[Ultimate Guide to LangChain & Deep Lake: Build ChatGPT to Answer Questions "
"on Your Financial Data](https://www.activeloop.ai/resources/ultimate-guide-"
"to-lang-chain-deep-lake-build-chat-gpt-to-answer-questions-on-your-financial-"
"data/)"
msgstr ""

#: ../docs/ecosystem/deeplake.md:11
msgid ""
"[Twitter the-algorithm codebase analysis with Deep Lake](../use_cases/code/"
"twitter-the-algorithm-analysis-deeplake.ipynb)"
msgstr ""

#: ../docs/ecosystem/deeplake.md:12
msgid ""
"Here is [whitepaper](https://www.deeplake.ai/whitepaper) and [academic paper]"
"(https://arxiv.org/pdf/2209.10785.pdf) for Deep Lake"
msgstr ""

#: ../docs/ecosystem/deeplake.md:13
msgid ""
"Here is a set of additional resources available for review: [Deep Lake]"
"(https://github.com/activeloopai/deeplake), [Getting Started](https://docs."
"activeloop.ai/getting-started) andÂ [Tutorials](https://docs.activeloop.ai/"
"hub-tutorials)"
msgstr ""

#: ../docs/ecosystem/deeplake.md:16
msgid "Install the Python package with `pip install deeplake`"
msgstr ""

#: ../docs/ecosystem/deeplake.md:22
msgid ""
"There exists a wrapper around Deep Lake, a data lake for Deep Learning "
"applications, allowing you to use it as a vector store (for now), whether "
"for semantic search or example selection."
msgstr ""

#: ../docs/ecosystem/deeplake.md:30
msgid ""
"For a more detailed walkthrough of the Deep Lake wrapper, see [this notebook]"
"(../modules/indexes/vectorstores/examples/deeplake.ipynb)"
msgstr ""

#: ../docs/ecosystem/forefrontai.md:1
msgid "ForefrontAI"
msgstr ""

#: ../docs/ecosystem/forefrontai.md:3
msgid ""
"This page covers how to use the ForefrontAI ecosystem within LangChain. It "
"is broken into two parts: installation and setup, and then references to "
"specific ForefrontAI wrappers."
msgstr ""

#: ../docs/ecosystem/forefrontai.md:7
msgid ""
"Get an ForefrontAI api key and set it as an environment variable "
"(`FOREFRONTAI_API_KEY`)"
msgstr ""

#: ../docs/ecosystem/forefrontai.md:13
msgid "There exists an ForefrontAI LLM wrapper, which you can access with"
msgstr ""

#: ../docs/ecosystem/google_search.md:1
msgid "Google Search Wrapper"
msgstr ""

#: ../docs/ecosystem/google_search.md:3
msgid ""
"This page covers how to use the Google Search API within LangChain. It is "
"broken into two parts: installation and setup, and then references to the "
"specific Google Search wrapper."
msgstr ""

#: ../docs/ecosystem/google_search.md:7 ../docs/reference/integrations.md:34
msgid "Install requirements with `pip install google-api-python-client`"
msgstr ""

#: ../docs/ecosystem/google_search.md:8
msgid ""
"Set up a Custom Search Engine, following [these instructions](https://"
"stackoverflow.com/questions/37083058/programmatically-searching-google-in-"
"python-using-custom-search)"
msgstr ""

#: ../docs/ecosystem/google_search.md:9
msgid ""
"Get an API Key and Custom Search Engine ID from the previous step, and set "
"them as environment variables `GOOGLE_API_KEY` and `GOOGLE_CSE_ID` "
"respectively"
msgstr ""

#: ../docs/ecosystem/google_search.md:15
msgid ""
"There exists a GoogleSearchAPIWrapper utility which wraps this API. To "
"import this utility:"
msgstr ""

#: ../docs/ecosystem/google_search.md:21
msgid ""
"For a more detailed walkthrough of this wrapper, see [this notebook](../"
"modules/agents/tools/examples/google_search.ipynb)."
msgstr ""

#: ../docs/ecosystem/google_search.md:23 ../docs/ecosystem/google_serper.md:64
#: ../docs/ecosystem/searx.md:48 ../docs/ecosystem/serpapi.md:22
#: ../docs/ecosystem/wolfram_alpha.md:25
msgid "Tool"
msgstr ""

#: ../docs/ecosystem/google_search.md:25 ../docs/ecosystem/google_serper.md:66
#: ../docs/ecosystem/serpapi.md:24 ../docs/ecosystem/wolfram_alpha.md:27
msgid ""
"You can also easily load this wrapper as a Tool (to use with an Agent). You "
"can do this with:"
msgstr ""

#: ../docs/ecosystem/google_search.md:32 ../docs/ecosystem/google_serper.md:73
#: ../docs/ecosystem/serpapi.md:31 ../docs/ecosystem/wolfram_alpha.md:34
msgid ""
"For more information on this, see [this page](../modules/agents/tools/"
"getting_started.md)"
msgstr ""

#: ../docs/ecosystem/google_serper.md:1
msgid "Google Serper Wrapper"
msgstr ""

#: ../docs/ecosystem/google_serper.md:3
msgid ""
"This page covers how to use the [Serper](https://serper.dev) Google Search "
"API within LangChain. Serper is a low-cost Google Search API that can be "
"used to add answer box, knowledge graph, and organic results data from "
"Google Search.  It is broken into two parts: setup, and then references to "
"the specific Google Serper wrapper."
msgstr ""

#: ../docs/ecosystem/google_serper.md:6 ../docs/ecosystem/pgvector.md:10
#: ../docs/use_cases/autonomous_agents/meta_prompt.ipynb:20002
#: ../docs/use_cases/evaluation/data_augmented_question_answering.ipynb:10006
#: ../docs/use_cases/evaluation/generic_agent_evaluation.ipynb:20002
#: ../docs/use_cases/evaluation/huggingface_datasets.ipynb:20002
#: ../docs/use_cases/evaluation/question_answering.ipynb:20002
msgid "Setup"
msgstr ""

#: ../docs/ecosystem/google_serper.md:7
msgid "Go to [serper.dev](https://serper.dev) to sign up for a free account"
msgstr ""

#: ../docs/ecosystem/google_serper.md:8
msgid ""
"Get the api key and set it as an environment variable (`SERPER_API_KEY`)"
msgstr ""

#: ../docs/ecosystem/google_serper.md:14
msgid ""
"There exists a GoogleSerperAPIWrapper utility which wraps this API. To "
"import this utility:"
msgstr ""

#: ../docs/ecosystem/google_serper.md:20
msgid "You can use it as part of a Self Ask chain:"
msgstr ""

#: ../docs/ecosystem/google_serper.md:47
msgid "Output"
msgstr ""

#: ../docs/ecosystem/google_serper.md:62
msgid ""
"For a more detailed walkthrough of this wrapper, see [this notebook](../"
"modules/agents/tools/examples/google_serper.ipynb)."
msgstr ""

#: ../docs/ecosystem/gooseai.md:1
msgid "GooseAI"
msgstr ""

#: ../docs/ecosystem/gooseai.md:3
msgid ""
"This page covers how to use the GooseAI ecosystem within LangChain. It is "
"broken into two parts: installation and setup, and then references to "
"specific GooseAI wrappers."
msgstr ""

#: ../docs/ecosystem/gooseai.md:7 ../docs/ecosystem/openai.md:7
msgid "Install the Python SDK with `pip install openai`"
msgstr ""

#: ../docs/ecosystem/gooseai.md:8
msgid "Get your GooseAI api key from this link [here](https://goose.ai/)."
msgstr ""

#: ../docs/ecosystem/gooseai.md:9
msgid "Set the environment variable (`GOOSEAI_API_KEY`)."
msgstr ""

#: ../docs/ecosystem/gooseai.md:20
msgid "There exists an GooseAI LLM wrapper, which you can access with:"
msgstr ""

#: ../docs/ecosystem/gpt4all.md:1 ../docs/ecosystem/gpt4all.md:11
msgid "GPT4All"
msgstr ""

#: ../docs/ecosystem/gpt4all.md:3
msgid ""
"This page covers how to use the `GPT4All` wrapper within LangChain. The "
"tutorial is divided into two parts: installation and setup, followed by "
"usage with an example."
msgstr ""

#: ../docs/ecosystem/gpt4all.md:6
msgid "Install the Python package with `pip install pyllamacpp`"
msgstr ""

#: ../docs/ecosystem/gpt4all.md:7
msgid ""
"Download a [GPT4All model](https://github.com/nomic-ai/pyllamacpp#supported-"
"model) and place it in your desired directory"
msgstr ""

#: ../docs/ecosystem/gpt4all.md:9 ../docs/ecosystem/pgvector.md:27
#: ../docs/ecosystem/rwkv.md:12
msgid "Usage"
msgstr ""

#: ../docs/ecosystem/gpt4all.md:13
msgid ""
"To use the GPT4All wrapper, you need to provide the path to the pre-trained "
"model file and the model's configuration."
msgstr ""

#: ../docs/ecosystem/gpt4all.md:25
msgid ""
"You can also customize the generation parameters, such as n_predict, temp, "
"top_p, top_k, and others."
msgstr ""

#: ../docs/ecosystem/gpt4all.md:27
msgid "To stream the model's predictions, add in a CallbackManager."
msgstr ""

#: ../docs/ecosystem/gpt4all.md:43 ../docs/ecosystem/rwkv.md:49
msgid "Model File"
msgstr ""

#: ../docs/ecosystem/gpt4all.md:45
msgid ""
"You can find links to model file downloads in the [pyllamacpp](https://"
"github.com/nomic-ai/pyllamacpp) repository."
msgstr ""

#: ../docs/ecosystem/gpt4all.md:47
msgid ""
"For a more detailed walkthrough of this, see [this notebook](../modules/"
"models/llms/integrations/gpt4all.ipynb)"
msgstr ""

#: ../docs/ecosystem/graphsignal.md:1
msgid "Graphsignal"
msgstr ""

#: ../docs/ecosystem/graphsignal.md:3
msgid ""
"This page covers how to use [Graphsignal](https://app.graphsignal.com) to "
"trace and monitor LangChain. Graphsignal enables full visibility into your "
"application. It provides latency breakdowns by chains and tools, exceptions "
"with full context, data monitoring, compute/GPU utilization, OpenAI cost "
"analytics, and more."
msgstr ""

#: ../docs/ecosystem/graphsignal.md:7
msgid "Install the Python library with `pip install graphsignal`"
msgstr ""

#: ../docs/ecosystem/graphsignal.md:8
msgid "Create free Graphsignal account [here](https://graphsignal.com)"
msgstr ""

#: ../docs/ecosystem/graphsignal.md:9
msgid ""
"Get an API key and set it as an environment variable (`GRAPHSIGNAL_API_KEY`)"
msgstr ""

#: ../docs/ecosystem/graphsignal.md:11
msgid "Tracing and Monitoring"
msgstr ""

#: ../docs/ecosystem/graphsignal.md:13
msgid ""
"Graphsignal automatically instruments and starts tracing and monitoring "
"chains. Traces and metrics are then available in your [Graphsignal "
"dashboards](https://app.graphsignal.com)."
msgstr ""

#: ../docs/ecosystem/graphsignal.md:15
msgid "Initialize the tracer by providing a deployment name:"
msgstr ""

#: ../docs/ecosystem/graphsignal.md:23
msgid ""
"To additionally trace any function or code, you can use a decorator or a "
"context manager:"
msgstr ""

#: ../docs/ecosystem/graphsignal.md:36
msgid ""
"Optionally, enable profiling to record function-level statistics for each "
"trace."
msgstr ""

#: ../docs/ecosystem/graphsignal.md:44
msgid ""
"See the [Quick Start](https://graphsignal.com/docs/guides/quick-start/) "
"guide for complete setup instructions."
msgstr ""

#: ../docs/ecosystem/hazy_research.md:1
msgid "Hazy Research"
msgstr ""

#: ../docs/ecosystem/hazy_research.md:3
msgid ""
"This page covers how to use the Hazy Research ecosystem within LangChain. It "
"is broken into two parts: installation and setup, and then references to "
"specific Hazy Research wrappers."
msgstr ""

#: ../docs/ecosystem/hazy_research.md:7
msgid "To use the `manifest`, install it with `pip install manifest-ml`"
msgstr ""

#: ../docs/ecosystem/hazy_research.md:13
msgid ""
"There exists an LLM wrapper around Hazy Research's `manifest` library.  "
"`manifest` is a python library which is itself a wrapper around many model "
"providers, and adds in caching, history, and more."
msgstr ""

#: ../docs/ecosystem/hazy_research.md:16
msgid "To use this wrapper:"
msgstr ""

#: ../docs/ecosystem/helicone.md:1 ../docs/ecosystem/helicone.md:9
#: ../docs/ecosystem/helicone.md:21
msgid "Helicone"
msgstr ""

#: ../docs/ecosystem/helicone.md:3
msgid ""
"This page covers how to use the [Helicone](https://helicone.ai) ecosystem "
"within LangChain."
msgstr ""

#: ../docs/ecosystem/helicone.md:5
msgid "What is Helicone?"
msgstr ""

#: ../docs/ecosystem/helicone.md:7
msgid ""
"Helicone is an [open source](https://github.com/Helicone/helicone) "
"observability platform that proxies your OpenAI traffic and provides you key "
"insights into your spend, latency and usage."
msgstr ""

#: ../docs/ecosystem/helicone.md:9
msgid "![Helicone](../_static/HeliconeDashboard.png)"
msgstr ""

#: ../docs/ecosystem/helicone.md:13
msgid ""
"With your LangChain environment you can just add the following parameter."
msgstr ""

#: ../docs/ecosystem/helicone.md:19
msgid ""
"Now head over to [helicone.ai](https://helicone.ai/onboarding?step=2) to "
"create your account, and add your OpenAI API key within our dashboard to "
"view your logs."
msgstr ""

#: ../docs/ecosystem/helicone.md:21
msgid "![Helicone](../_static/HeliconeKeys.png)"
msgstr ""

#: ../docs/ecosystem/helicone.md:23
msgid "How to enable Helicone caching"
msgstr ""

#: ../docs/ecosystem/helicone.md:35
msgid ""
"[Helicone caching docs](https://docs.helicone.ai/advanced-usage/caching)"
msgstr ""

#: ../docs/ecosystem/helicone.md:37
msgid "How to use Helicone custom properties"
msgstr ""

#: ../docs/ecosystem/helicone.md:53
msgid ""
"[Helicone property docs](https://docs.helicone.ai/advanced-usage/custom-"
"properties)"
msgstr ""

#: ../docs/ecosystem/huggingface.md:1
msgid "Hugging Face"
msgstr ""

#: ../docs/ecosystem/huggingface.md:3
msgid ""
"This page covers how to use the Hugging Face ecosystem (including the "
"[Hugging Face Hub](https://huggingface.co)) within LangChain. It is broken "
"into two parts: installation and setup, and then references to specific "
"Hugging Face wrappers."
msgstr ""

#: ../docs/ecosystem/huggingface.md:8
msgid "If you want to work with the Hugging Face Hub:"
msgstr ""

#: ../docs/ecosystem/huggingface.md:9
msgid "Install the Hub client library with `pip install huggingface_hub`"
msgstr ""

#: ../docs/ecosystem/huggingface.md:10
msgid "Create a Hugging Face account (it's free!)"
msgstr ""

#: ../docs/ecosystem/huggingface.md:11
msgid ""
"Create an [access token](https://huggingface.co/docs/hub/security-tokens) "
"and set it as an environment variable (`HUGGINGFACEHUB_API_TOKEN`)"
msgstr ""

#: ../docs/ecosystem/huggingface.md:13
msgid "If you want work with the Hugging Face Python libraries:"
msgstr ""

#: ../docs/ecosystem/huggingface.md:14
msgid ""
"Install `pip install transformers` for working with models and tokenizers"
msgstr ""

#: ../docs/ecosystem/huggingface.md:15
msgid "Install `pip install datasets` for working with datasets"
msgstr ""

#: ../docs/ecosystem/huggingface.md:21
msgid ""
"There exists two Hugging Face LLM wrappers, one for a local pipeline and one "
"for a model hosted on Hugging Face Hub. Note that these wrappers only work "
"for models that support the following tasks: [`text2text-generation`]"
"(https://huggingface.co/models?library=transformers&pipeline_tag=text2text-"
"generation&sort=downloads), [`text-generation`](https://huggingface.co/"
"models?library=transformers&pipeline_tag=text-classification&sort=downloads)"
msgstr ""

#: ../docs/ecosystem/huggingface.md:24 ../docs/ecosystem/huggingface.md:41
msgid "To use the local pipeline wrapper:"
msgstr ""

#: ../docs/ecosystem/huggingface.md:29 ../docs/ecosystem/huggingface.md:46
msgid "To use a the wrapper for a model hosted on Hugging Face Hub:"
msgstr ""

#: ../docs/ecosystem/huggingface.md:33
msgid ""
"For a more detailed walkthrough of the Hugging Face Hub wrapper, see [this "
"notebook](../modules/models/llms/integrations/huggingface_hub.ipynb)"
msgstr ""

#: ../docs/ecosystem/huggingface.md:38
msgid ""
"There exists two Hugging Face Embeddings wrappers, one for a local model and "
"one for a model hosted on Hugging Face Hub. Note that these wrappers only "
"work for [`sentence-transformers` models](https://huggingface.co/models?"
"library=sentence-transformers&sort=downloads)."
msgstr ""

#: ../docs/ecosystem/huggingface.md:50
msgid ""
"For a more detailed walkthrough of this, see [this notebook](../modules/"
"models/text_embedding/examples/huggingfacehub.ipynb)"
msgstr ""

#: ../docs/ecosystem/huggingface.md:52 ../docs/ecosystem/openai.md:37
msgid "Tokenizer"
msgstr ""

#: ../docs/ecosystem/huggingface.md:54
msgid ""
"There are several places you can use tokenizers available through the "
"`transformers` package. By default, it is used to count tokens for all LLMs."
msgstr ""

#: ../docs/ecosystem/huggingface.md:57 ../docs/ecosystem/openai.md:42
msgid "You can also use it to count tokens when splitting documents with"
msgstr ""

#: ../docs/ecosystem/huggingface.md:62
msgid ""
"For a more detailed walkthrough of this, see [this notebook](../modules/"
"indexes/text_splitters/examples/huggingface_length_function.ipynb)"
msgstr ""

#: ../docs/ecosystem/huggingface.md:65
msgid "Datasets"
msgstr ""

#: ../docs/ecosystem/huggingface.md:67
msgid ""
"The Hugging Face Hub has lots of great [datasets](https://huggingface.co/"
"datasets) that can be used to evaluate your LLM chains."
msgstr ""

#: ../docs/ecosystem/huggingface.md:69
msgid ""
"For a detailed walkthrough of how to use them to do so, see [this notebook]"
"(../use_cases/evaluation/huggingface_datasets.ipynb)"
msgstr ""

#: ../docs/ecosystem/jina.md:1
msgid "Jina"
msgstr ""

#: ../docs/ecosystem/jina.md:3
msgid ""
"This page covers how to use the Jina ecosystem within LangChain. It is "
"broken into two parts: installation and setup, and then references to "
"specific Jina wrappers."
msgstr ""

#: ../docs/ecosystem/jina.md:7
msgid "Install the Python SDK with `pip install jina`"
msgstr ""

#: ../docs/ecosystem/jina.md:8
msgid ""
"Get a Jina AI Cloud auth token from [here](https://cloud.jina.ai/settings/"
"tokens) and set it as an environment variable (`JINA_AUTH_TOKEN`)"
msgstr ""

#: ../docs/ecosystem/jina.md:14
msgid "There exists a Jina Embeddings wrapper, which you can access with"
msgstr ""

#: ../docs/ecosystem/jina.md:18
msgid ""
"For a more detailed walkthrough of this, see [this notebook](../modules/"
"models/text_embedding/examples/jina.ipynb)"
msgstr ""

#: ../docs/ecosystem/llamacpp.md:1
msgid "Llama.cpp"
msgstr ""

#: ../docs/ecosystem/llamacpp.md:3
msgid ""
"This page covers how to use [llama.cpp](https://github.com/ggerganov/llama."
"cpp) within LangChain. It is broken into two parts: installation and setup, "
"and then references to specific Llama-cpp wrappers."
msgstr ""

#: ../docs/ecosystem/llamacpp.md:7
msgid "Install the Python package with `pip install llama-cpp-python`"
msgstr ""

#: ../docs/ecosystem/llamacpp.md:8
msgid ""
"Download one of the [supported models](https://github.com/ggerganov/llama."
"cpp#description) and convert them to the llama.cpp format per the "
"[instructions](https://github.com/ggerganov/llama.cpp)"
msgstr ""

#: ../docs/ecosystem/llamacpp.md:14
msgid "There exists a LlamaCpp LLM wrapper, which you can access with"
msgstr ""

#: ../docs/ecosystem/llamacpp.md:18
msgid ""
"For a more detailed walkthrough of this, see [this notebook](../modules/"
"models/llms/integrations/llamacpp.ipynb)"
msgstr ""

#: ../docs/ecosystem/llamacpp.md:22
msgid "There exists a LlamaCpp Embeddings wrapper, which you can access with"
msgstr ""

#: ../docs/ecosystem/llamacpp.md:26
msgid ""
"For a more detailed walkthrough of this, see [this notebook](../modules/"
"models/text_embedding/examples/llamacpp.ipynb)"
msgstr ""

#: ../docs/ecosystem/metal.md:1 ../docs/ecosystem/metal.md:9
msgid "Metal"
msgstr ""

#: ../docs/ecosystem/metal.md:3
msgid ""
"This page covers how to use [Metal](https://getmetal.io) within LangChain."
msgstr ""

#: ../docs/ecosystem/metal.md:5
msgid "What is Metal?"
msgstr ""

#: ../docs/ecosystem/metal.md:7
msgid ""
"Metal is a  managed retrieval & memory platform built for production. Easily "
"index your data into `Metal` and run semantic search and retrieval on it."
msgstr ""

#: ../docs/ecosystem/metal.md:9
msgid "![Metal](../_static/MetalDash.png)"
msgstr ""

#: ../docs/ecosystem/metal.md:13
msgid ""
"Get started by [creating a Metal account](https://app.getmetal.io/signup)."
msgstr ""

#: ../docs/ecosystem/metal.md:15
msgid ""
"Then, you can easily take advantage of the `MetalRetriever` class to start "
"retrieving your data for semantic search, prompting context, etc. This class "
"takes a `Metal` instance and a dictionary of parameters to pass to the Metal "
"API."
msgstr ""

#: ../docs/ecosystem/milvus.md:1
msgid "Milvus"
msgstr ""

#: ../docs/ecosystem/milvus.md:3
msgid ""
"This page covers how to use the Milvus ecosystem within LangChain. It is "
"broken into two parts: installation and setup, and then references to "
"specific Milvus wrappers."
msgstr ""

#: ../docs/ecosystem/milvus.md:7 ../docs/ecosystem/zilliz.md:8
msgid "Install the Python SDK with `pip install pymilvus`"
msgstr ""

#: ../docs/ecosystem/milvus.md:12
msgid ""
"There exists a wrapper around Milvus indexes, allowing you to use it as a "
"vectorstore, whether for semantic search or example selection."
msgstr ""

#: ../docs/ecosystem/milvus.md:20
msgid ""
"For a more detailed walkthrough of the Miluvs wrapper, see [this notebook]"
"(../modules/indexes/vectorstores/examples/milvus.ipynb)"
msgstr ""

#: ../docs/ecosystem/modal.md:1
msgid "Modal"
msgstr ""

#: ../docs/ecosystem/modal.md:3
msgid ""
"This page covers how to use the Modal ecosystem within LangChain. It is "
"broken into two parts: installation and setup, and then references to "
"specific Modal wrappers."
msgstr ""

#: ../docs/ecosystem/modal.md:7
msgid "Install with `pip install modal-client`"
msgstr ""

#: ../docs/ecosystem/modal.md:8
msgid "Run `modal token new`"
msgstr ""

#: ../docs/ecosystem/modal.md:10
msgid "Define your Modal Functions and Webhooks"
msgstr ""

#: ../docs/ecosystem/modal.md:12
msgid "You must include a prompt. There is a rigid response structure."
msgstr ""

#: ../docs/ecosystem/modal.md:23
msgid "An example with GPT2:"
msgstr ""

#: ../docs/ecosystem/modal.md:63
msgid "There exists an Modal LLM wrapper, which you can access with"
msgstr ""

#: ../docs/ecosystem/myscale.md:1
msgid "MyScale"
msgstr ""

#: ../docs/ecosystem/myscale.md:3
msgid ""
"This page covers how to use MyScale vector database within LangChain. It is "
"broken into two parts: installation and setup, and then references to "
"specific MyScale wrappers."
msgstr ""

#: ../docs/ecosystem/myscale.md:6
msgid ""
"With MyScale, you can manage both structured and unstructured (vectorized) "
"data, and perform joint queries and analytics on both types of data using "
"SQL. Plus, MyScale's cloud-native OLAP architecture, built on top of "
"ClickHouse, enables lightning-fast data processing even on massive datasets."
msgstr ""

#: ../docs/ecosystem/myscale.md:8
msgid "Introduction"
msgstr ""

#: ../docs/ecosystem/myscale.md:10
msgid ""
"[Overview to MyScale and High performance vector search](https://docs."
"myscale.com/en/overview/)"
msgstr ""

#: ../docs/ecosystem/myscale.md:12
msgid ""
"You can now register on our SaaS and [start a cluster now!](https://docs."
"myscale.com/en/quickstart/)"
msgstr ""

#: ../docs/ecosystem/myscale.md:14
msgid ""
"If you are also interested in how we managed to integrate SQL and vector, "
"please refer to [this document](https://docs.myscale.com/en/vector-"
"reference/) for further syntax reference."
msgstr ""

#: ../docs/ecosystem/myscale.md:16
msgid ""
"We also deliver with live demo on huggingface! Please checkout our "
"[huggingface space](https://huggingface.co/myscale)! They search millions of "
"vector within a blink!"
msgstr ""

#: ../docs/ecosystem/myscale.md:19
msgid "Install the Python SDK with `pip install clickhouse-connect`"
msgstr ""

#: ../docs/ecosystem/myscale.md:21
msgid "Setting up envrionments"
msgstr ""

#: ../docs/ecosystem/myscale.md:23
msgid "There are two ways to set up parameters for myscale index."
msgstr ""

#: ../docs/ecosystem/myscale.md:25
msgid "Environment Variables"
msgstr ""

#: ../docs/ecosystem/myscale.md:27
msgid ""
"Before you run the app, please set the environment variable with `export`:  "
"`export MYSCALE_URL='<your-endpoints-url>' MYSCALE_PORT=<your-endpoints-"
"port> MYSCALE_USERNAME=<your-username> MYSCALE_PASSWORD=<your-password> ...`"
msgstr ""

#: ../docs/ecosystem/myscale.md:30
msgid ""
"You can easily find your account, password and other info on our SaaS. For "
"details please refer to [this document](https://docs.myscale.com/en/cluster-"
"management/)  Every attributes under `MyScaleSettings` can be set with "
"prefix `MYSCALE_` and is case insensitive."
msgstr ""

#: ../docs/ecosystem/myscale.md:33
msgid "Create `MyScaleSettings` object with parameters"
msgstr ""

#: ../docs/ecosystem/myscale.md:44
msgid "supported functions:"
msgstr ""

#: ../docs/ecosystem/myscale.md:45
msgid "`add_texts`"
msgstr ""

#: ../docs/ecosystem/myscale.md:46
msgid "`add_documents`"
msgstr ""

#: ../docs/ecosystem/myscale.md:47
msgid "`from_texts`"
msgstr ""

#: ../docs/ecosystem/myscale.md:48
msgid "`from_documents`"
msgstr ""

#: ../docs/ecosystem/myscale.md:49
msgid "`similarity_search`"
msgstr ""

#: ../docs/ecosystem/myscale.md:50
msgid "`asimilarity_search`"
msgstr ""

#: ../docs/ecosystem/myscale.md:51
msgid "`similarity_search_by_vector`"
msgstr ""

#: ../docs/ecosystem/myscale.md:52
msgid "`asimilarity_search_by_vector`"
msgstr ""

#: ../docs/ecosystem/myscale.md:53
msgid "`similarity_search_with_relevance_scores`"
msgstr ""

#: ../docs/ecosystem/myscale.md:57
msgid ""
"There exists a wrapper around MyScale database, allowing you to use it as a "
"vectorstore, whether for semantic search or similar example retrieval."
msgstr ""

#: ../docs/ecosystem/myscale.md:65
msgid ""
"For a more detailed walkthrough of the MyScale wrapper, see [this notebook]"
"(../modules/indexes/vectorstores/examples/myscale.ipynb)"
msgstr ""

#: ../docs/ecosystem/nlpcloud.md:1
msgid "NLPCloud"
msgstr ""

#: ../docs/ecosystem/nlpcloud.md:3
msgid ""
"This page covers how to use the NLPCloud ecosystem within LangChain. It is "
"broken into two parts: installation and setup, and then references to "
"specific NLPCloud wrappers."
msgstr ""

#: ../docs/ecosystem/nlpcloud.md:7
msgid "Install the Python SDK with `pip install nlpcloud`"
msgstr ""

#: ../docs/ecosystem/nlpcloud.md:8
msgid ""
"Get an NLPCloud api key and set it as an environment variable "
"(`NLPCLOUD_API_KEY`)"
msgstr ""

#: ../docs/ecosystem/nlpcloud.md:14
msgid "There exists an NLPCloud LLM wrapper, which you can access with"
msgstr ""

#: ../docs/ecosystem/openai.md:1
msgid "OpenAI"
msgstr ""

#: ../docs/ecosystem/openai.md:3
msgid ""
"This page covers how to use the OpenAI ecosystem within LangChain. It is "
"broken into two parts: installation and setup, and then references to "
"specific OpenAI wrappers."
msgstr ""

#: ../docs/ecosystem/openai.md:8
msgid ""
"Get an OpenAI api key and set it as an environment variable "
"(`OPENAI_API_KEY`)"
msgstr ""

#: ../docs/ecosystem/openai.md:9
msgid ""
"If you want to use OpenAI's tokenizer (only available for Python 3.9+), "
"install it with `pip install tiktoken`"
msgstr ""

#: ../docs/ecosystem/openai.md:15
msgid "There exists an OpenAI LLM wrapper, which you can access with"
msgstr ""

#: ../docs/ecosystem/openai.md:20
msgid ""
"If you are using a model hosted on Azure, you should use different wrapper "
"for that:"
msgstr ""

#: ../docs/ecosystem/openai.md:24
msgid ""
"For a more detailed walkthrough of the Azure wrapper, see [this notebook](../"
"modules/models/llms/integrations/azure_openai_example.ipynb)"
msgstr ""

#: ../docs/ecosystem/openai.md:30
msgid "There exists an OpenAI Embeddings wrapper, which you can access with"
msgstr ""

#: ../docs/ecosystem/openai.md:34
msgid ""
"For a more detailed walkthrough of this, see [this notebook](../modules/"
"models/text_embedding/examples/openai.ipynb)"
msgstr ""

#: ../docs/ecosystem/openai.md:39
msgid ""
"There are several places you can use the `tiktoken` tokenizer. By default, "
"it is used to count tokens for OpenAI LLMs."
msgstr ""

#: ../docs/ecosystem/openai.md:47
msgid ""
"For a more detailed walkthrough of this, see [this notebook](../modules/"
"indexes/text_splitters/examples/tiktoken.ipynb)"
msgstr ""

#: ../docs/ecosystem/openai.md:49
msgid "Moderation"
msgstr ""

#: ../docs/ecosystem/openai.md:50
msgid "You can also access the OpenAI content moderation endpoint with"
msgstr ""

#: ../docs/ecosystem/openai.md:55
msgid ""
"For a more detailed walkthrough of this, see [this notebook](../modules/"
"chains/examples/moderation.ipynb)"
msgstr ""

#: ../docs/ecosystem/opensearch.md:1
msgid "OpenSearch"
msgstr ""

#: ../docs/ecosystem/opensearch.md:3
msgid ""
"This page covers how to use the OpenSearch ecosystem within LangChain. It is "
"broken into two parts: installation and setup, and then references to "
"specific OpenSearch wrappers."
msgstr ""

#: ../docs/ecosystem/opensearch.md:7
msgid "Install the Python package with `pip install opensearch-py`"
msgstr ""

#: ../docs/ecosystem/opensearch.md:12
msgid ""
"There exists a wrapper around OpenSearch vector databases, allowing you to "
"use it as a vectorstore  for semantic search using approximate vector search "
"powered by lucene, nmslib and faiss engines  or using painless scripting and "
"script scoring functions for bruteforce vector search."
msgstr ""

#: ../docs/ecosystem/opensearch.md:21
msgid ""
"For a more detailed walkthrough of the OpenSearch wrapper, see [this "
"notebook](../modules/indexes/vectorstores/examples/opensearch.ipynb)"
msgstr ""

#: ../docs/ecosystem/petals.md:1
msgid "Petals"
msgstr ""

#: ../docs/ecosystem/petals.md:3
msgid ""
"This page covers how to use the Petals ecosystem within LangChain. It is "
"broken into two parts: installation and setup, and then references to "
"specific Petals wrappers."
msgstr ""

#: ../docs/ecosystem/petals.md:7
msgid "Install with `pip install petals`"
msgstr ""

#: ../docs/ecosystem/petals.md:8
msgid ""
"Get a Hugging Face api key and set it as an environment variable "
"(`HUGGINGFACE_API_KEY`)"
msgstr ""

#: ../docs/ecosystem/petals.md:14
msgid "There exists an Petals LLM wrapper, which you can access with"
msgstr ""

#: ../docs/ecosystem/pgvector.md:1
msgid "PGVector"
msgstr ""

#: ../docs/ecosystem/pgvector.md:3
msgid ""
"This page covers how to use the Postgres [PGVector](https://github.com/"
"pgvector/pgvector) ecosystem within LangChain It is broken into two parts: "
"installation and setup, and then references to specific PGVector wrappers."
msgstr ""

#: ../docs/ecosystem/pgvector.md:6 ../docs/getting_started/getting_started.md:6
#: ../docs/reference/installation.md:1 ../docs/tracing/hosted_installation.md:7
#: ../docs/tracing/local_installation.md:5
msgid "Installation"
msgstr ""

#: ../docs/ecosystem/pgvector.md:7
msgid "Install the Python package with `pip install pgvector`"
msgstr ""

#: ../docs/ecosystem/pgvector.md:11
msgid ""
"The first step is to create a database with the `pgvector` extension "
"installed."
msgstr ""

#: ../docs/ecosystem/pgvector.md:13
msgid ""
"Follow the steps at [PGVector Installation Steps](https://github.com/"
"pgvector/pgvector#installation) to install the database and the extension. "
"The docker image is the easiest way to get started."
msgstr ""

#: ../docs/ecosystem/pgvector.md:19
msgid ""
"There exists a wrapper around Postgres vector databases, allowing you to use "
"it as a vectorstore, whether for semantic search or example selection."
msgstr ""

#: ../docs/ecosystem/pgvector.md:29
msgid ""
"For a more detailed walkthrough of the PGVector Wrapper, see [this notebook]"
"(../modules/indexes/vectorstores/examples/pgvector.ipynb)"
msgstr ""

#: ../docs/ecosystem/pinecone.md:1
msgid "Pinecone"
msgstr ""

#: ../docs/ecosystem/pinecone.md:3
msgid ""
"This page covers how to use the Pinecone ecosystem within LangChain. It is "
"broken into two parts: installation and setup, and then references to "
"specific Pinecone wrappers."
msgstr ""

#: ../docs/ecosystem/pinecone.md:7
msgid "Install the Python SDK with `pip install pinecone-client`"
msgstr ""

#: ../docs/ecosystem/pinecone.md:12
msgid ""
"There exists a wrapper around Pinecone indexes, allowing you to use it as a "
"vectorstore, whether for semantic search or example selection."
msgstr ""

#: ../docs/ecosystem/pinecone.md:20
msgid ""
"For a more detailed walkthrough of the Pinecone wrapper, see [this notebook]"
"(../modules/indexes/vectorstores/examples/pinecone.ipynb)"
msgstr ""

#: ../docs/ecosystem/predictionguard.md:1
msgid "Prediction Guard"
msgstr ""

#: ../docs/ecosystem/predictionguard.md:3
msgid ""
"This page covers how to use the Prediction Guard ecosystem within LangChain. "
"It is broken into two parts: installation and setup, and then references to "
"specific Prediction Guard wrappers."
msgstr ""

#: ../docs/ecosystem/predictionguard.md:7
msgid "Install the Python SDK with `pip install predictionguard`"
msgstr ""

#: ../docs/ecosystem/predictionguard.md:8
msgid ""
"Get an Prediction Guard access token (as described [here](https://docs."
"predictionguard.com/)) and set it as an environment variable "
"(`PREDICTIONGUARD_TOKEN`)"
msgstr ""

#: ../docs/ecosystem/predictionguard.md:10
msgid "LLM Wrapper"
msgstr ""

#: ../docs/ecosystem/predictionguard.md:12
msgid "There exists a Prediction Guard LLM wrapper, which you can access with"
msgstr ""

#: ../docs/ecosystem/predictionguard.md:17
msgid ""
"You can provide the name of your Prediction Guard \"proxy\" as an argument "
"when initializing the LLM:"
msgstr ""

#: ../docs/ecosystem/predictionguard.md:22
msgid ""
"Alternatively, you can use Prediction Guard's default proxy for SOTA LLMs:"
msgstr ""

#: ../docs/ecosystem/predictionguard.md:27
msgid "You can also provide your access token directly as an argument:"
msgstr ""

#: ../docs/ecosystem/predictionguard.md:32
msgid "Example usage"
msgstr ""

#: ../docs/ecosystem/predictionguard.md:34
msgid "Basic usage of the LLM wrapper:"
msgstr ""

#: ../docs/ecosystem/predictionguard.md:42
msgid "Basic LLM Chaining with the Prediction Guard wrapper:"
msgstr ""

#: ../docs/ecosystem/promptlayer.md:1
msgid "PromptLayer"
msgstr ""

#: ../docs/ecosystem/promptlayer.md:3
msgid ""
"This page covers how to use [PromptLayer](https://www.promptlayer.com) "
"within LangChain. It is broken into two parts: installation and setup, and "
"then references to specific PromptLayer wrappers."
msgstr ""

#: ../docs/ecosystem/promptlayer.md:8
msgid "If you want to work with PromptLayer:"
msgstr ""

#: ../docs/ecosystem/promptlayer.md:9
msgid "Install the promptlayer python library `pip install promptlayer`"
msgstr ""

#: ../docs/ecosystem/promptlayer.md:10
msgid "Create a PromptLayer account"
msgstr ""

#: ../docs/ecosystem/promptlayer.md:11
msgid ""
"Create an api token and set it as an environment variable "
"(`PROMPTLAYER_API_KEY`)"
msgstr ""

#: ../docs/ecosystem/promptlayer.md:17
msgid ""
"There exists an PromptLayer OpenAI LLM wrapper, which you can access with"
msgstr ""

#: ../docs/ecosystem/promptlayer.md:22
msgid ""
"To tag your requests, use the argument `pl_tags` when instanializing the LLM"
msgstr ""

#: ../docs/ecosystem/promptlayer.md:28
msgid ""
"To get the PromptLayer request id, use the argument `return_pl_id` when "
"instanializing the LLM"
msgstr ""

#: ../docs/ecosystem/promptlayer.md:33
msgid ""
"This will add the PromptLayer request ID in the `generation_info` field of "
"the `Generation` returned when using `.generate` or `.agenerate`"
msgstr ""

#: ../docs/ecosystem/promptlayer.md:35
msgid "For example:"
msgstr ""

#: ../docs/ecosystem/promptlayer.md:41
msgid ""
"You can use the PromptLayer request ID to add a prompt, score, or other "
"metadata to your request. [Read more about it here](https://magniv.notion."
"site/Track-4deee1b1f7a34c1680d085f82567dab9)."
msgstr ""

#: ../docs/ecosystem/promptlayer.md:43
msgid "This LLM is identical to the [OpenAI LLM](./openai.md), except that"
msgstr ""

#: ../docs/ecosystem/promptlayer.md:44
msgid "all your requests will be logged to your PromptLayer account"
msgstr ""

#: ../docs/ecosystem/promptlayer.md:45
msgid ""
"you can add `pl_tags` when instantializing to tag your requests on "
"PromptLayer"
msgstr ""

#: ../docs/ecosystem/promptlayer.md:46
msgid ""
"you can add `return_pl_id` when instantializing to return a PromptLayer "
"request id to use [while tracking requests](https://magniv.notion.site/"
"Track-4deee1b1f7a34c1680d085f82567dab9)."
msgstr ""

#: ../docs/ecosystem/promptlayer.md:49
msgid ""
"PromptLayer also provides native wrappers for [`PromptLayerChatOpenAI`](../"
"modules/models/chat/integrations/promptlayer_chatopenai.ipynb) and "
"`PromptLayerOpenAIChat`"
msgstr ""

#: ../docs/ecosystem/qdrant.md:1
msgid "Qdrant"
msgstr ""

#: ../docs/ecosystem/qdrant.md:3
msgid ""
"This page covers how to use the Qdrant ecosystem within LangChain. It is "
"broken into two parts: installation and setup, and then references to "
"specific Qdrant wrappers."
msgstr ""

#: ../docs/ecosystem/qdrant.md:7
msgid "Install the Python SDK with `pip install qdrant-client`"
msgstr ""

#: ../docs/ecosystem/qdrant.md:12
msgid ""
"There exists a wrapper around Qdrant indexes, allowing you to use it as a "
"vectorstore, whether for semantic search or example selection."
msgstr ""

#: ../docs/ecosystem/qdrant.md:20
msgid ""
"For a more detailed walkthrough of the Qdrant wrapper, see [this notebook]"
"(../modules/indexes/vectorstores/examples/qdrant.ipynb)"
msgstr ""

#: ../docs/ecosystem/replicate.md:1
msgid "Replicate"
msgstr ""

#: ../docs/ecosystem/replicate.md:2
msgid "This page covers how to run models on Replicate within LangChain."
msgstr ""

#: ../docs/ecosystem/replicate.md:5
msgid ""
"Create a [Replicate](https://replicate.com) account. Get your API key and "
"set it as an environment variable (`REPLICATE_API_TOKEN`)"
msgstr ""

#: ../docs/ecosystem/replicate.md:6
msgid ""
"Install the [Replicate python client](https://github.com/replicate/replicate-"
"python) with `pip install replicate`"
msgstr ""

#: ../docs/ecosystem/replicate.md:8
msgid "Calling a model"
msgstr ""

#: ../docs/ecosystem/replicate.md:10
msgid ""
"Find a model on the [Replicate explore page](https://replicate.com/explore), "
"and then paste in the model name and version in this format: `owner-name/"
"model-name:version`"
msgstr ""

#: ../docs/ecosystem/replicate.md:12
msgid ""
"For example, for this [dolly model](https://replicate.com/replicate/dolly-"
"v2-12b), click on the API tab. The model name/version would be: `\"replicate/"
"dolly-v2-12b:"
"ef0e1aefc61f8e096ebe4db6b2bacc297daf2ef6899f0f7e001ec445893500e5\"`"
msgstr ""

#: ../docs/ecosystem/replicate.md:14
msgid ""
"Only the `model` param is required, but any other model parameters can also "
"be passed in with the format `input={model_param: value, ...}`"
msgstr ""

#: ../docs/ecosystem/replicate.md:17
msgid ""
"For example, if we were running stable diffusion and wanted to change the "
"image dimensions:"
msgstr ""

#: ../docs/ecosystem/replicate.md:23
msgid ""
"*Note that only the first output of a model will be returned.* From here, we "
"can initialize our model:"
msgstr ""

#: ../docs/ecosystem/replicate.md:30
msgid "And run it:"
msgstr ""

#: ../docs/ecosystem/replicate.md:40
msgid ""
"We can call any Replicate model (not just LLMs) using this syntax. For "
"example, we can call [Stable Diffusion](https://replicate.com/stability-ai/"
"stable-diffusion):"
msgstr ""

#: ../docs/ecosystem/runhouse.md:1
msgid "Runhouse"
msgstr ""

#: ../docs/ecosystem/runhouse.md:3
msgid ""
"This page covers how to use the [Runhouse](https://github.com/run-house/"
"runhouse) ecosystem within LangChain. It is broken into three parts: "
"installation and setup, LLMs, and Embeddings."
msgstr ""

#: ../docs/ecosystem/runhouse.md:7
msgid "Install the Python SDK with `pip install runhouse`"
msgstr ""

#: ../docs/ecosystem/runhouse.md:8
msgid ""
"If you'd like to use on-demand cluster, check your cloud credentials with "
"`sky check`"
msgstr ""

#: ../docs/ecosystem/runhouse.md:10
msgid "Self-hosted LLMs"
msgstr ""

#: ../docs/ecosystem/runhouse.md:11
msgid ""
"For a basic self-hosted LLM, you can use the `SelfHostedHuggingFaceLLM` "
"class. For more custom LLMs, you can use the `SelfHostedPipeline` parent "
"class."
msgstr ""

#: ../docs/ecosystem/runhouse.md:18
msgid ""
"For a more detailed walkthrough of the Self-hosted LLMs, see [this notebook]"
"(../modules/models/llms/integrations/runhouse.ipynb)"
msgstr ""

#: ../docs/ecosystem/runhouse.md:20
msgid "Self-hosted Embeddings"
msgstr ""

#: ../docs/ecosystem/runhouse.md:21
msgid ""
"There are several ways to use self-hosted embeddings with LangChain via "
"Runhouse."
msgstr ""

#: ../docs/ecosystem/runhouse.md:23
msgid ""
"For a basic self-hosted embedding from a Hugging Face Transformers model, "
"you can use  the `SelfHostedEmbedding` class."
msgstr ""

#: ../docs/ecosystem/runhouse.md:29
msgid ""
"For a more detailed walkthrough of the Self-hosted Embeddings, see [this "
"notebook](../modules/models/text_embedding/examples/self-hosted.ipynb)"
msgstr ""

#: ../docs/ecosystem/rwkv.md:1
msgid "RWKV-4"
msgstr ""

#: ../docs/ecosystem/rwkv.md:3
msgid ""
"This page covers how to use the `RWKV-4` wrapper within LangChain. It is "
"broken into two parts: installation and setup, and then usage with an "
"example."
msgstr ""

#: ../docs/ecosystem/rwkv.md:7
msgid "Install the Python package with `pip install rwkv`"
msgstr ""

#: ../docs/ecosystem/rwkv.md:8
msgid "Install the tokenizer Python package with `pip install tokenizer`"
msgstr ""

#: ../docs/ecosystem/rwkv.md:9
msgid ""
"Download a [RWKV model](https://huggingface.co/BlinkDL/rwkv-4-raven/tree/"
"main) and place it in your desired directory"
msgstr ""

#: ../docs/ecosystem/rwkv.md:10
msgid ""
"Download the [tokens file](https://raw.githubusercontent.com/BlinkDL/"
"ChatRWKV/main/20B_tokenizer.json)"
msgstr ""

#: ../docs/ecosystem/rwkv.md:14
msgid "RWKV"
msgstr ""

#: ../docs/ecosystem/rwkv.md:16
msgid ""
"To use the RWKV wrapper, you need to provide the path to the pre-trained "
"model file and the tokenizer's configuration."
msgstr ""

#: ../docs/ecosystem/rwkv.md:51
msgid ""
"You can find links to model file downloads at the [RWKV-4-Raven](https://"
"huggingface.co/BlinkDL/rwkv-4-raven/tree/main) repository."
msgstr ""

#: ../docs/ecosystem/rwkv.md:53
msgid "Rwkv-4 models -> recommended VRAM"
msgstr ""

#: ../docs/ecosystem/rwkv.md:65
msgid ""
"See the [rwkv pip](https://pypi.org/project/rwkv/) page for more information "
"about strategies, including streaming and cuda support."
msgstr ""

#: ../docs/ecosystem/searx.md:1
msgid "SearxNG Search API"
msgstr ""

#: ../docs/ecosystem/searx.md:3
msgid ""
"This page covers how to use the SearxNG search API within LangChain. It is "
"broken into two parts: installation and setup, and then references to the "
"specific SearxNG API wrapper."
msgstr ""

#: ../docs/ecosystem/searx.md:8
msgid ""
"While it is possible to utilize the wrapper in conjunction with  [public "
"searx instances](https://searx.space/) these instances frequently do not "
"permit API access (see note on output format below) and have limitations on "
"the frequency of requests. It is recommended to opt for a self-hosted "
"instance instead."
msgstr ""

#: ../docs/ecosystem/searx.md:13
msgid "Self Hosted Instance:"
msgstr ""

#: ../docs/ecosystem/searx.md:15
msgid ""
"See [this page](https://searxng.github.io/searxng/admin/installation.html) "
"for installation instructions."
msgstr ""

#: ../docs/ecosystem/searx.md:17
msgid ""
"When you install SearxNG, the only active output format by default is the "
"HTML format. You need to activate the `json` format to use the API. This can "
"be done by adding the following line to the `settings.yml` file:"
msgstr ""

#: ../docs/ecosystem/searx.md:25
msgid ""
"You can make sure that the API is working by issuing a curl request to the "
"API endpoint:"
msgstr ""

#: ../docs/ecosystem/searx.md:27
msgid ""
"`curl -kLX GET --data-urlencode q='langchain' -d format=json http://"
"localhost:8888`"
msgstr ""

#: ../docs/ecosystem/searx.md:29
msgid "This should return a JSON object with the results."
msgstr ""

#: ../docs/ecosystem/searx.md:36
msgid ""
"To use the wrapper we need to pass the host of the SearxNG instance to the "
"wrapper with:     1. the named parameter `searx_host` when creating the "
"instance.     2. exporting the environment variable `SEARXNG_HOST`."
msgstr ""

#: ../docs/ecosystem/searx.md:40
msgid "You can use the wrapper to get results from a SearxNG instance."
msgstr ""

#: ../docs/ecosystem/searx.md:50
msgid "You can also load this wrapper as a Tool (to use with an Agent)."
msgstr ""

#: ../docs/ecosystem/searx.md:52
msgid "You can do this with:"
msgstr ""

#: ../docs/ecosystem/searx.md:61
msgid "Note that we could _optionally_ pass custom engines to use."
msgstr ""

#: ../docs/ecosystem/searx.md:63
msgid "If you want to obtain results with metadata as *json* you can use:"
msgstr ""

#: ../docs/ecosystem/searx.md:70
msgid ""
"For more information on tools, see [this page](../modules/agents/tools/"
"getting_started.md)"
msgstr ""

#: ../docs/ecosystem/serpapi.md:1 ../docs/reference/modules/serpapi.rst:2
msgid "SerpAPI"
msgstr ""

#: ../docs/ecosystem/serpapi.md:3
msgid ""
"This page covers how to use the SerpAPI search APIs within LangChain. It is "
"broken into two parts: installation and setup, and then references to the "
"specific SerpAPI wrapper."
msgstr ""

#: ../docs/ecosystem/serpapi.md:7 ../docs/reference/integrations.md:31
msgid "Install requirements with `pip install google-search-results`"
msgstr ""

#: ../docs/ecosystem/serpapi.md:8
msgid ""
"Get a SerpAPI api key and either set it as an environment variable "
"(`SERPAPI_API_KEY`)"
msgstr ""

#: ../docs/ecosystem/serpapi.md:14
msgid ""
"There exists a SerpAPI utility which wraps this API. To import this utility:"
msgstr ""

#: ../docs/ecosystem/serpapi.md:20
msgid ""
"For a more detailed walkthrough of this wrapper, see [this notebook](../"
"modules/agents/tools/examples/serpapi.ipynb)."
msgstr ""

#: ../docs/ecosystem/stochasticai.md:1
msgid "StochasticAI"
msgstr ""

#: ../docs/ecosystem/stochasticai.md:3
msgid ""
"This page covers how to use the StochasticAI ecosystem within LangChain. It "
"is broken into two parts: installation and setup, and then references to "
"specific StochasticAI wrappers."
msgstr ""

#: ../docs/ecosystem/stochasticai.md:7
msgid "Install with `pip install stochasticx`"
msgstr ""

#: ../docs/ecosystem/stochasticai.md:8
msgid ""
"Get an StochasticAI api key and set it as an environment variable "
"(`STOCHASTICAI_API_KEY`)"
msgstr ""

#: ../docs/ecosystem/stochasticai.md:14
msgid "There exists an StochasticAI LLM wrapper, which you can access with"
msgstr ""

#: ../docs/ecosystem/unstructured.md:1
msgid "Unstructured"
msgstr ""

#: ../docs/ecosystem/unstructured.md:3
msgid ""
"This page covers how to use the [`unstructured`](https://github.com/"
"Unstructured-IO/unstructured) ecosystem within LangChain. The `unstructured` "
"package from [Unstructured.IO](https://www.unstructured.io/) extracts clean "
"text from raw source documents like PDFs and Word documents."
msgstr ""

#: ../docs/ecosystem/unstructured.md:9
msgid ""
"This page is broken into two parts: installation and setup, and then "
"references to specific `unstructured` wrappers."
msgstr ""

#: ../docs/ecosystem/unstructured.md:13
msgid ""
"Install the Python SDK with `pip install \"unstructured[local-inference]\"`"
msgstr ""

#: ../docs/ecosystem/unstructured.md:14
msgid ""
"Install the following system dependencies if they are not already available "
"on your system. Depending on what document types you're parsing, you may not "
"need all of these."
msgstr ""

#: ../docs/ecosystem/unstructured.md:16
msgid "`libmagic-dev` (filetype detection)"
msgstr ""

#: ../docs/ecosystem/unstructured.md:17
msgid "`poppler-utils` (images and PDFs)"
msgstr ""

#: ../docs/ecosystem/unstructured.md:18
msgid "`tesseract-ocr`(images and PDFs)"
msgstr ""

#: ../docs/ecosystem/unstructured.md:19
msgid "`libreoffice` (MS Office docs)"
msgstr ""

#: ../docs/ecosystem/unstructured.md:20
msgid "`pandoc` (EPUBs)"
msgstr ""

#: ../docs/ecosystem/unstructured.md:21
msgid ""
"If you are parsing PDFs using the `\"hi_res\"` strategy, run the following "
"to install the `detectron2` model, which `unstructured` uses for layout "
"detection:"
msgstr ""

#: ../docs/ecosystem/unstructured.md:23
msgid ""
"`pip install \"detectron2@git+https://github.com/facebookresearch/detectron2."
"git@e2ce8dc#egg=detectron2\"`"
msgstr ""

#: ../docs/ecosystem/unstructured.md:24
msgid ""
"If `detectron2` is not installed, `unstructured` will fallback to processing "
"PDFs using the `\"fast\"` strategy, which uses `pdfminer` directly and "
"doesn't require `detectron2`."
msgstr ""

#: ../docs/ecosystem/unstructured.md:30
msgid "Data Loaders"
msgstr ""

#: ../docs/ecosystem/unstructured.md:32
msgid ""
"The primary `unstructured` wrappers within `langchain` are data loaders. The "
"following shows how to use the most basic unstructured data loader. There "
"are other file-specific data loaders available in the `langchain."
"document_loaders` module."
msgstr ""

#: ../docs/ecosystem/unstructured.md:43
msgid ""
"If you instantiate the loader with `UnstructuredFileLoader(mode=\"elements"
"\")`, the loader will track additional metadata like the page number and "
"text type (i.e. title, narrative text) when that information is available."
msgstr ""

#: ../docs/ecosystem/wandb_tracking.ipynb:10002
msgid "Weights & Biases"
msgstr ""

#: ../docs/ecosystem/wandb_tracking.ipynb:10004
msgid ""
"This notebook goes over how to track your LangChain experiments into one "
"centralized Weights and Biases dashboard. To learn more about prompt "
"engineering and the callback please refer to this Report which explains both "
"alongside the resultant dashboards you can expect to see."
msgstr ""

#: ../docs/ecosystem/wandb_tracking.ipynb:10006
msgid ""
"Run in Colab: https://colab.research.google.com/"
"drive/1DXH4beT4HFaRKy_Vm4PoxhXVDRf7Ym8L?usp=sharing"
msgstr ""

#: ../docs/ecosystem/wandb_tracking.ipynb:10008
msgid ""
"View Report: https://wandb.ai/a-sh0ts/langchain_callback_demo/reports/Prompt-"
"Engineering-LLMs-with-LangChain-and-W-B--VmlldzozNjk1NTUw#ðŸ‘‹-how-to-build-a-"
"callback-in-langchain-for-better-prompt-engineering"
msgstr ""

#: ../docs/ecosystem/wandb_tracking.ipynb:70002
msgid ""
"NOTE: For beta workflows we have made the default analysis based on textstat "
"and the visualizations based on spacy"
msgstr ""

#: ../docs/ecosystem/wandb_tracking.ipynb:100002
msgid ""
"The `flush_tracker` function is used to log LangChain sessions to Weights & "
"Biases. It takes in the LangChain module or agent, and logs at minimum the "
"prompts and generations alongside the serialized form of the LangChain "
"module to the specified Weights & Biases project. By default we reset the "
"session as opposed to concluding the session outright."
msgstr ""

#: ../docs/ecosystem/weaviate.md:1
msgid "Weaviate"
msgstr ""

#: ../docs/ecosystem/weaviate.md:3
msgid "This page covers how to use the Weaviate ecosystem within LangChain."
msgstr ""

#: ../docs/ecosystem/weaviate.md:5
msgid "What is Weaviate?"
msgstr ""

#: ../docs/ecosystem/weaviate.md:7
msgid "**Weaviate in a nutshell:**"
msgstr ""

#: ../docs/ecosystem/weaviate.md:8
msgid "Weaviate is an open-source â€‹database of the type â€‹vector search engine."
msgstr ""

#: ../docs/ecosystem/weaviate.md:9
msgid ""
"Weaviate allows you to store JSON documents in a class property-like fashion "
"while attaching machine learning vectors to these documents to represent "
"them in vector space."
msgstr ""

#: ../docs/ecosystem/weaviate.md:10
msgid ""
"Weaviate can be used stand-alone (aka bring your vectors) or with a variety "
"of modules that can do the vectorization for you and extend the core "
"capabilities."
msgstr ""

#: ../docs/ecosystem/weaviate.md:11
msgid "Weaviate has a GraphQL-API to access your data easily."
msgstr ""

#: ../docs/ecosystem/weaviate.md:12
msgid ""
"We aim to bring your vector search set up to production to query in mere "
"milliseconds (check our [open source benchmarks](https://weaviate.io/"
"developers/weaviate/current/benchmarks/) to see if Weaviate fits your use "
"case)."
msgstr ""

#: ../docs/ecosystem/weaviate.md:13
msgid ""
"Get to know Weaviate in the [basics getting started guide](https://weaviate."
"io/developers/weaviate/current/core-knowledge/basics.html) in under five "
"minutes."
msgstr ""

#: ../docs/ecosystem/weaviate.md:15
msgid "**Weaviate in detail:**"
msgstr ""

#: ../docs/ecosystem/weaviate.md:17
msgid ""
"Weaviate is a low-latency vector search engine with out-of-the-box support "
"for different media types (text, images, etc.). It offers Semantic Search, "
"Question-Answer Extraction, Classification, Customizable Models (PyTorch/"
"TensorFlow/Keras), etc. Built from scratch in Go, Weaviate stores both "
"objects and vectors, allowing for combining vector search with structured "
"filtering and the fault tolerance of a cloud-native database. It is all "
"accessible through GraphQL, REST, and various client-side programming "
"languages."
msgstr ""

#: ../docs/ecosystem/weaviate.md:20
msgid "Install the Python SDK with `pip install weaviate-client`"
msgstr ""

#: ../docs/ecosystem/weaviate.md:25
msgid ""
"There exists a wrapper around Weaviate indexes, allowing you to use it as a "
"vectorstore, whether for semantic search or example selection."
msgstr ""

#: ../docs/ecosystem/weaviate.md:33
msgid ""
"For a more detailed walkthrough of the Weaviate wrapper, see [this notebook]"
"(../modules/indexes/vectorstores/examples/weaviate.ipynb)"
msgstr ""

#: ../docs/ecosystem/wolfram_alpha.md:1
msgid "Wolfram Alpha Wrapper"
msgstr ""

#: ../docs/ecosystem/wolfram_alpha.md:3
msgid ""
"This page covers how to use the Wolfram Alpha API within LangChain. It is "
"broken into two parts: installation and setup, and then references to "
"specific Wolfram Alpha wrappers."
msgstr ""

#: ../docs/ecosystem/wolfram_alpha.md:7 ../docs/reference/integrations.md:37
msgid "Install requirements with `pip install wolframalpha`"
msgstr ""

#: ../docs/ecosystem/wolfram_alpha.md:8
msgid ""
"Go to wolfram alpha and sign up for a developer account [here](https://"
"developer.wolframalpha.com/)"
msgstr ""

#: ../docs/ecosystem/wolfram_alpha.md:9
msgid "Create an app and get your APP ID"
msgstr ""

#: ../docs/ecosystem/wolfram_alpha.md:10
msgid "Set your APP ID as an environment variable `WOLFRAM_ALPHA_APPID`"
msgstr ""

#: ../docs/ecosystem/wolfram_alpha.md:17
msgid ""
"There exists a WolframAlphaAPIWrapper utility which wraps this API. To "
"import this utility:"
msgstr ""

#: ../docs/ecosystem/wolfram_alpha.md:23
msgid ""
"For a more detailed walkthrough of this wrapper, see [this notebook](../"
"modules/agents/tools/examples/wolfram_alpha.ipynb)."
msgstr ""

#: ../docs/ecosystem/writer.md:1
msgid "Writer"
msgstr ""

#: ../docs/ecosystem/writer.md:3
msgid ""
"This page covers how to use the Writer ecosystem within LangChain. It is "
"broken into two parts: installation and setup, and then references to "
"specific Writer wrappers."
msgstr ""

#: ../docs/ecosystem/writer.md:7
msgid ""
"Get an Writer api key and set it as an environment variable "
"(`WRITER_API_KEY`)"
msgstr ""

#: ../docs/ecosystem/writer.md:13
msgid "There exists an Writer LLM wrapper, which you can access with"
msgstr ""

#: ../docs/ecosystem/yeagerai.md:1
msgid "Yeager.ai"
msgstr ""

#: ../docs/ecosystem/yeagerai.md:3
msgid ""
"This page covers how to use [Yeager.ai](https://yeager.ai) to generate "
"LangChain tools and agents."
msgstr ""

#: ../docs/ecosystem/yeagerai.md:5
msgid "What is Yeager.ai?"
msgstr ""

#: ../docs/ecosystem/yeagerai.md:6
msgid ""
"Yeager.ai is an ecosystem designed to simplify the process of creating AI "
"agents and tools."
msgstr ""

#: ../docs/ecosystem/yeagerai.md:8
msgid ""
"It features yAgents, a No-code LangChain Agent Builder, which enables users "
"to build, test, and deploy AI solutions with ease. Leveraging the LangChain "
"framework, yAgents allows seamless integration with various language models "
"and resources, making it suitable for developers, researchers, and AI "
"enthusiasts across diverse applications."
msgstr ""

#: ../docs/ecosystem/yeagerai.md:10
msgid "yAgents"
msgstr ""

#: ../docs/ecosystem/yeagerai.md:11
msgid ""
"Low code generative agent designed to help you build, prototype, and deploy "
"Langchain tools with ease."
msgstr ""

#: ../docs/ecosystem/yeagerai.md:13
msgid "How to use?"
msgstr ""

#: ../docs/ecosystem/yeagerai.md:18
msgid "Go to http://127.0.0.1:7860"
msgstr ""

#: ../docs/ecosystem/yeagerai.md:20
msgid ""
"This will install the necessary dependencies and set up yAgents on your "
"system. After the first run, yAgents will create a .env file where you can "
"input your OpenAI API key. You can do the same directly from the Gradio "
"interface under the tab \"Settings\"."
msgstr ""

#: ../docs/ecosystem/yeagerai.md:22
msgid "`OPENAI_API_KEY=<your_openai_api_key_here>`"
msgstr ""

#: ../docs/ecosystem/yeagerai.md:24
msgid ""
"We recommend using GPT-4,. However, the tool can also work with GPT-3 if the "
"problem is broken down sufficiently."
msgstr ""

#: ../docs/ecosystem/yeagerai.md:26
msgid "Creating and Executing Tools with yAgents"
msgstr ""

#: ../docs/ecosystem/yeagerai.md:27
msgid ""
"yAgents makes it easy to create and execute AI-powered tools. Here's a brief "
"overview of the process:"
msgstr ""

#: ../docs/ecosystem/yeagerai.md:28
msgid ""
"Create a tool: To create a tool, provide a natural language prompt to "
"yAgents. The prompt should clearly describe the tool's purpose and "
"functionality. For example: `create a tool that returns the n-th prime "
"number`"
msgstr ""

#: ../docs/ecosystem/yeagerai.md:31
msgid ""
"Load the tool into the toolkit: To load a tool into yAgents, simply provide "
"a command to yAgents that says so. For example: `load the tool that you just "
"created it into your toolkit`"
msgstr ""

#: ../docs/ecosystem/yeagerai.md:34
msgid ""
"Execute the tool: To run a tool or agent, simply provide a command to "
"yAgents that includes the name of the tool and any required parameters. For "
"example: `generate the 50th prime number`"
msgstr ""

#: ../docs/ecosystem/yeagerai.md:37
msgid ""
"You can see a video of how it works [here](https://www.youtube.com/watch?"
"v=KA5hCM3RaWE)."
msgstr ""

#: ../docs/ecosystem/yeagerai.md:39
msgid ""
"As you become more familiar with yAgents, you can create more advanced tools "
"and agents to automate your work and enhance your productivity."
msgstr ""

#: ../docs/ecosystem/yeagerai.md:41
msgid ""
"For more information, see [yAgents' Github](https://github.com/yeagerai/"
"yeagerai-agent) or our [docs](https://yeagerai.gitbook.io/docs/general/"
"welcome-to-yeager.ai)"
msgstr ""

#: ../docs/ecosystem/zilliz.md:1
msgid "Zilliz"
msgstr ""

#: ../docs/ecosystem/zilliz.md:3
msgid ""
"This page covers how to use the Zilliz Cloud ecosystem within LangChain. "
"Zilliz uses the Milvus integration.  It is broken into two parts: "
"installation and setup, and then references to specific Milvus wrappers."
msgstr ""

#: ../docs/ecosystem/zilliz.md:13
msgid ""
"There exists a wrapper around Zilliz indexes, allowing you to use it as a "
"vectorstore, whether for semantic search or example selection."
msgstr ""

#: ../docs/ecosystem/zilliz.md:21
msgid ""
"For a more detailed walkthrough of the Miluvs wrapper, see [this notebook]"
"(../modules/indexes/vectorstores/examples/zilliz.ipynb)"
msgstr ""

#: ../docs/gallery.rst:2
msgid "LangChain Gallery"
msgstr ""

#: ../docs/gallery.rst:4
msgid ""
"Lots of people have built some pretty awesome stuff with LangChain. This is "
"a collection of our favorites. If you see any other demos that you think we "
"should highlight, be sure to let us know!"
msgstr ""

#: ../docs/gallery.rst:10
msgid "Open Source"
msgstr ""

#: ../docs/gallery.rst:24
msgid ""
"This is an experiment in building a large-language-model-backed chatbot. It "
"can hold a conversation, remember previous comments/questions, and answer "
"all types of queries (history, web search, movie data, weather, news, and "
"more)."
msgstr ""

#: ../docs/gallery.rst:36
msgid ""
"An end-to-end example of doing question answering on YouTube transcripts, "
"returning the timestamps as sources to legitimize the answer."
msgstr ""

#: ../docs/gallery.rst:47
msgid ""
"This application is a Slack Bot that uses Langchain and OpenAI's GPT3 "
"language model to provide domain specific answers. You provide the documents."
msgstr ""

#: ../docs/gallery.rst:58
msgid ""
"A central, open resource and community around data and tools related to "
"chain-of-thought reasoning in large language models."
msgstr ""

#: ../docs/gallery.rst:69
msgid ""
"This Python package adds a decorator llm_strategy that connects to an LLM "
"(such as OpenAIâ€™s GPT-3) and uses the LLM to \"implement\" abstract methods "
"in interface classes. It does this by forwarding requests to the LLM and "
"converting the responses back to Python data using Python's @dataclasses."
msgstr ""

#: ../docs/gallery.rst:80
msgid ""
"A notebook showing how to use GPT to help with the work of a corporate "
"lobbyist."
msgstr ""

#: ../docs/gallery.rst:91
msgid ""
"A jupyter notebook demonstrating how you could create a semantic search "
"engine on documents in one of your Google Folders"
msgstr ""

#: ../docs/gallery.rst:102
msgid "Build a GitHub support bot with GPT3, LangChain, and Python."
msgstr ""

#: ../docs/gallery.rst:113
msgid ""
"Record sounds of anything (birds, wind, fire, train station) and chat with "
"it."
msgstr ""

#: ../docs/gallery.rst:124
msgid ""
"This simple application demonstrates a conversational agent implemented with "
"OpenAI GPT-3.5 and LangChain. When necessary, it leverages tools for complex "
"math, searching the internet, and accessing news and weather."
msgstr ""

#: ../docs/gallery.rst:135
msgid ""
"A Hugging Face spaces project showing off the benefits of using PAL for math "
"problems."
msgstr ""

#: ../docs/gallery.rst:146
msgid "Measure the political compass of GPT."
msgstr ""

#: ../docs/gallery.rst:157
msgid ""
"Open source GitHub project shows how to use LangChain to create a chatbot "
"that can answer questions about an arbitrary Notion database."
msgstr ""

#: ../docs/gallery.rst:168
msgid ""
"LlamaIndex (formerly GPT Index) is a project consisting of a set of data "
"structures that are created using GPT-3 and can be traversed using GPT-3 in "
"order to answer queries."
msgstr ""

#: ../docs/gallery.rst:179
msgid ""
"Leveraging Qiskit, OpenAI and LangChain to demonstrate Grover's algorithm"
msgstr ""

#: ../docs/gallery.rst:190
msgid ""
"A chat UI to play Nim, where a player can select an opponent, either a "
"quantum computer or an AI"
msgstr ""

#: ../docs/gallery.rst:201
msgid "Leveraging the ReActTextWorldAgent to play TextWorld with an LLM!"
msgstr ""

#: ../docs/gallery.rst:212
msgid ""
"This repo is a simple demonstration of using LangChain to do fact-checking "
"with prompt chaining."
msgstr ""

#: ../docs/gallery.rst:223
msgid "Answer questions about the documentation of any project"
msgstr ""

#: ../docs/gallery.rst:226
msgid "Misc. Colab Notebooks"
msgstr ""

#: ../docs/gallery.rst:240
msgid "Give ChatGPT a WolframAlpha neural implant"
msgstr ""

#: ../docs/gallery.rst:251
msgid "Agent improvements (6th Jan 2023)"
msgstr ""

#: ../docs/gallery.rst:262
msgid "Langchain AGI (23rd Dec 2022)"
msgstr ""

#: ../docs/gallery.rst:265
msgid "Proprietary"
msgstr ""

#: ../docs/gallery.rst:279
msgid "A chat-based AI personal assistant with long-term memory about you."
msgstr ""

#: ../docs/gallery.rst:290
msgid ""
"Summarize not only long docs, interview audio or video files quickly, but "
"also entire websites and YouTube videos. Share or download your generated "
"summaries to collaborate with others, or revisit them at any time! Bonus: "
"`@anysummary <https://twitter.com/anysummary>`_ on Twitter will also "
"summarize any thread it is tagged in."
msgstr ""

#: ../docs/gallery.rst:301
msgid ""
"An app to write SQL using natural language, and execute against real DB."
msgstr ""

#: ../docs/gallery.rst:312
msgid ""
"Stack Tracing QA Bot to help debug complex stack tracing (especially the "
"ones that go multi-function/file deep)."
msgstr ""

#: ../docs/gallery.rst:323
msgid ""
"By Raza Habib, this demo utilizes LangChain + SerpAPI + HumanLoop to write "
"sales emails. Give it a company name and a person, this application will use "
"Google Search (via SerpAPI) to get more information on the company and the "
"person, and then write them a sales message."
msgstr ""

#: ../docs/gallery.rst:334
msgid ""
"By Zahid Khawaja, this demo utilizes question answering to answer questions "
"about a given website. A followup added this for `YouTube videos <https://"
"twitter.com/chillzaza_/status/1593739682013220865?s=20&t=EhU8jl0KyCPJ7vE9Rnz-"
"cQ>`_, and then another followup added it for `Wikipedia <https://twitter."
"com/chillzaza_/status/1594847151238037505?s=20&t=EhU8jl0KyCPJ7vE9Rnz-cQ>`_."
msgstr ""

#: ../docs/gallery.rst:345
msgid ""
"A journaling app for self-care that uses AI to uncover insights and patterns "
"over time."
msgstr ""

#: ../docs/getting_started/getting_started.md:1
msgid "Quickstart Guide"
msgstr ""

#: ../docs/getting_started/getting_started.md:4
msgid ""
"This tutorial gives you a quick walkthrough about building an end-to-end "
"language model application with LangChain."
msgstr ""

#: ../docs/getting_started/getting_started.md:8
msgid "To get started, install LangChain with the following command:"
msgstr ""

#: ../docs/getting_started/getting_started.md:17
#: ../docs/tracing/hosted_installation.md:11
#: ../docs/tracing/local_installation.md:23
msgid "Environment Setup"
msgstr ""

#: ../docs/getting_started/getting_started.md:19
msgid ""
"Using LangChain will usually require integrations with one or more model "
"providers, data stores, apis, etc."
msgstr ""

#: ../docs/getting_started/getting_started.md:21
msgid ""
"For this example, we will be using OpenAI's APIs, so we will first need to "
"install their SDK:"
msgstr ""

#: ../docs/getting_started/getting_started.md:27
msgid "We will then need to set the environment variable in the terminal."
msgstr ""

#: ../docs/getting_started/getting_started.md:33
msgid ""
"Alternatively, you could do this from inside the Jupyter notebook (or Python "
"script):"
msgstr ""

#: ../docs/getting_started/getting_started.md:41
msgid "Building a Language Model Application: LLMs"
msgstr ""

#: ../docs/getting_started/getting_started.md:43
msgid ""
"Now that we have installed LangChain and set up our environment, we can "
"start building our language model application."
msgstr ""

#: ../docs/getting_started/getting_started.md:45
msgid ""
"LangChain provides many modules that can be used to build language model "
"applications. Modules can be combined to create more complex applications, "
"or be used individually for simple applications."
msgstr ""

#: ../docs/getting_started/getting_started.md:49
msgid "LLMs: Get predictions from a language model"
msgstr ""

#: ../docs/getting_started/getting_started.md:51
msgid ""
"The most basic building block of LangChain is calling an LLM on some input. "
"Let's walk through a simple example of how to do this.  For this purpose, "
"let's pretend we are building a service that generates a company name based "
"on what the company makes."
msgstr ""

#: ../docs/getting_started/getting_started.md:55
msgid "In order to do this, we first need to import the LLM wrapper."
msgstr ""

#: ../docs/getting_started/getting_started.md:61
msgid ""
"We can then initialize the wrapper with any arguments. In this example, we "
"probably want the outputs to be MORE random, so we'll initialize it with a "
"HIGH temperature."
msgstr ""

#: ../docs/getting_started/getting_started.md:68
msgid "We can now call it on some input!"
msgstr ""

#: ../docs/getting_started/getting_started.md:79
msgid ""
"For more details on how to use LLMs within LangChain, see the [LLM getting "
"started guide](../modules/models/llms/getting_started.ipynb)."
msgstr ""

#: ../docs/getting_started/getting_started.md:82
msgid "Prompt Templates: Manage prompts for LLMs"
msgstr ""

#: ../docs/getting_started/getting_started.md:84
msgid ""
"Calling an LLM is a great first step, but it's just the beginning. Normally "
"when you use an LLM in an application, you are not sending user input "
"directly to the LLM. Instead, you are probably taking user input and "
"constructing a prompt, and then sending that to the LLM."
msgstr ""

#: ../docs/getting_started/getting_started.md:88
msgid ""
"For example, in the previous example, the text we passed in was hardcoded to "
"ask for a name for a company that made colorful socks. In this imaginary "
"service, what we would want to do is take only the user input describing "
"what the company does, and then format the prompt with that information."
msgstr ""

#: ../docs/getting_started/getting_started.md:91
msgid "This is easy to do with LangChain!"
msgstr ""

#: ../docs/getting_started/getting_started.md:93
msgid "First lets define the prompt template:"
msgstr ""

#: ../docs/getting_started/getting_started.md:104
msgid ""
"Let's now see how this works! We can call the `.format` method to format it."
msgstr ""

#: ../docs/getting_started/getting_started.md:115
msgid ""
"[For more details, check out the getting started guide for prompts.](../"
"modules/prompts/chat_prompt_template.ipynb)"
msgstr ""

#: ../docs/getting_started/getting_started.md:120
msgid "Chains: Combine LLMs and prompts in multi-step workflows"
msgstr ""

#: ../docs/getting_started/getting_started.md:122
msgid ""
"Up until now, we've worked with the PromptTemplate and LLM primitives by "
"themselves. But of course, a real application is not just one primitive, but "
"rather a combination of them."
msgstr ""

#: ../docs/getting_started/getting_started.md:124
msgid ""
"A chain in LangChain is made up of links, which can be either primitives "
"like LLMs or other chains."
msgstr ""

#: ../docs/getting_started/getting_started.md:126
msgid ""
"The most core type of chain is an LLMChain, which consists of a "
"PromptTemplate and an LLM."
msgstr ""

#: ../docs/getting_started/getting_started.md:128
msgid ""
"Extending the previous example, we can construct an LLMChain which takes "
"user input, formats it with a PromptTemplate, and then passes the formatted "
"response to an LLM."
msgstr ""

#: ../docs/getting_started/getting_started.md:141
msgid ""
"We can now create a very simple chain that will take user input, format the "
"prompt with it, and then send it to the LLM:"
msgstr ""

#: ../docs/getting_started/getting_started.md:148
msgid "Now we can run that chain only specifying the product!"
msgstr ""

#: ../docs/getting_started/getting_started.md:155
msgid ""
"There we go! There's the first chain - an LLM Chain. This is one of the "
"simpler types of chains, but understanding how it works will set you up well "
"for working with more complex chains."
msgstr ""

#: ../docs/getting_started/getting_started.md:158
msgid ""
"[For more details, check out the getting started guide for chains.](../"
"modules/chains/getting_started.ipynb)"
msgstr ""

#: ../docs/getting_started/getting_started.md:160
msgid "Agents: Dynamically Call Chains Based on User Input"
msgstr ""

#: ../docs/getting_started/getting_started.md:162
msgid "So far the chains we've looked at run in a predetermined order."
msgstr ""

#: ../docs/getting_started/getting_started.md:164
msgid ""
"Agents no longer do: they use an LLM to determine which actions to take and "
"in what order. An action can either be using a tool and observing its "
"output, or returning to the user."
msgstr ""

#: ../docs/getting_started/getting_started.md:166
msgid ""
"When used correctly agents can be extremely powerful. In this tutorial, we "
"show you how to easily use agents through the simplest, highest level API."
msgstr ""

#: ../docs/getting_started/getting_started.md:169
msgid "In order to load agents, you should understand the following concepts:"
msgstr ""

#: ../docs/getting_started/getting_started.md:171
msgid ""
"Tool: A function that performs a specific duty. This can be things like: "
"Google Search, Database lookup, Python REPL, other chains. The interface for "
"a tool is currently a function that is expected to have a string as an "
"input, with a string as an output."
msgstr ""

#: ../docs/getting_started/getting_started.md:172
msgid "LLM: The language model powering the agent."
msgstr ""

#: ../docs/getting_started/getting_started.md:173
msgid ""
"Agent: The agent to use. This should be a string that references a support "
"agent class. Because this notebook focuses on the simplest, highest level "
"API, this only covers using the standard supported agents. If you want to "
"implement a custom agent, see the documentation for custom agents (coming "
"soon)."
msgstr ""

#: ../docs/getting_started/getting_started.md:175
msgid ""
"**Agents**: For a list of supported agents and their specifications, see "
"[here](../modules/agents/agents.md)."
msgstr ""

#: ../docs/getting_started/getting_started.md:177
msgid ""
"**Tools**: For a list of predefined tools and their specifications, see "
"[here](../modules/agents/tools.md)."
msgstr ""

#: ../docs/getting_started/getting_started.md:179
msgid ""
"For this example, you will also need to install the SerpAPI Python package."
msgstr ""

#: ../docs/getting_started/getting_started.md:185
msgid "And set the appropriate environment variables."
msgstr ""

#: ../docs/getting_started/getting_started.md:192
msgid "Now we can get started!"
msgstr ""

#: ../docs/getting_started/getting_started.md:233
#: ../docs/getting_started/getting_started.md:460
msgid "Memory: Add State to Chains and Agents"
msgstr ""

#: ../docs/getting_started/getting_started.md:235
msgid ""
"So far, all the chains and agents we've gone through have been stateless. "
"But often, you may want a chain or agent to have some concept of \"memory\" "
"so that it may remember information about its previous interactions. The "
"clearest and simple example of this is when designing a chatbot - you want "
"it to remember previous messages so it can use context from that to have a "
"better conversation. This would be a type of \"short-term memory\". On the "
"more complex side, you could imagine a chain/agent remembering key pieces of "
"information over time - this would be a form of \"long-term memory\". For "
"more concrete ideas on the latter, see this [awesome paper](https://"
"memprompt.com/)."
msgstr ""

#: ../docs/getting_started/getting_started.md:237
msgid ""
"LangChain provides several specially created chains just for this purpose. "
"This notebook walks through using one of those chains (the "
"`ConversationChain`) with two different types of memory."
msgstr ""

#: ../docs/getting_started/getting_started.md:239
msgid ""
"By default, the `ConversationChain` has a simple type of memory that "
"remembers all previous inputs/outputs and adds them to the context that is "
"passed. Let's take a look at using this chain (setting `verbose=True` so we "
"can see the prompt)."
msgstr ""

#: ../docs/getting_started/getting_started.md:286
msgid "Building a Language Model Application: Chat Models"
msgstr ""

#: ../docs/getting_started/getting_started.md:288
msgid ""
"Similarly, you can use chat models instead of LLMs. Chat models are a "
"variation on language models. While chat models use language models under "
"the hood, the interface they expose is a bit different: rather than expose a "
"\"text in, text out\" API, they expose an interface where \"chat messages\" "
"are the inputs and outputs."
msgstr ""

#: ../docs/getting_started/getting_started.md:290
msgid ""
"Chat model APIs are fairly new, so we are still figuring out the correct "
"abstractions."
msgstr ""

#: ../docs/getting_started/getting_started.md:292
msgid "Get Message Completions from a Chat Model"
msgstr ""

#: ../docs/getting_started/getting_started.md:294
msgid ""
"You can get chat completions by passing one or more messages to the chat "
"model. The response will be a message. The types of messages currently "
"supported in LangChain are `AIMessage`, `HumanMessage`, `SystemMessage`, and "
"`ChatMessage` -- `ChatMessage` takes in an arbitrary role parameter. Most of "
"the time, you'll just be dealing with `HumanMessage`, `AIMessage`, and "
"`SystemMessage`."
msgstr ""

#: ../docs/getting_started/getting_started.md:307
msgid "You can get completions by passing in a single message."
msgstr ""

#: ../docs/getting_started/getting_started.md:314
msgid ""
"You can also pass in multiple messages for OpenAI's gpt-3.5-turbo and gpt-4 "
"models."
msgstr ""

#: ../docs/getting_started/getting_started.md:325
msgid ""
"You can go one step further and generate completions for multiple sets of "
"messages using `generate`. This returns an `LLMResult` with an additional "
"`message` parameter:"
msgstr ""

#: ../docs/getting_started/getting_started.md:342
msgid "You can recover things like token usage from this LLMResult:"
msgstr ""

#: ../docs/getting_started/getting_started.md:349
msgid "Chat Prompt Templates"
msgstr ""

#: ../docs/getting_started/getting_started.md:350
msgid ""
"Similar to LLMs, you can make use of templating by using a "
"`MessagePromptTemplate`. You can build a `ChatPromptTemplate` from one or "
"more `MessagePromptTemplate`s. You can use `ChatPromptTemplate`'s "
"`format_prompt` -- this returns a `PromptValue`, which you can convert to a "
"string or `Message` object, depending on whether you want to use the "
"formatted value as input to an llm or chat model."
msgstr ""

#: ../docs/getting_started/getting_started.md:352
msgid ""
"For convience, there is a `from_template` method exposed on the template. If "
"you were to use this template, this is what it would look like:"
msgstr ""

#: ../docs/getting_started/getting_started.md:376
msgid "Chains with Chat Models"
msgstr ""

#: ../docs/getting_started/getting_started.md:377
msgid ""
"The `LLMChain` discussed in the above section can be used with chat models "
"as well:"
msgstr ""

#: ../docs/getting_started/getting_started.md:401
msgid "Agents with Chat Models"
msgstr ""

#: ../docs/getting_started/getting_started.md:402
msgid ""
"Agents can also be used with chat models, you can initialize one using "
"`AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION` as the agent type."
msgstr ""

#: ../docs/getting_started/getting_started.md:461
msgid ""
"You can use Memory with chains and agents initialized with chat models. The "
"main difference between this and Memory for LLMs is that rather than trying "
"to condense all previous messages into a string, we can keep them as their "
"own unique memory object."
msgstr ""

#: ../docs/glossary.md:1
msgid "Glossary"
msgstr ""

#: ../docs/glossary.md:3
msgid ""
"This is a collection of terminology commonly used when developing LLM "
"applications. It contains reference to external papers or sources where the "
"concept was first introduced, as well as to places in LangChain where the "
"concept is used."
msgstr ""

#: ../docs/glossary.md:7
msgid "Chain of Thought Prompting"
msgstr ""

#: ../docs/glossary.md:9
msgid ""
"A prompting technique used to encourage the model to generate a series of "
"intermediate reasoning steps. A less formal way to induce this behavior is "
"to include â€œLetâ€™s think step-by-stepâ€ in the prompt."
msgstr ""

#: ../docs/glossary.md:12 ../docs/glossary.md:22 ../docs/glossary.md:32
#: ../docs/glossary.md:42 ../docs/glossary.md:51 ../docs/glossary.md:62
#: ../docs/glossary.md:71 ../docs/glossary.md:80 ../docs/glossary.md:88
msgid "Resources:"
msgstr ""

#: ../docs/glossary.md:14
msgid "[Chain-of-Thought Paper](https://arxiv.org/pdf/2201.11903.pdf)"
msgstr ""

#: ../docs/glossary.md:15
msgid "[Step-by-Step Paper](https://arxiv.org/abs/2112.00114)"
msgstr ""

#: ../docs/glossary.md:17
msgid "Action Plan Generation"
msgstr ""

#: ../docs/glossary.md:19
msgid ""
"A prompt usage that uses a language model to generate actions to take. The "
"results of these actions can then be fed back into the language model to "
"generate a subsequent action."
msgstr ""

#: ../docs/glossary.md:24
msgid "[WebGPT Paper](https://arxiv.org/pdf/2112.09332.pdf)"
msgstr ""

#: ../docs/glossary.md:25
msgid "[SayCan Paper](https://say-can.github.io/assets/palm_saycan.pdf)"
msgstr ""

#: ../docs/glossary.md:27
msgid "ReAct Prompting"
msgstr ""

#: ../docs/glossary.md:29
msgid ""
"A prompting technique that combines Chain-of-Thought prompting with action "
"plan generation. This induces the to model to think about what action to "
"take, then take it."
msgstr ""

#: ../docs/glossary.md:34
msgid "[Paper](https://arxiv.org/pdf/2210.03629.pdf)"
msgstr ""

#: ../docs/glossary.md:35
msgid "[LangChain Example](modules/agents/agents/examples/react.ipynb)"
msgstr ""

#: ../docs/glossary.md:37
msgid "Self-ask"
msgstr ""

#: ../docs/glossary.md:39
msgid ""
"A prompting method that builds on top of chain-of-thought prompting. In this "
"method, the model explicitly asks itself follow-up questions, which are then "
"answered by an external search engine."
msgstr ""

#: ../docs/glossary.md:44
msgid "[Paper](https://ofir.io/self-ask.pdf)"
msgstr ""

#: ../docs/glossary.md:45
msgid ""
"[LangChain Example](modules/agents/agents/examples/self_ask_with_search."
"ipynb)"
msgstr ""

#: ../docs/glossary.md:47
msgid "Prompt Chaining"
msgstr ""

#: ../docs/glossary.md:49
msgid ""
"Combining multiple LLM calls together, with the output of one-step being the "
"input to the next."
msgstr ""

#: ../docs/glossary.md:53
msgid "[PromptChainer Paper](https://arxiv.org/pdf/2203.06566.pdf)"
msgstr ""

#: ../docs/glossary.md:54
msgid "[Language Model Cascades](https://arxiv.org/abs/2207.10342)"
msgstr ""

#: ../docs/glossary.md:55
msgid "[ICE Primer Book](https://primer.ought.org/)"
msgstr ""

#: ../docs/glossary.md:56
msgid "[Socratic Models](https://socraticmodels.github.io/)"
msgstr ""

#: ../docs/glossary.md:58
msgid "Memetic Proxy"
msgstr ""

#: ../docs/glossary.md:60
msgid ""
"Encouraging the LLM to respond in a certain way framing the discussion in a "
"context that the model knows of and that will result in that type of "
"response. For example, as a conversation between a student and a teacher."
msgstr ""

#: ../docs/glossary.md:64
msgid "[Paper](https://arxiv.org/pdf/2102.07350.pdf)"
msgstr ""

#: ../docs/glossary.md:66
msgid "Self Consistency"
msgstr ""

#: ../docs/glossary.md:68
msgid ""
"A decoding strategy that samples a diverse set of reasoning paths and then "
"selects the most consistent answer. Is most effective when combined with "
"Chain-of-thought prompting."
msgstr ""

#: ../docs/glossary.md:73
msgid "[Paper](https://arxiv.org/pdf/2203.11171.pdf)"
msgstr ""

#: ../docs/glossary.md:75
msgid "Inception"
msgstr ""

#: ../docs/glossary.md:77
msgid ""
"Also called â€œFirst Person Instructionâ€. Encouraging the model to think a "
"certain way by including the start of the modelâ€™s response in the prompt."
msgstr ""

#: ../docs/glossary.md:82
msgid ""
"[Example](https://twitter.com/goodside/status/1583262455207460865?"
"s=20&t=8Hz7XBnK1OF8siQrxxCIGQ)"
msgstr ""

#: ../docs/glossary.md:84
msgid "MemPrompt"
msgstr ""

#: ../docs/glossary.md:86
msgid ""
"MemPrompt maintains a memory of errors and user feedback, and uses them to "
"prevent repetition of mistakes."
msgstr ""

#: ../docs/glossary.md:90
msgid "[Paper](https://memprompt.com/)"
msgstr ""

#: ../docs/index.rst:20 ../docs/index.rst:14
msgid "Getting Started"
msgstr ""

#: ../docs/index.rst:48 ../docs/index.rst:29
msgid "Modules"
msgstr ""

#: ../docs/index.rst:89 ../docs/index.rst:62
msgid "Use Cases"
msgstr ""

#: ../docs/index.rst:115
msgid "Reference"
msgstr ""

#: ../docs/index.rst:133
msgid "Ecosystem"
msgstr ""

#: ../docs/index.rst:167
msgid "LangChainHub"
msgstr ""

#: ../docs/index.rst:167
msgid "Discord"
msgstr ""

#: ../docs/index.rst:167
msgid "Production Support"
msgstr ""

#: ../docs/index.rst:167 ../docs/index.rst:144
msgid "Additional Resources"
msgstr ""

#: ../docs/index.rst:2
msgid "Welcome to LangChain"
msgstr ""

#: ../docs/index.rst:4
msgid ""
"LangChain is a framework for developing applications powered by language "
"models. We believe that the most powerful and differentiated applications "
"will not only call out to a language model via an API, but will also:"
msgstr ""

#: ../docs/index.rst:6
msgid "*Be data-aware*: connect a language model to other sources of data"
msgstr ""

#: ../docs/index.rst:7
msgid "*Be agentic*: allow a language model to interact with its environment"
msgstr ""

#: ../docs/index.rst:9
msgid "The LangChain framework is designed with the above principles in mind."
msgstr ""

#: ../docs/index.rst:11
msgid ""
"This is the Python specific portion of the documentation. For a purely "
"conceptual guide to LangChain, see `here <https://docs.langchain.com/docs/"
">`_. For the JavaScript documentation, see `here <https://js.langchain.com/"
"docs/>`_."
msgstr ""

#: ../docs/index.rst:16
msgid ""
"Checkout the below guide for a walkthrough of how to get started using "
"LangChain to create an Language Model application."
msgstr ""

#: ../docs/index.rst:18
msgid ""
"`Getting Started Documentation <./getting_started/getting_started.html>`_"
msgstr ""

#: ../docs/index.rst:31
msgid ""
"There are several main modules that LangChain provides support for. For each "
"module we provide some examples to get started, how-to guides, reference "
"docs, and conceptual guides. These modules are, in increasing order of "
"complexity:"
msgstr ""

#: ../docs/index.rst:35
msgid ""
"`Models <./modules/models.html>`_: The various model types and model "
"integrations LangChain supports."
msgstr ""

#: ../docs/index.rst:37
msgid ""
"`Prompts <./modules/prompts.html>`_: This includes prompt management, prompt "
"optimization, and prompt serialization."
msgstr ""

#: ../docs/index.rst:39
msgid ""
"`Memory <./modules/memory.html>`_: Memory is the concept of persisting state "
"between calls of a chain/agent. LangChain provides a standard interface for "
"memory, a collection of memory implementations, and examples of chains/"
"agents that use memory."
msgstr ""

#: ../docs/index.rst:41
msgid ""
"`Indexes <./modules/indexes.html>`_: Language models are often more powerful "
"when combined with your own text data - this module covers best practices "
"for doing exactly that."
msgstr ""

#: ../docs/index.rst:43
msgid ""
"`Chains <./modules/chains.html>`_: Chains go beyond just a single LLM call, "
"and are sequences of calls (whether to an LLM or a different utility). "
"LangChain provides a standard interface for chains, lots of integrations "
"with other tools, and end-to-end chains for common applications."
msgstr ""

#: ../docs/index.rst:45
msgid ""
"`Agents <./modules/agents.html>`_: Agents involve an LLM making decisions "
"about which Actions to take, taking that Action, seeing an Observation, and "
"repeating that until done. LangChain provides a standard interface for "
"agents, a selection of agents to choose from, and examples of end to end "
"agents."
msgstr ""

#: ../docs/index.rst:64
msgid ""
"The above modules can be used in a variety of ways. LangChain also provides "
"guidance and assistance in this. Below are some of the common use cases "
"LangChain supports."
msgstr ""

#: ../docs/index.rst:66
msgid ""
"`Autonomous Agents <./use_cases/autonomous_agents.html>`_: Autonomous agents "
"are long running agents that take many steps in an attempt to accomplish an "
"objective. Examples include AutoGPT and BabyAGI."
msgstr ""

#: ../docs/index.rst:68
msgid ""
"`Agent Simulations <./use_cases/agent_simulations.html>`_: Putting agents in "
"a sandbox and observing how they interact with each other or to events can "
"be an interesting way to observe their long-term memory abilities."
msgstr ""

#: ../docs/index.rst:70
msgid ""
"`Personal Assistants <./use_cases/personal_assistants.html>`_: The main "
"LangChain use case. Personal assistants need to take actions, remember "
"interactions, and have knowledge about your data."
msgstr ""

#: ../docs/index.rst:72
msgid ""
"`Question Answering <./use_cases/question_answering.html>`_: The second big "
"LangChain use case. Answering questions over specific documents, only "
"utilizing the information in those documents to construct an answer."
msgstr ""

#: ../docs/index.rst:74
msgid ""
"`Chatbots <./use_cases/chatbots.html>`_: Since language models are good at "
"producing text, that makes them ideal for creating chatbots."
msgstr ""

#: ../docs/index.rst:76
msgid ""
"`Querying Tabular Data <./use_cases/tabular.html>`_: If you want to "
"understand how to use LLMs to query data that is stored in a tabular format "
"(csvs, SQL, dataframes, etc) you should read this page."
msgstr ""

#: ../docs/index.rst:78
msgid ""
"`Code Understanding <./use_cases/code.html>`_: If you want to understand how "
"to use LLMs to query source code from github, you should read this page."
msgstr ""

#: ../docs/index.rst:80
msgid ""
"`Interacting with APIs <./use_cases/apis.html>`_: Enabling LLMs to interact "
"with APIs is extremely powerful in order to give them more up-to-date "
"information and allow them to take actions."
msgstr ""

#: ../docs/index.rst:82
msgid ""
"`Extraction <./use_cases/extraction.html>`_: Extract structured information "
"from text."
msgstr ""

#: ../docs/index.rst:84
msgid ""
"`Summarization <./use_cases/summarization.html>`_: Summarizing longer "
"documents into shorter, more condensed chunks of information. A type of Data "
"Augmented Generation."
msgstr ""

#: ../docs/index.rst:86
msgid ""
"`Evaluation <./use_cases/evaluation.html>`_: Generative models are "
"notoriously hard to evaluate with traditional metrics. One new way of "
"evaluating them is using language models themselves to do the evaluation. "
"LangChain provides some prompts/chains for assisting in this."
msgstr ""

#: ../docs/index.rst:109
msgid "Reference Docs"
msgstr ""

#: ../docs/index.rst:111
msgid ""
"All of LangChain's reference documentation, in one place. Full documentation "
"on all methods, classes, installation methods, and integration setups for "
"LangChain."
msgstr ""

#: ../docs/index.rst:114
msgid "`Reference Documentation <./reference.html>`_"
msgstr ""

#: ../docs/index.rst:131
msgid "`LangChain Ecosystem <./ecosystem.html>`_"
msgstr ""

#: ../docs/index.rst:146
msgid ""
"Additional collection of resources we think may be useful as you develop "
"your application!"
msgstr ""

#: ../docs/index.rst:148
msgid ""
"`LangChainHub <https://github.com/hwchase17/langchain-hub>`_: The "
"LangChainHub is a place to share and explore other prompts, chains, and "
"agents."
msgstr ""

#: ../docs/index.rst:150
msgid ""
"`Glossary <./glossary.html>`_: A glossary of all related terms, papers, "
"methods, etc. Whether implemented in LangChain or not!"
msgstr ""

#: ../docs/index.rst:152
msgid ""
"`Gallery <./gallery.html>`_: A collection of our favorite projects that use "
"LangChain. Useful for finding inspiration or seeing how things were done in "
"other applications."
msgstr ""

#: ../docs/index.rst:154
msgid ""
"`Deployments <./deployments.html>`_: A collection of instructions, code "
"snippets, and template repositories for deploying LangChain apps."
msgstr ""

#: ../docs/index.rst:156
msgid ""
"`Tracing <./tracing.html>`_: A guide on using tracing in LangChain to "
"visualize the execution of chains and agents."
msgstr ""

#: ../docs/index.rst:158
msgid ""
"`Model Laboratory <./model_laboratory.html>`_: Experimenting with different "
"prompts, models, and chains is a big part of developing the best possible "
"application. The ModelLaboratory makes it easy to do so."
msgstr ""

#: ../docs/index.rst:160
msgid ""
"`Discord <https://discord.gg/6adMQxSpJS>`_: Join us on our Discord to "
"discuss all things LangChain!"
msgstr ""

#: ../docs/index.rst:162
msgid ""
"`YouTube <./youtube.html>`_: A collection of the LangChain tutorials and "
"videos."
msgstr ""

#: ../docs/index.rst:164
msgid ""
"`Production Support <https://forms.gle/57d8AmXBYp8PP8tZA>`_: As you move "
"your LangChains into production, we'd love to offer more comprehensive "
"support. Please fill out this form and we'll set up a dedicated support "
"Slack channel."
msgstr ""

#: ../docs/model_laboratory.ipynb:10002
msgid "Model Comparison"
msgstr ""

#: ../docs/model_laboratory.ipynb:10004
msgid ""
"Constructing your language model application will likely involved choosing "
"between many different options of prompts, models, and even chains to use. "
"When doing so, you will want to compare these different options on different "
"inputs in an easy, flexible, and intuitive way."
msgstr ""

#: ../docs/model_laboratory.ipynb:10006
msgid ""
"LangChain provides the concept of a ModelLaboratory to test out and try "
"different models."
msgstr ""

#: ../docs/reference.rst:2
msgid "API References"
msgstr ""

#: ../docs/reference.rst:4
msgid ""
"All of LangChain's reference documentation, in one place. Full documentation "
"on all methods, classes, and APIs in LangChain."
msgstr ""

#: ../docs/reference/agents.rst:2 ../docs/reference/modules/agents.rst:2
#: ../docs/use_cases/apis.md:17 ../docs/use_cases/tabular.md:26
msgid "Agents"
msgstr ""

#: ../docs/reference/agents.rst:4
msgid "Reference guide for Agents and associated abstractions."
msgstr ""

#: ../docs/reference/indexes.rst:2
msgid "Indexes"
msgstr ""

#: ../docs/reference/indexes.rst:3
msgid ""
"Indexes refer to ways to structure documents so that LLMs can best interact "
"with them. LangChain has a number of modules that help you load, structure, "
"store, and retrieve documents."
msgstr ""

#: ../docs/reference/installation.md:3
msgid "Official Releases"
msgstr ""

#: ../docs/reference/installation.md:5
msgid "LangChain is available on PyPi, so to it is easily installable with:"
msgstr ""

#: ../docs/reference/installation.md:11
msgid ""
"That will install the bare minimum requirements of LangChain. A lot of the "
"value of LangChain comes when integrating it with various model providers, "
"datastores, etc. By default, the dependencies needed to do that are NOT "
"installed. However, there are two other ways to install LangChain that do "
"bring in those dependencies."
msgstr ""

#: ../docs/reference/installation.md:16
msgid "To install modules needed for the common LLM providers, run:"
msgstr ""

#: ../docs/reference/installation.md:22
msgid "To install all modules needed for all integrations, run:"
msgstr ""

#: ../docs/reference/installation.md:28
msgid ""
"Note that if you are using `zsh`, you'll need to quote square brackets when "
"passing them as an argument to a command, for example:"
msgstr ""

#: ../docs/reference/installation.md:34
msgid "Installing from source"
msgstr ""

#: ../docs/reference/installation.md:36
msgid ""
"If you want to install from source, you can do so by cloning the repo and "
"running:"
msgstr ""

#: ../docs/reference/integrations.md:1
msgid "Integrations"
msgstr ""

#: ../docs/reference/integrations.md:3
msgid ""
"Besides the installation of this python package, you will also need to "
"install packages and set environment variables depending on which chains you "
"want to use."
msgstr ""

#: ../docs/reference/integrations.md:5
msgid ""
"Note: the reason these packages are not included in the dependencies by "
"default is that as we imagine scaling this package, we do not want to force "
"dependencies that are not needed."
msgstr ""

#: ../docs/reference/integrations.md:7
msgid "The following use cases require specific installs and api keys:"
msgstr ""

#: ../docs/reference/integrations.md:9
msgid "_OpenAI_:"
msgstr ""

#: ../docs/reference/integrations.md:10 ../docs/reference/integrations.md:16
msgid "Install requirements with `pip install openai`"
msgstr ""

#: ../docs/reference/integrations.md:11
msgid ""
"Get an OpenAI api key and either set it as an environment variable "
"(`OPENAI_API_KEY`) or pass it to the LLM constructor as `openai_api_key`."
msgstr ""

#: ../docs/reference/integrations.md:12
msgid "_Cohere_:"
msgstr ""

#: ../docs/reference/integrations.md:13
msgid "Install requirements with `pip install cohere`"
msgstr ""

#: ../docs/reference/integrations.md:14
msgid ""
"Get a Cohere api key and either set it as an environment variable "
"(`COHERE_API_KEY`) or pass it to the LLM constructor as `cohere_api_key`."
msgstr ""

#: ../docs/reference/integrations.md:15
msgid "_GooseAI_:"
msgstr ""

#: ../docs/reference/integrations.md:17
msgid ""
"Get an GooseAI api key and either set it as an environment variable "
"(`GOOSEAI_API_KEY`) or pass it to the LLM constructor as `gooseai_api_key`."
msgstr ""

#: ../docs/reference/integrations.md:18
msgid "_Hugging Face Hub_"
msgstr ""

#: ../docs/reference/integrations.md:19
msgid "Install requirements with `pip install huggingface_hub`"
msgstr ""

#: ../docs/reference/integrations.md:20
msgid ""
"Get a Hugging Face Hub api token and either set it as an environment "
"variable (`HUGGINGFACEHUB_API_TOKEN`) or pass it to the LLM constructor as "
"`huggingfacehub_api_token`."
msgstr ""

#: ../docs/reference/integrations.md:21
msgid "_Petals_:"
msgstr ""

#: ../docs/reference/integrations.md:22
msgid "Install requirements with `pip install petals`"
msgstr ""

#: ../docs/reference/integrations.md:23
msgid ""
"Get an GooseAI api key and either set it as an environment variable "
"(`HUGGINGFACE_API_KEY`) or pass it to the LLM constructor as "
"`huggingface_api_key`."
msgstr ""

#: ../docs/reference/integrations.md:24
msgid "_CerebriumAI_:"
msgstr ""

#: ../docs/reference/integrations.md:25
msgid "Install requirements with `pip install cerebrium`"
msgstr ""

#: ../docs/reference/integrations.md:26
msgid ""
"Get a Cerebrium api key and either set it as an environment variable "
"(`CEREBRIUMAI_API_KEY`) or pass it to the LLM constructor as "
"`cerebriumai_api_key`."
msgstr ""

#: ../docs/reference/integrations.md:27
msgid "_PromptLayer_:"
msgstr ""

#: ../docs/reference/integrations.md:28
msgid ""
"Install requirements with `pip install promptlayer` (be sure to be on "
"version 0.1.62 or higher)"
msgstr ""

#: ../docs/reference/integrations.md:29
msgid ""
"Get an API key from [promptlayer.com](http://www.promptlayer.com) and set it "
"using `promptlayer.api_key=<API KEY>`"
msgstr ""

#: ../docs/reference/integrations.md:30
msgid "_SerpAPI_:"
msgstr ""

#: ../docs/reference/integrations.md:32
msgid ""
"Get a SerpAPI api key and either set it as an environment variable "
"(`SERPAPI_API_KEY`) or pass it to the LLM constructor as `serpapi_api_key`."
msgstr ""

#: ../docs/reference/integrations.md:33
msgid "_GoogleSearchAPI_:"
msgstr ""

#: ../docs/reference/integrations.md:35
msgid ""
"Get a Google api key and either set it as an environment variable "
"(`GOOGLE_API_KEY`) or pass it to the LLM constructor as `google_api_key`. "
"You will also need to set the `GOOGLE_CSE_ID` environment variable to your "
"custom search engine id. You can pass it to the LLM constructor as "
"`google_cse_id` as well."
msgstr ""

#: ../docs/reference/integrations.md:36
msgid "_WolframAlphaAPI_:"
msgstr ""

#: ../docs/reference/integrations.md:38
msgid ""
"Get a Wolfram Alpha api key and either set it as an environment variable "
"(`WOLFRAM_ALPHA_APPID`) or pass it to the LLM constructor as "
"`wolfram_alpha_appid`."
msgstr ""

#: ../docs/reference/integrations.md:39
msgid "_NatBot_:"
msgstr ""

#: ../docs/reference/integrations.md:40
msgid "Install requirements with `pip install playwright`"
msgstr ""

#: ../docs/reference/integrations.md:41
msgid "_Wikipedia_:"
msgstr ""

#: ../docs/reference/integrations.md:42
msgid "Install requirements with `pip install wikipedia`"
msgstr ""

#: ../docs/reference/integrations.md:43
msgid "_Elasticsearch_:"
msgstr ""

#: ../docs/reference/integrations.md:44
msgid "Install requirements with `pip install elasticsearch`"
msgstr ""

#: ../docs/reference/integrations.md:45
msgid ""
"Set up Elasticsearch backend. If you want to do locally, [this](https://www."
"elastic.co/guide/en/elasticsearch/reference/7.17/getting-started.html) is a "
"good guide."
msgstr ""

#: ../docs/reference/integrations.md:46
msgid "_FAISS_:"
msgstr ""

#: ../docs/reference/integrations.md:47
msgid ""
"Install requirements with `pip install faiss` for Python 3.7 and `pip "
"install faiss-cpu` for Python 3.10+."
msgstr ""

#: ../docs/reference/integrations.md:48
msgid "_MyScale_"
msgstr ""

#: ../docs/reference/integrations.md:49
msgid ""
"Install requirements with `pip install clickhouse-connect`. For "
"documentations, please refer to [this document](https://docs.myscale.com/en/"
"overview/)."
msgstr ""

#: ../docs/reference/integrations.md:50
msgid "_Manifest_:"
msgstr ""

#: ../docs/reference/integrations.md:51
msgid ""
"Install requirements with `pip install manifest-ml` (Note: this is only "
"available in Python 3.8+ currently)."
msgstr ""

#: ../docs/reference/integrations.md:52
msgid "_OpenSearch_:"
msgstr ""

#: ../docs/reference/integrations.md:53
msgid "Install requirements with `pip install opensearch-py`"
msgstr ""

#: ../docs/reference/integrations.md:54
msgid ""
"If you want to set up OpenSearch on your local, [here](https://opensearch."
"org/docs/latest/)"
msgstr ""

#: ../docs/reference/integrations.md:55
msgid "_DeepLake_:"
msgstr ""

#: ../docs/reference/integrations.md:56
msgid "Install requirements with `pip install deeplake`"
msgstr ""

#: ../docs/reference/integrations.md:57
msgid "_LlamaCpp_:"
msgstr ""

#: ../docs/reference/integrations.md:58
msgid "Install requirements with `pip install llama-cpp-python`"
msgstr ""

#: ../docs/reference/integrations.md:59
msgid ""
"Download model and convert following [llama.cpp instructions](https://github."
"com/ggerganov/llama.cpp)"
msgstr ""

#: ../docs/reference/integrations.md:60
msgid "_Milvus_:"
msgstr ""

#: ../docs/reference/integrations.md:61 ../docs/reference/integrations.md:64
msgid "Install requirements with `pip install pymilvus`"
msgstr ""

#: ../docs/reference/integrations.md:62
msgid ""
"In order to setup a local cluster, take a look [here](https://milvus.io/"
"docs)."
msgstr ""

#: ../docs/reference/integrations.md:63
msgid "_Zilliz_:"
msgstr ""

#: ../docs/reference/integrations.md:65
msgid ""
"To get up and running, take a look [here](https://zilliz.com/doc/"
"quick_start)."
msgstr ""

#: ../docs/reference/integrations.md:68
msgid ""
"If you are using the `NLTKTextSplitter` or the `SpacyTextSplitter`, you will "
"also need to install the appropriate models. For example, if you want to use "
"the `SpacyTextSplitter`, you will need to install the `en_core_web_sm` model "
"with `python -m spacy download en_core_web_sm`. Similarly, if you want to "
"use the `NLTKTextSplitter`, you will need to install the `punkt` model with "
"`python -m nltk.downloader punkt`."
msgstr ""

#: ../docs/reference/models.rst:2
msgid "Models"
msgstr ""

#: ../docs/reference/models.rst:4
msgid ""
"LangChain provides interfaces and integrations for a number of different "
"types of models."
msgstr ""

#: ../docs/reference/modules/agent_toolkits.rst:2
msgid "Agent Toolkits"
msgstr ""

#: ../docs/reference/modules/chains.rst:2 ../docs/use_cases/apis.md:9
#: ../docs/use_cases/tabular.md:18
msgid "Chains"
msgstr ""

#: ../docs/reference/modules/chat_models.rst:2
msgid "Chat Models"
msgstr ""

#: ../docs/reference/modules/docstore.rst:2
msgid "Docstore"
msgstr ""

#: ../docs/reference/modules/document_compressors.rst:2
msgid "Document Compressors"
msgstr ""

#: ../docs/reference/modules/document_loaders.rst:2
msgid "Document Loaders"
msgstr ""

#: ../docs/reference/modules/document_transformers.rst:2
msgid "Document Transformers"
msgstr ""

#: ../docs/reference/modules/example_selector.rst:2
msgid "Example Selector"
msgstr ""

#: ../docs/reference/modules/experimental.rst:3
msgid "Experimental Modules"
msgstr ""

#: ../docs/reference/modules/experimental.rst:5
msgid ""
"This module contains experimental modules and reproductions of existing work "
"using LangChain primitives."
msgstr ""

#: ../docs/reference/modules/experimental.rst:8
#: ../docs/use_cases/autonomous_agents.md:1
msgid "Autonomous Agents"
msgstr ""

#: ../docs/reference/modules/experimental.rst:10
msgid ""
"Here, we document the BabyAGI and AutoGPT classes from the langchain."
"experimental module."
msgstr ""

#: ../docs/reference/modules/experimental.rst:20
msgid "Generative Agents"
msgstr ""

#: ../docs/reference/modules/experimental.rst:22
msgid ""
"Here, we document the GenerativeAgent and GenerativeAgentMemory classes from "
"the langchain.experimental module."
msgstr ""

#: ../docs/reference/modules/llms.rst:2
msgid "LLMs"
msgstr ""

#: ../docs/reference/modules/memory.rst:2
msgid "Memory"
msgstr ""

#: ../docs/reference/modules/output_parsers.rst:2
msgid "Output Parsers"
msgstr ""

#: ../docs/reference/modules/prompts.rst:2
msgid "PromptTemplates"
msgstr ""

#: ../docs/reference/modules/python.rst:2
msgid "Python REPL"
msgstr ""

#: ../docs/reference/modules/retrievers.rst:2
msgid "Retrievers"
msgstr ""

#: ../docs/reference/modules/searx_search.rst:2
msgid "SearxNG Search"
msgstr ""

#: ../docs/reference/modules/text_splitter.rst:2
msgid "Text Splitter"
msgstr ""

#: ../docs/reference/modules/tools.rst:2
#: ../docs/use_cases/agents/wikibase_agent.ipynb:110002
msgid "Tools"
msgstr ""

#: ../docs/reference/modules/utilities.rst:2
msgid "Utilities"
msgstr ""

#: ../docs/reference/modules/vectorstores.rst:2
msgid "Vector Stores"
msgstr ""

#: ../docs/reference/prompts.rst:2
#: ../docs/use_cases/agents/wikibase_agent.ipynb:250002
msgid "Prompts"
msgstr ""

#: ../docs/reference/prompts.rst:4
msgid ""
"The reference guides here all relate to objects for working with Prompts."
msgstr ""

#: ../docs/tracing.md:1
msgid "Tracing"
msgstr ""

#: ../docs/tracing.md:3
msgid ""
"By enabling tracing in your LangChain runs, youâ€™ll be able to more "
"effectively visualize, step through, and debug your chains and agents."
msgstr ""

#: ../docs/tracing.md:5
msgid ""
"First, you should install tracing and set up your environment properly. You "
"can use either a locally hosted version of this (uses Docker) or a cloud "
"hosted version (in closed alpha). If you're interested in using the hosted "
"platform, please fill out the form [here](https://forms.gle/"
"tRCEMSeopZf6TE3b6)."
msgstr ""

#: ../docs/tracing.md:10
msgid "[Locally Hosted Setup](./tracing/local_installation.md)"
msgstr ""

#: ../docs/tracing.md:11
msgid "[Cloud Hosted Setup](./tracing/hosted_installation.md)"
msgstr ""

#: ../docs/tracing.md:13 ../docs/tracing/agent_with_tracing.ipynb:10002
msgid "Tracing Walkthrough"
msgstr ""

#: ../docs/tracing.md:15
msgid ""
"When you first access the UI, you should see a page with your tracing "
"sessions.  An initial one \"default\" should already be created for you.  A "
"session is just a way to group traces together.  If you click on a session, "
"it will take you to a page with no recorded traces that says \"No Runs.\"  "
"You can create a new session with the new session form."
msgstr ""

#: ../docs/tracing.md:21
msgid "![](tracing/homepage.png)"
msgstr ""

#: ../docs/tracing.md:23
msgid ""
"If we click on the `default` session, we can see that to start we have no "
"traces stored."
msgstr ""

#: ../docs/tracing.md:25
msgid "![](tracing/default_empty.png)"
msgstr ""

#: ../docs/tracing.md:27
msgid ""
"If we now start running chains and agents with tracing enabled, we will see "
"data show up here. To do so, we can run [this notebook](tracing/"
"agent_with_tracing.ipynb) as an example. After running it, we will see an "
"initial trace show up."
msgstr ""

#: ../docs/tracing.md:31
msgid "![](tracing/first_trace.png)"
msgstr ""

#: ../docs/tracing.md:33
msgid ""
"From here we can explore the trace at a high level by clicking on the arrow "
"to show nested runs. We can keep on clicking further and further down to "
"explore deeper and deeper."
msgstr ""

#: ../docs/tracing.md:36
msgid "![](tracing/explore.png)"
msgstr ""

#: ../docs/tracing.md:38
msgid ""
"We can also click on the \"Explore\" button of the top level run to dive "
"even deeper.  Here, we can see the inputs and outputs in full, as well as "
"all the nested traces."
msgstr ""

#: ../docs/tracing.md:41
msgid "![](tracing/explore_trace.png)"
msgstr ""

#: ../docs/tracing.md:43
msgid ""
"We can keep on exploring each of these nested traces in more detail. For "
"example, here is the lowest level trace with the exact inputs/outputs to the "
"LLM."
msgstr ""

#: ../docs/tracing.md:46
msgid "![](tracing/explore_llm.png)"
msgstr ""

#: ../docs/tracing.md:48
msgid "Changing Sessions"
msgstr ""

#: ../docs/tracing.md:49
msgid ""
"To initially record traces to a session other than `\"default\"`, you can "
"set the `LANGCHAIN_SESSION` environment variable to the name of the session "
"you want to record to:"
msgstr ""

#: ../docs/tracing.md:57
msgid ""
"To switch sessions mid-script or mid-notebook, do NOT set the "
"`LANGCHAIN_SESSION` environment variable. Instead: `langchain."
"set_tracing_callback_manager(session_name=\"my_session\")`"
msgstr ""

#: ../docs/tracing/hosted_installation.md:1
msgid "Cloud Hosted Setup"
msgstr ""

#: ../docs/tracing/hosted_installation.md:3
msgid ""
"We offer a hosted version of tracing at [langchainplus.vercel.app](https://"
"langchainplus.vercel.app/). You can use this to view traces from your run "
"without having to run the server locally."
msgstr ""

#: ../docs/tracing/hosted_installation.md:5
msgid ""
"Note: we are currently only offering this to a limited number of users. The "
"hosted platform is VERY alpha, in active development, and data might be "
"dropped at any time. Don't depend on data being persisted in the system long "
"term and don't log traces that may contain sensitive information. If you're "
"interested in using the hosted platform, please fill out the form [here]"
"(https://forms.gle/tRCEMSeopZf6TE3b6)."
msgstr ""

#: ../docs/tracing/hosted_installation.md:9
msgid ""
"Login to the system and click \"API Key\" in the top right corner. Generate "
"a new key and keep it safe. You will need it to authenticate with the system."
msgstr ""

#: ../docs/tracing/hosted_installation.md:13
#: ../docs/tracing/local_installation.md:25
msgid ""
"After installation, you must now set up your environment to use tracing."
msgstr ""

#: ../docs/tracing/hosted_installation.md:15
#: ../docs/tracing/local_installation.md:27
msgid ""
"This can be done by setting an environment variable in your terminal by "
"running `export LANGCHAIN_HANDLER=langchain`."
msgstr ""

#: ../docs/tracing/hosted_installation.md:17
#: ../docs/tracing/local_installation.md:29
msgid ""
"You can also do this by adding the below snippet to the top of every script. "
"**IMPORTANT:** this must go at the VERY TOP of your script, before you "
"import anything from `langchain`."
msgstr ""

#: ../docs/tracing/hosted_installation.md:24
msgid ""
"You will also need to set an environment variable to specify the endpoint "
"and your API key. This can be done with the following environment variables:"
msgstr ""

#: ../docs/tracing/hosted_installation.md:26
msgid ""
"`LANGCHAIN_ENDPOINT` = \"https://langchain-api-gateway-57eoxz8z.uc.gateway."
"dev\""
msgstr ""

#: ../docs/tracing/hosted_installation.md:27
msgid ""
"`LANGCHAIN_API_KEY` - set this to the API key you generated during "
"installation."
msgstr ""

#: ../docs/tracing/hosted_installation.md:29
msgid "An example of adding all relevant environment variables is below:"
msgstr ""

#: ../docs/tracing/local_installation.md:1
msgid "Locally Hosted Setup"
msgstr ""

#: ../docs/tracing/local_installation.md:3
msgid ""
"This page contains instructions for installing and then setting up the "
"environment to use the locally hosted version of tracing."
msgstr ""

#: ../docs/tracing/local_installation.md:7
msgid ""
"Ensure you have Docker installed (see [Get Docker](https://docs.docker.com/"
"get-docker/)) and that itâ€™s running."
msgstr ""

#: ../docs/tracing/local_installation.md:8
msgid ""
"Install the latest version of `langchain`: `pip install langchain` or `pip "
"install langchain -U` to upgrade your existing version."
msgstr ""

#: ../docs/tracing/local_installation.md:10
msgid ""
"Run `langchain-server`. This command was installed automatically when you "
"ran the above command (`pip install langchain`)."
msgstr ""

#: ../docs/tracing/local_installation.md:11
msgid ""
"This will spin up the server in the terminal, hosted on port `4137` by "
"default."
msgstr ""

#: ../docs/tracing/local_installation.md:12
msgid ""
"Once you see the terminal output `langchain-langchain-frontend-1 | âžœ Local: "
"[http://localhost:4173/](http://localhost:4173/)`, navigate to [http://"
"localhost:4173/](http://localhost:4173/)"
msgstr ""

#: ../docs/tracing/local_installation.md:16
msgid ""
"You should see a page with your tracing sessions. See the overview page for "
"a walkthrough of the UI."
msgstr ""

#: ../docs/tracing/local_installation.md:18
msgid ""
"Currently, trace data is not guaranteed to be persisted between runs of "
"`langchain-server`. If you want to     persist your data, you can mount a "
"volume to the Docker container. See the [Docker docs](https://docs.docker."
"com/storage/volumes/) for more info."
msgstr ""

#: ../docs/tracing/local_installation.md:20
msgid ""
"To stop the server, press `Ctrl+C` in the terminal where you ran `langchain-"
"server`."
msgstr ""

#: ../docs/use_cases/agent_simulations.md:1
msgid "Agent Simulations"
msgstr ""

#: ../docs/use_cases/agent_simulations.md:3
msgid ""
"Agent simulations involve interacting one of more agents with eachother. "
"Agent simulations generally involve two main components:"
msgstr ""

#: ../docs/use_cases/agent_simulations.md:6
msgid "Long Term Memory"
msgstr ""

#: ../docs/use_cases/agent_simulations.md:7
msgid "Simulation Environment"
msgstr ""

#: ../docs/use_cases/agent_simulations.md:9
msgid ""
"Specific implementations of agent simulations (or parts of agent "
"simulations) include"
msgstr ""

#: ../docs/use_cases/agent_simulations.md:11
msgid "Simulations with Two Agents"
msgstr ""

#: ../docs/use_cases/agent_simulations.md:12
msgid ""
"[CAMEL](agent_simulations/camel_role_playing.ipynb): an implementation of "
"the CAMEL (Communicative Agents for â€œMindâ€ Exploration of Large Scale "
"Language Model Society) paper, where two agents communicate with each other."
msgstr ""

#: ../docs/use_cases/agent_simulations.md:13
msgid ""
"[Two Player D&D](agent_simulations/two_player_dnd.ipynb): an example of how "
"to use a generic simulator for two agents to implement a variant of the "
"popular Dungeons & Dragons role playing game."
msgstr ""

#: ../docs/use_cases/agent_simulations.md:15
msgid "Simulations with Multiple Agents"
msgstr ""

#: ../docs/use_cases/agent_simulations.md:16
msgid ""
"[Multi-Player D&D](agent_simulations/multi_player_dnd.ipynb): an example of "
"how to use a generic dialogue simulator for multiple dialogue agents with a "
"custom speaker-ordering, illustrated with a variant of the popular Dungeons "
"& Dragons role playing game."
msgstr ""

#: ../docs/use_cases/agent_simulations.md:17
msgid ""
"[Decentralized Speaker Selection](agent_simulations/multiagent_bidding."
"ipynb): an example of how to implement a multi-agent dialogue without a "
"fixed schedule for who speaks when. Instead the agents decide for themselves "
"who speaks by outputting bids to speak. This example shows how to do this in "
"the context of a fictitious presidential debate."
msgstr ""

#: ../docs/use_cases/agent_simulations.md:18
msgid ""
"[Generative Agents](agent_simulations/characters.ipynb): This notebook "
"implements a generative agent based on the paper [Generative Agents: "
"Interactive Simulacra of Human Behavior](https://arxiv.org/abs/2304.03442) "
"by Park, et. al."
msgstr ""

#: ../docs/use_cases/agent_simulations/camel_role_playing.ipynb:10002
#: ../docs/use_cases/agents/camel_role_playing.ipynb:10002
msgid "CAMEL Role-Playing Autonomous Cooperative Agents"
msgstr ""

#: ../docs/use_cases/agent_simulations/camel_role_playing.ipynb:10004
#: ../docs/use_cases/agents/camel_role_playing.ipynb:10004
msgid ""
"This is a langchain implementation of paper: \"CAMEL: Communicative Agents "
"for â€œMindâ€ Exploration of Large Scale Language Model Society\"."
msgstr ""

#: ../docs/use_cases/agent_simulations/camel_role_playing.ipynb:10006
#: ../docs/use_cases/agents/camel_role_playing.ipynb:10006
msgid "Overview:"
msgstr ""

#: ../docs/use_cases/agent_simulations/camel_role_playing.ipynb:10008
#: ../docs/use_cases/agents/camel_role_playing.ipynb:10008
msgid ""
"The rapid advancement of conversational and chat-based language models has "
"led to remarkable progress in complex task-solving. However, their success "
"heavily relies on human input to guide the conversation, which can be "
"challenging and time-consuming. This paper explores the potential of "
"building scalable techniques to facilitate autonomous cooperation among "
"communicative agents and provide insight into their \"cognitive\" processes. "
"To address the challenges of achieving autonomous cooperation, we propose a "
"novel communicative agent framework named role-playing. Our approach "
"involves using inception prompting to guide chat agents toward task "
"completion while maintaining consistency with human intentions. We showcase "
"how role-playing can be used to generate conversational data for studying "
"the behaviors and capabilities of chat agents, providing a valuable resource "
"for investigating conversational language models. Our contributions include "
"introducing a novel communicative agent framework, offering a scalable "
"approach for studying the cooperative behaviors and capabilities of multi-"
"agent systems, and open-sourcing our library to support research on "
"communicative agents and beyond."
msgstr ""

#: ../docs/use_cases/agent_simulations/camel_role_playing.ipynb:10010
#: ../docs/use_cases/agents/camel_role_playing.ipynb:10010
msgid "The original implementation: https://github.com/lightaime/camel"
msgstr ""

#: ../docs/use_cases/agent_simulations/camel_role_playing.ipynb:10012
#: ../docs/use_cases/agents/camel_role_playing.ipynb:10012
msgid "Project website: https://www.camel-ai.org/"
msgstr ""

#: ../docs/use_cases/agent_simulations/camel_role_playing.ipynb:10014
#: ../docs/use_cases/agents/camel_role_playing.ipynb:10014
msgid "Arxiv paper: https://arxiv.org/abs/2303.17760"
msgstr ""

#: ../docs/use_cases/agent_simulations/camel_role_playing.ipynb:20002
#: ../docs/use_cases/agent_simulations/multi_player_dnd.ipynb:20002
#: ../docs/use_cases/agent_simulations/multiagent_bidding.ipynb:20002
#: ../docs/use_cases/agent_simulations/two_player_dnd.ipynb:20002
#: ../docs/use_cases/agents/camel_role_playing.ipynb:20002
msgid "Import LangChain related modules"
msgstr ""

#: ../docs/use_cases/agent_simulations/camel_role_playing.ipynb:40002
#: ../docs/use_cases/agents/camel_role_playing.ipynb:40002
msgid "Define a CAMEL agent helper class"
msgstr ""

#: ../docs/use_cases/agent_simulations/camel_role_playing.ipynb:60002
#: ../docs/use_cases/agents/camel_role_playing.ipynb:60002
msgid "Setup OpenAI API key and roles and task for role-playing"
msgstr ""

#: ../docs/use_cases/agent_simulations/camel_role_playing.ipynb:80002
#: ../docs/use_cases/agents/camel_role_playing.ipynb:80002
msgid ""
"Create a task specify agent for brainstorming and get the specified task"
msgstr ""

#: ../docs/use_cases/agent_simulations/camel_role_playing.ipynb:100002
#: ../docs/use_cases/agents/camel_role_playing.ipynb:100002
msgid "Create inception prompts for AI assistant and AI user for role-playing"
msgstr ""

#: ../docs/use_cases/agent_simulations/camel_role_playing.ipynb:120002
#: ../docs/use_cases/agents/camel_role_playing.ipynb:120002
msgid ""
"Create a helper helper to get system messages for AI assistant and AI user "
"from role names and the task"
msgstr ""

#: ../docs/use_cases/agent_simulations/camel_role_playing.ipynb:140002
#: ../docs/use_cases/agents/camel_role_playing.ipynb:140002
msgid ""
"Create AI assistant agent and AI user agent from obtained system messages"
msgstr ""

#: ../docs/use_cases/agent_simulations/camel_role_playing.ipynb:160002
#: ../docs/use_cases/agents/camel_role_playing.ipynb:160002
msgid "Start role-playing session to solve the task!"
msgstr ""

#: ../docs/use_cases/agent_simulations/characters.ipynb:10002
msgid "Generative Agents in LangChain"
msgstr ""

#: ../docs/use_cases/agent_simulations/characters.ipynb:10004
msgid ""
"This notebook implements a generative agent based on the paper [Generative "
"Agents: Interactive Simulacra of Human Behavior](https://arxiv.org/"
"abs/2304.03442) by Park, et. al."
msgstr ""

#: ../docs/use_cases/agent_simulations/characters.ipynb:10006
msgid ""
"In it, we leverage a time-weighted Memory object backed by a LangChain "
"Retriever."
msgstr ""

#: ../docs/use_cases/agent_simulations/characters.ipynb:60002
msgid "Generative Agent Memory Components"
msgstr ""

#: ../docs/use_cases/agent_simulations/characters.ipynb:60004
msgid ""
"This tutorial highlights the memory of generative agents and its impact on "
"their behavior. The memory varies from standard LangChain Chat memory in two "
"aspects:"
msgstr ""

#: ../docs/use_cases/agent_simulations/characters.ipynb:60006
msgid "**Memory Formation**"
msgstr ""

#: ../docs/use_cases/agent_simulations/characters.ipynb:60008
msgid "Generative Agents have extended memories, stored in a single stream:"
msgstr ""

#: ../docs/use_cases/agent_simulations/characters.ipynb:60009
msgid ""
"Observations - from dialogues or interactions with the virtual world, about "
"self or others"
msgstr ""

#: ../docs/use_cases/agent_simulations/characters.ipynb:60010
msgid "Reflections - resurfaced and summarized core memories"
msgstr ""

#: ../docs/use_cases/agent_simulations/characters.ipynb:60013
msgid "**Memory Recall**"
msgstr ""

#: ../docs/use_cases/agent_simulations/characters.ipynb:60015
msgid ""
"Memories are retrieved using a weighted sum of salience, recency, and "
"importance."
msgstr ""

#: ../docs/use_cases/agent_simulations/characters.ipynb:60017
msgid ""
"You can review the definitions of the `GenerativeAgent` and "
"`GenerativeAgentMemory` in the [reference documentation](\"../../reference/"
"modules/experimental\") for the following imports, focusing on `add_memory` "
"and `summarize_related_memories` methods."
msgstr ""

#: ../docs/use_cases/agent_simulations/characters.ipynb:80002
msgid "Memory Lifecycle"
msgstr ""

#: ../docs/use_cases/agent_simulations/characters.ipynb:80004
msgid ""
"Summarizing the key methods in the above: `add_memory` and "
"`summarize_related_memories`."
msgstr ""

#: ../docs/use_cases/agent_simulations/characters.ipynb:80006
msgid "When an agent makes an observation, it stores the memory:"
msgstr ""

#: ../docs/use_cases/agent_simulations/characters.ipynb:80008
msgid ""
"Language model scores the memory's importance (1 for mundane, 10 for "
"poignant)"
msgstr ""

#: ../docs/use_cases/agent_simulations/characters.ipynb:80009
msgid ""
"Observation and importance are stored within a document by "
"TimeWeightedVectorStoreRetriever, with a `last_accessed_time`."
msgstr ""

#: ../docs/use_cases/agent_simulations/characters.ipynb:80011
msgid "When an agent responds to an observation:"
msgstr ""

#: ../docs/use_cases/agent_simulations/characters.ipynb:80013
msgid ""
"Generates query(s) for retriever, which fetches documents based on salience, "
"recency, and importance."
msgstr ""

#: ../docs/use_cases/agent_simulations/characters.ipynb:80014
msgid "Summarizes the retrieved information"
msgstr ""

#: ../docs/use_cases/agent_simulations/characters.ipynb:80015
msgid "Updates the `last_accessed_time` for the used documents."
msgstr ""

#: ../docs/use_cases/agent_simulations/characters.ipynb:90002
msgid "Create a Generative Character"
msgstr ""

#: ../docs/use_cases/agent_simulations/characters.ipynb:90006
msgid ""
"Now that we've walked through the definition, we will create two characters "
"named \"Tommie\" and \"Eve\"."
msgstr ""

#: ../docs/use_cases/agent_simulations/characters.ipynb:150002
msgid "Pre-Interview with Character"
msgstr ""

#: ../docs/use_cases/agent_simulations/characters.ipynb:150004
msgid ""
"Before sending our character on their way, let's ask them a few questions."
msgstr ""

#: ../docs/use_cases/agent_simulations/characters.ipynb:200002
msgid "Step through the day's observations."
msgstr ""

#: ../docs/use_cases/agent_simulations/characters.ipynb:230002
msgid "Interview after the day"
msgstr ""

#: ../docs/use_cases/agent_simulations/characters.ipynb:270002
msgid "Adding Multiple Characters"
msgstr ""

#: ../docs/use_cases/agent_simulations/characters.ipynb:270004
msgid ""
"Let's add a second character to have a conversation with Tommie. Feel free "
"to configure different traits."
msgstr ""

#: ../docs/use_cases/agent_simulations/characters.ipynb:310002
msgid "Pre-conversation interviews"
msgstr ""

#: ../docs/use_cases/agent_simulations/characters.ipynb:310005
msgid "Let's \"Interview\" Eve before she speaks with Tommie."
msgstr ""

#: ../docs/use_cases/agent_simulations/characters.ipynb:360002
msgid "Dialogue between Generative Agents"
msgstr ""

#: ../docs/use_cases/agent_simulations/characters.ipynb:360004
msgid ""
"Generative agents are much more complex when they interact with a virtual "
"environment or with each other. Below, we run a simple conversation between "
"Tommie and Eve."
msgstr ""

#: ../docs/use_cases/agent_simulations/characters.ipynb:390002
msgid "Let's interview our agents after their conversation"
msgstr ""

#: ../docs/use_cases/agent_simulations/characters.ipynb:390004
msgid ""
"Since the generative agents retain their memories from the day, we can ask "
"them about their plans, conversations, and other memoreis."
msgstr ""

#: ../docs/use_cases/agent_simulations/multi_player_dnd.ipynb:10002
msgid "Multi-Player Dungeons & Dragons"
msgstr ""

#: ../docs/use_cases/agent_simulations/multi_player_dnd.ipynb:10004
msgid ""
"This notebook shows how the `DialogueAgent` and `DialogueSimulator` class "
"make it easy to extend the [Two-Player Dungeons & Dragons example](https://"
"python.langchain.com/en/latest/use_cases/agent_simulations/two_player_dnd."
"html) to multiple players."
msgstr ""

#: ../docs/use_cases/agent_simulations/multi_player_dnd.ipynb:10006
msgid ""
"The main difference between simulating two players and multiple players is "
"in revising the schedule for when each agent speaks"
msgstr ""

#: ../docs/use_cases/agent_simulations/multi_player_dnd.ipynb:10008
msgid ""
"To this end, we augment `DialogueSimulator` to take in a custom function "
"that determines the schedule of which agent speaks. In the example below, "
"each character speaks in round-robin fashion, with the storyteller "
"interleaved between each player."
msgstr ""

#: ../docs/use_cases/agent_simulations/multi_player_dnd.ipynb:40002
#: ../docs/use_cases/agent_simulations/two_player_dnd.ipynb:40002
msgid "`DialogueAgent` class"
msgstr ""

#: ../docs/use_cases/agent_simulations/multi_player_dnd.ipynb:40003
#: ../docs/use_cases/agent_simulations/two_player_dnd.ipynb:40003
msgid ""
"The `DialogueAgent` class is a simple wrapper around the `ChatOpenAI` model "
"that stores the message history from the `dialogue_agent`'s point of view by "
"simply concatenating the messages as strings."
msgstr ""

#: ../docs/use_cases/agent_simulations/multi_player_dnd.ipynb:40005
#: ../docs/use_cases/agent_simulations/two_player_dnd.ipynb:40005
msgid "It exposes two methods:"
msgstr ""

#: ../docs/use_cases/agent_simulations/multi_player_dnd.ipynb:40006
#: ../docs/use_cases/agent_simulations/two_player_dnd.ipynb:40006
msgid ""
"`send()`: applies the chatmodel to the message history and returns the "
"message string"
msgstr ""

#: ../docs/use_cases/agent_simulations/multi_player_dnd.ipynb:40007
#: ../docs/use_cases/agent_simulations/two_player_dnd.ipynb:40007
msgid ""
"`receive(name, message)`: adds the `message` spoken by `name` to message "
"history"
msgstr ""

#: ../docs/use_cases/agent_simulations/multi_player_dnd.ipynb:60002
#: ../docs/use_cases/agent_simulations/two_player_dnd.ipynb:60002
msgid "`DialogueSimulator` class"
msgstr ""

#: ../docs/use_cases/agent_simulations/multi_player_dnd.ipynb:60003
#: ../docs/use_cases/agent_simulations/two_player_dnd.ipynb:60003
msgid ""
"The `DialogueSimulator` class takes a list of agents. At each step, it "
"performs the following:"
msgstr ""

#: ../docs/use_cases/agent_simulations/multi_player_dnd.ipynb:60004
#: ../docs/use_cases/agent_simulations/two_player_dnd.ipynb:60004
msgid "Select the next speaker"
msgstr ""

#: ../docs/use_cases/agent_simulations/multi_player_dnd.ipynb:60005
#: ../docs/use_cases/agent_simulations/two_player_dnd.ipynb:60005
msgid "Calls the next speaker to send a message"
msgstr ""

#: ../docs/use_cases/agent_simulations/multi_player_dnd.ipynb:60006
#: ../docs/use_cases/agent_simulations/two_player_dnd.ipynb:60006
msgid "Broadcasts the message to all other agents"
msgstr ""

#: ../docs/use_cases/agent_simulations/multi_player_dnd.ipynb:60007
#: ../docs/use_cases/agent_simulations/two_player_dnd.ipynb:60007
msgid ""
"Update the step counter. The selection of the next speaker can be "
"implemented as any function, but in this case we simply loop through the "
"agents."
msgstr ""

#: ../docs/use_cases/agent_simulations/multi_player_dnd.ipynb:80002
#: ../docs/use_cases/agent_simulations/two_player_dnd.ipynb:80002
msgid "Define roles and quest"
msgstr ""

#: ../docs/use_cases/agent_simulations/multi_player_dnd.ipynb:100002
#: ../docs/use_cases/agent_simulations/two_player_dnd.ipynb:100002
msgid "Ask an LLM to add detail to the game description"
msgstr ""

#: ../docs/use_cases/agent_simulations/multi_player_dnd.ipynb:130002
#: ../docs/use_cases/agent_simulations/two_player_dnd.ipynb:150002
msgid "Use an LLM to create an elaborate quest description"
msgstr ""

#: ../docs/use_cases/agent_simulations/multi_player_dnd.ipynb:150002
#: ../docs/use_cases/agent_simulations/multiagent_bidding.ipynb:230002
#: ../docs/use_cases/agent_simulations/two_player_dnd.ipynb:170002
msgid "Main Loop"
msgstr ""

#: ../docs/use_cases/agent_simulations/multiagent_bidding.ipynb:10002
msgid "Multi-agent decentralized speaker selection"
msgstr ""

#: ../docs/use_cases/agent_simulations/multiagent_bidding.ipynb:10004
msgid ""
"This notebook showcases how to implement a multi-agent simulation without a "
"fixed schedule for who speaks when. Instead the agents decide for themselves "
"who speaks. We can implement this by having each agent bid to speak. "
"Whichever agent's bid is the highest gets to speak."
msgstr ""

#: ../docs/use_cases/agent_simulations/multiagent_bidding.ipynb:10006
msgid ""
"We will show how to do this in the example below that showcases a fictitious "
"presidential debate."
msgstr ""

#: ../docs/use_cases/agent_simulations/multiagent_bidding.ipynb:40002
msgid "`DialogueAgent` and `DialogueSimulator` classes"
msgstr ""

#: ../docs/use_cases/agent_simulations/multiagent_bidding.ipynb:40003
msgid ""
"We will use the same `DialogueAgent` and `DialogueSimulator` classes defined "
"in [Multi-Player Dungeons & Dragons](https://python.langchain.com/en/latest/"
"use_cases/agent_simulations/multi_player_dnd.html)."
msgstr ""

#: ../docs/use_cases/agent_simulations/multiagent_bidding.ipynb:60002
msgid "`BiddingDialogueAgent` class"
msgstr ""

#: ../docs/use_cases/agent_simulations/multiagent_bidding.ipynb:60003
msgid ""
"We define a subclass of `DialogueAgent` that has a `bid()` method that "
"produces a bid given the message history and the most recent message."
msgstr ""

#: ../docs/use_cases/agent_simulations/multiagent_bidding.ipynb:80002
msgid "Define participants and debate topic"
msgstr ""

#: ../docs/use_cases/agent_simulations/multiagent_bidding.ipynb:100002
msgid "Generate system messages"
msgstr ""

#: ../docs/use_cases/agent_simulations/multiagent_bidding.ipynb:130002
msgid "Output parser for bids"
msgstr ""

#: ../docs/use_cases/agent_simulations/multiagent_bidding.ipynb:130003
msgid ""
"We ask the agents to output a bid to speak. But since the agents are LLMs "
"that output strings, we need to"
msgstr ""

#: ../docs/use_cases/agent_simulations/multiagent_bidding.ipynb:130004
msgid "define a format they will produce their outputs in"
msgstr ""

#: ../docs/use_cases/agent_simulations/multiagent_bidding.ipynb:130005
msgid "parse their outputs"
msgstr ""

#: ../docs/use_cases/agent_simulations/multiagent_bidding.ipynb:130007
msgid ""
"We can subclass the [RegexParser](https://github.com/hwchase17/langchain/"
"blob/master/langchain/output_parsers/regex.py) to implement our own custom "
"output parser for bids."
msgstr ""

#: ../docs/use_cases/agent_simulations/multiagent_bidding.ipynb:150002
msgid "Generate bidding system message"
msgstr ""

#: ../docs/use_cases/agent_simulations/multiagent_bidding.ipynb:150003
msgid ""
"This is inspired by the prompt used in [Generative Agents](https://arxiv.org/"
"pdf/2304.03442.pdf) for using an LLM to determine the importance of "
"memories. This will use the formatting instructions from our "
"`BidOutputParser`."
msgstr ""

#: ../docs/use_cases/agent_simulations/multiagent_bidding.ipynb:180002
msgid "Use an LLM to create an elaborate on debate topic"
msgstr ""

#: ../docs/use_cases/agent_simulations/multiagent_bidding.ipynb:200002
msgid "Define the speaker selection function"
msgstr ""

#: ../docs/use_cases/agent_simulations/multiagent_bidding.ipynb:200003
msgid ""
"Lastly we will define a speaker selection function `select_next_speaker` "
"that takes each agent's bid and selects the agent with the highest bid (with "
"ties broken randomly)."
msgstr ""

#: ../docs/use_cases/agent_simulations/multiagent_bidding.ipynb:200005
msgid ""
"We will define a `ask_for_bid` function that uses the `bid_parser` we "
"defined before to parse the agent's bid. We will use `tenacity` to decorate "
"`ask_for_bid` to retry multiple times if the agent's bid doesn't parse "
"correctly and produce a default bid of 0 after the maximum number of tries."
msgstr ""

#: ../docs/use_cases/agent_simulations/two_player_dnd.ipynb:10002
msgid "Two-Player Dungeons & Dragons"
msgstr ""

#: ../docs/use_cases/agent_simulations/two_player_dnd.ipynb:10004
msgid ""
"In this notebook, we show how we can use concepts from [CAMEL](https://www."
"camel-ai.org/) to simulate a role-playing game with a protagonist and a "
"dungeon master. To simulate this game, we create an `DialogueSimulator` "
"class that coordinates the dialogue between the two agents."
msgstr ""

#: ../docs/use_cases/agent_simulations/two_player_dnd.ipynb:130002
msgid "Protagonist and dungeon master system messages"
msgstr ""

#: ../docs/use_cases/agents/baby_agi.ipynb:10002
#: ../docs/use_cases/autonomous_agents/baby_agi.ipynb:10002
msgid "BabyAGI User Guide"
msgstr ""

#: ../docs/use_cases/agents/baby_agi.ipynb:10004
#: ../docs/use_cases/autonomous_agents/baby_agi.ipynb:10004
msgid ""
"This notebook demonstrates how to implement [BabyAGI](https://github.com/"
"yoheinakajima/babyagi/tree/main) by [Yohei Nakajima](https://twitter.com/"
"yoheinakajima). BabyAGI is an AI agent that can generate and pretend to "
"execute tasks based on a given objective."
msgstr ""

#: ../docs/use_cases/agents/baby_agi.ipynb:10006
#: ../docs/use_cases/autonomous_agents/baby_agi.ipynb:10006
msgid ""
"This guide will help you understand the components to create your own "
"recursive agents."
msgstr ""

#: ../docs/use_cases/agents/baby_agi.ipynb:10008
#: ../docs/use_cases/autonomous_agents/baby_agi.ipynb:10008
msgid ""
"Although BabyAGI uses specific vectorstores/model providers (Pinecone, "
"OpenAI), one of the benefits of implementing it with LangChain is that you "
"can easily swap those out for different options. In this implementation we "
"use a FAISS vectorstore (because it runs locally and is free)."
msgstr ""

#: ../docs/use_cases/agents/baby_agi.ipynb:20002
#: ../docs/use_cases/agents/baby_agi_with_agent.ipynb:20002
#: ../docs/use_cases/autonomous_agents/baby_agi.ipynb:20002
#: ../docs/use_cases/autonomous_agents/baby_agi_with_agent.ipynb:20002
msgid "Install and Import Required Modules"
msgstr ""

#: ../docs/use_cases/agents/baby_agi.ipynb:40002
#: ../docs/use_cases/agents/baby_agi_with_agent.ipynb:40002
#: ../docs/use_cases/autonomous_agents/baby_agi.ipynb:40002
#: ../docs/use_cases/autonomous_agents/baby_agi_with_agent.ipynb:40002
msgid "Connect to the Vector Store"
msgstr ""

#: ../docs/use_cases/agents/baby_agi.ipynb:40004
#: ../docs/use_cases/agents/baby_agi_with_agent.ipynb:40004
#: ../docs/use_cases/autonomous_agents/baby_agi.ipynb:40004
#: ../docs/use_cases/autonomous_agents/baby_agi_with_agent.ipynb:40004
msgid "Depending on what vectorstore you use, this step may look different."
msgstr ""

#: ../docs/use_cases/agents/baby_agi.ipynb:70002
#: ../docs/use_cases/agents/baby_agi_with_agent.ipynb:70002
#: ../docs/use_cases/autonomous_agents/baby_agi_with_agent.ipynb:70002
msgid "Define the Chains"
msgstr ""

#: ../docs/use_cases/agents/baby_agi.ipynb:70004
#: ../docs/use_cases/agents/baby_agi_with_agent.ipynb:70004
#: ../docs/use_cases/autonomous_agents/baby_agi_with_agent.ipynb:70004
msgid "BabyAGI relies on three LLM chains:"
msgstr ""

#: ../docs/use_cases/agents/baby_agi.ipynb:70005
#: ../docs/use_cases/agents/baby_agi_with_agent.ipynb:70005
#: ../docs/use_cases/autonomous_agents/baby_agi_with_agent.ipynb:70005
msgid "Task creation chain to select new tasks to add to the list"
msgstr ""

#: ../docs/use_cases/agents/baby_agi.ipynb:70006
#: ../docs/use_cases/agents/baby_agi_with_agent.ipynb:70006
#: ../docs/use_cases/autonomous_agents/baby_agi_with_agent.ipynb:70006
msgid "Task prioritization chain to re-prioritize tasks"
msgstr ""

#: ../docs/use_cases/agents/baby_agi.ipynb:70007
#: ../docs/use_cases/agents/baby_agi_with_agent.ipynb:70007
#: ../docs/use_cases/autonomous_agents/baby_agi_with_agent.ipynb:70007
msgid "Execution Chain to execute the tasks"
msgstr ""

#: ../docs/use_cases/agents/baby_agi.ipynb:110002
#: ../docs/use_cases/agents/baby_agi_with_agent.ipynb:110002
msgid "Define the BabyAGI Controller"
msgstr ""

#: ../docs/use_cases/agents/baby_agi.ipynb:110004
#: ../docs/use_cases/agents/baby_agi_with_agent.ipynb:110004
msgid ""
"BabyAGI composes the chains defined above in a (potentially-)infinite loop."
msgstr ""

#: ../docs/use_cases/agents/baby_agi.ipynb:160002
#: ../docs/use_cases/agents/baby_agi_with_agent.ipynb:160002
#: ../docs/use_cases/autonomous_agents/baby_agi.ipynb:70002
#: ../docs/use_cases/autonomous_agents/baby_agi_with_agent.ipynb:100002
msgid "Run the BabyAGI"
msgstr ""

#: ../docs/use_cases/agents/baby_agi.ipynb:160004
#: ../docs/use_cases/agents/baby_agi_with_agent.ipynb:160004
#: ../docs/use_cases/autonomous_agents/baby_agi.ipynb:70004
#: ../docs/use_cases/autonomous_agents/baby_agi_with_agent.ipynb:100004
msgid ""
"Now it's time to create the BabyAGI controller and watch it try to "
"accomplish your objective."
msgstr ""

#: ../docs/use_cases/agents/baby_agi_with_agent.ipynb:10002
#: ../docs/use_cases/autonomous_agents/baby_agi_with_agent.ipynb:10002
msgid "BabyAGI with Tools"
msgstr ""

#: ../docs/use_cases/agents/baby_agi_with_agent.ipynb:10004
#: ../docs/use_cases/autonomous_agents/baby_agi_with_agent.ipynb:10004
msgid ""
"This notebook builds on top of [baby agi](baby_agi.ipynb), but shows how you "
"can swap out the execution chain. The previous execution chain was just an "
"LLM which made stuff up. By swapping it out with an agent that has access to "
"tools, we can hopefully get real reliable information"
msgstr ""

#: ../docs/use_cases/agents/baby_agi_with_agent.ipynb:70010
#: ../docs/use_cases/autonomous_agents/baby_agi_with_agent.ipynb:70010
msgid "NOTE: in this notebook, the Execution chain will now be an agent."
msgstr ""

#: ../docs/use_cases/agents/custom_agent_with_plugin_retrieval.ipynb:10002
msgid "Custom Agent with PlugIn Retrieval"
msgstr ""

#: ../docs/use_cases/agents/custom_agent_with_plugin_retrieval.ipynb:10004
msgid ""
"This notebook combines two concepts in order to build a custom agent that "
"can interact with AI Plugins:"
msgstr ""

#: ../docs/use_cases/agents/custom_agent_with_plugin_retrieval.ipynb:10006
msgid ""
"[Custom Agent with Retrieval](../../modules/agents/agents/"
"custom_agent_with_plugin_retrieval.ipynb): This introduces the concept of "
"retrieving many tools, which is useful when trying to work with arbitrarily "
"many plugins."
msgstr ""

#: ../docs/use_cases/agents/custom_agent_with_plugin_retrieval.ipynb:10007
msgid ""
"[Natural Language API Chains](../../modules/chains/examples/openapi.ipynb): "
"This creates Natural Language wrappers around OpenAPI endpoints. This is "
"useful because (1) plugins use OpenAPI endpoints under the hood, (2) "
"wrapping them in an NLAChain allows the router agent to call it more easily."
msgstr ""

#: ../docs/use_cases/agents/custom_agent_with_plugin_retrieval.ipynb:10009
msgid ""
"The novel idea introduced in this notebook is the idea of using retrieval to "
"select not the tools explicitly, but the set of OpenAPI specs to use. We can "
"then generate tools from those OpenAPI specs. The use case for this is when "
"trying to get agents to use plugins. It may be more efficient to choose "
"plugins first, then the endpoints, rather than the endpoints directly. This "
"is because the plugins may contain more useful information for selection."
msgstr ""

#: ../docs/use_cases/agents/custom_agent_with_plugin_retrieval.ipynb:20002
#: ../docs/use_cases/agents/custom_agent_with_plugin_retrieval_using_plugnplai.ipynb:20002
msgid "Set up environment"
msgstr ""

#: ../docs/use_cases/agents/custom_agent_with_plugin_retrieval.ipynb:20004
#: ../docs/use_cases/agents/custom_agent_with_plugin_retrieval_using_plugnplai.ipynb:20004
msgid "Do necessary imports, etc."
msgstr ""

#: ../docs/use_cases/agents/custom_agent_with_plugin_retrieval.ipynb:40002
#: ../docs/use_cases/agents/custom_agent_with_plugin_retrieval_using_plugnplai.ipynb:60002
msgid "Setup LLM"
msgstr ""

#: ../docs/use_cases/agents/custom_agent_with_plugin_retrieval.ipynb:60002
#: ../docs/use_cases/agents/custom_agent_with_plugin_retrieval_using_plugnplai.ipynb:80002
msgid "Set up plugins"
msgstr ""

#: ../docs/use_cases/agents/custom_agent_with_plugin_retrieval.ipynb:60004
#: ../docs/use_cases/agents/custom_agent_with_plugin_retrieval_using_plugnplai.ipynb:80004
msgid "Load and index plugins"
msgstr ""

#: ../docs/use_cases/agents/custom_agent_with_plugin_retrieval.ipynb:80002
#: ../docs/use_cases/agents/custom_agent_with_plugin_retrieval_using_plugnplai.ipynb:100002
msgid "Tool Retriever"
msgstr ""

#: ../docs/use_cases/agents/custom_agent_with_plugin_retrieval.ipynb:80004
#: ../docs/use_cases/agents/custom_agent_with_plugin_retrieval_using_plugnplai.ipynb:100004
msgid ""
"We will use a vectorstore to create embeddings for each tool description. "
"Then, for an incoming query we can create embeddings for that query and do a "
"similarity search for relevant tools."
msgstr ""

#: ../docs/use_cases/agents/custom_agent_with_plugin_retrieval.ipynb:120002
#: ../docs/use_cases/agents/custom_agent_with_plugin_retrieval_using_plugnplai.ipynb:140002
msgid "We can now test this retriever to see if it seems to work."
msgstr ""

#: ../docs/use_cases/agents/custom_agent_with_plugin_retrieval.ipynb:150002
#: ../docs/use_cases/agents/custom_agent_with_plugin_retrieval_using_plugnplai.ipynb:170002
msgid "Prompt Template"
msgstr ""

#: ../docs/use_cases/agents/custom_agent_with_plugin_retrieval.ipynb:150004
#: ../docs/use_cases/agents/custom_agent_with_plugin_retrieval_using_plugnplai.ipynb:170004
msgid ""
"The prompt template is pretty standard, because we're not actually changing "
"that much logic in the actual prompt template, but rather we are just "
"changing how retrieval is done."
msgstr ""

#: ../docs/use_cases/agents/custom_agent_with_plugin_retrieval.ipynb:170002
#: ../docs/use_cases/agents/custom_agent_with_plugin_retrieval_using_plugnplai.ipynb:190002
msgid ""
"The custom prompt template now has the concept of a tools_getter, which we "
"call on the input to select the tools to use"
msgstr ""

#: ../docs/use_cases/agents/custom_agent_with_plugin_retrieval.ipynb:200002
#: ../docs/use_cases/agents/custom_agent_with_plugin_retrieval_using_plugnplai.ipynb:220002
msgid "Output Parser"
msgstr ""

#: ../docs/use_cases/agents/custom_agent_with_plugin_retrieval.ipynb:200004
#: ../docs/use_cases/agents/custom_agent_with_plugin_retrieval_using_plugnplai.ipynb:220004
msgid ""
"The output parser is unchanged from the previous notebook, since we are not "
"changing anything about the output format."
msgstr ""

#: ../docs/use_cases/agents/custom_agent_with_plugin_retrieval.ipynb:230002
#: ../docs/use_cases/agents/custom_agent_with_plugin_retrieval_using_plugnplai.ipynb:250002
msgid "Set up LLM, stop sequence, and the agent"
msgstr ""

#: ../docs/use_cases/agents/custom_agent_with_plugin_retrieval.ipynb:230004
#: ../docs/use_cases/agents/custom_agent_with_plugin_retrieval_using_plugnplai.ipynb:250004
msgid "Also the same as the previous notebook"
msgstr ""

#: ../docs/use_cases/agents/custom_agent_with_plugin_retrieval.ipynb:270002
#: ../docs/use_cases/agents/custom_agent_with_plugin_retrieval_using_plugnplai.ipynb:290002
msgid "Use the Agent"
msgstr ""

#: ../docs/use_cases/agents/custom_agent_with_plugin_retrieval.ipynb:270004
#: ../docs/use_cases/agents/custom_agent_with_plugin_retrieval_using_plugnplai.ipynb:290004
msgid "Now we can use it!"
msgstr ""

#: ../docs/use_cases/agents/custom_agent_with_plugin_retrieval_using_plugnplai.ipynb:10002
msgid "Plug-and-Plai"
msgstr ""

#: ../docs/use_cases/agents/custom_agent_with_plugin_retrieval_using_plugnplai.ipynb:10004
msgid ""
"This notebook builds upon the idea of [tool retrieval]"
"(custom_agent_with_plugin_retrieval.html), but pulls all tools from "
"`plugnplai` - a directory of AI Plugins."
msgstr ""

#: ../docs/use_cases/agents/custom_agent_with_plugin_retrieval_using_plugnplai.ipynb:30002
msgid ""
"Install plugnplai lib to get a list of active plugins from https://plugplai."
"com directory"
msgstr ""

#: ../docs/use_cases/agents/sales_agent_with_context.ipynb:10002
msgid "SalesGPT - Your Context-Aware AI Sales Assistant"
msgstr ""

#: ../docs/use_cases/agents/sales_agent_with_context.ipynb:10004
msgid ""
"This notebook demonstrates an implementation of a **Context-Aware** AI Sales "
"agent."
msgstr ""

#: ../docs/use_cases/agents/sales_agent_with_context.ipynb:10006
msgid ""
"This notebook was originally published at [filipmichalsky/SalesGPT](https://"
"github.com/filip-michalsky/SalesGPT) by [@FilipMichalsky](https://twitter."
"com/FilipMichalsky)."
msgstr ""

#: ../docs/use_cases/agents/sales_agent_with_context.ipynb:10008
msgid ""
"SalesGPT is context-aware, which means it can understand what section of a "
"sales conversation it is in and act accordingly."
msgstr ""

#: ../docs/use_cases/agents/sales_agent_with_context.ipynb:10010
msgid ""
"As such, this agent can have a natural sales conversation with a prospect "
"and behaves based on the conversation stage. Hence, this notebook "
"demonstrates how we can use AI to automate sales development representatives "
"activites, such as outbound sales calls."
msgstr ""

#: ../docs/use_cases/agents/sales_agent_with_context.ipynb:10012
msgid ""
"We leverage the [`langchain`](https://github.com/hwchase17/langchain) "
"library in this implementation and are inspired by [BabyAGI](https://github."
"com/yoheinakajima/babyagi) architecture ."
msgstr ""

#: ../docs/use_cases/agents/sales_agent_with_context.ipynb:20002
msgid "Import Libraries and Set Up Your Environment"
msgstr ""

#: ../docs/use_cases/agents/sales_agent_with_context.ipynb:40002
msgid "SalesGPT architecture"
msgstr ""

#: ../docs/use_cases/agents/sales_agent_with_context.ipynb:50002
msgid "Seed the SalesGPT agent"
msgstr ""

#: ../docs/use_cases/agents/sales_agent_with_context.ipynb:50003
msgid "Run Sales Agent"
msgstr ""

#: ../docs/use_cases/agents/sales_agent_with_context.ipynb:50004
msgid ""
"Run Sales Stage Recognition Agent to recognize which stage is the sales "
"agent at and adjust their behaviour accordingly."
msgstr ""

#: ../docs/use_cases/agents/sales_agent_with_context.ipynb:60002
msgid "Here is the schematic of the architecture:"
msgstr ""

#: ../docs/use_cases/agents/sales_agent_with_context.ipynb:70002
msgid "Architecture diagram"
msgstr ""

#: ../docs/use_cases/agents/sales_agent_with_context.ipynb:80002
msgid "Sales conversation stages."
msgstr ""

#: ../docs/use_cases/agents/sales_agent_with_context.ipynb:80004
msgid ""
"The agent employs an assistant who keeps it in check as in what stage of the "
"conversation it is in. These stages were generated by ChatGPT and can be "
"easily modified to fit other use cases or modes of conversation."
msgstr ""

#: ../docs/use_cases/agents/sales_agent_with_context.ipynb:80006
msgid ""
"Introduction: Start the conversation by introducing yourself and your "
"company. Be polite and respectful while keeping the tone of the conversation "
"professional."
msgstr ""

#: ../docs/use_cases/agents/sales_agent_with_context.ipynb:80008
msgid ""
"Qualification: Qualify the prospect by confirming if they are the right "
"person to talk to regarding your product/service. Ensure that they have the "
"authority to make purchasing decisions."
msgstr ""

#: ../docs/use_cases/agents/sales_agent_with_context.ipynb:80010
msgid ""
"Value proposition: Briefly explain how your product/service can benefit the "
"prospect. Focus on the unique selling points and value proposition of your "
"product/service that sets it apart from competitors."
msgstr ""

#: ../docs/use_cases/agents/sales_agent_with_context.ipynb:80012
msgid ""
"Needs analysis: Ask open-ended questions to uncover the prospect's needs and "
"pain points. Listen carefully to their responses and take notes."
msgstr ""

#: ../docs/use_cases/agents/sales_agent_with_context.ipynb:80014
msgid ""
"Solution presentation: Based on the prospect's needs, present your product/"
"service as the solution that can address their pain points."
msgstr ""

#: ../docs/use_cases/agents/sales_agent_with_context.ipynb:80016
msgid ""
"Objection handling: Address any objections that the prospect may have "
"regarding your product/service. Be prepared to provide evidence or "
"testimonials to support your claims."
msgstr ""

#: ../docs/use_cases/agents/sales_agent_with_context.ipynb:80018
msgid ""
"Close: Ask for the sale by proposing a next step. This could be a demo, a "
"trial or a meeting with decision-makers. Ensure to summarize what has been "
"discussed and reiterate the benefits."
msgstr ""

#: ../docs/use_cases/agents/sales_agent_with_context.ipynb:150002
msgid "Set up the SalesGPT Controller with the Sales Agent and Stage Analyzer"
msgstr ""

#: ../docs/use_cases/agents/sales_agent_with_context.ipynb:170002
msgid "Set up the AI Sales Agent and start the conversation"
msgstr ""

#: ../docs/use_cases/agents/sales_agent_with_context.ipynb:180002
msgid "Set up the agent"
msgstr ""

#: ../docs/use_cases/agents/sales_agent_with_context.ipynb:200002
msgid "Run the agent"
msgstr ""

#: ../docs/use_cases/agents/wikibase_agent.ipynb:10002
msgid "Wikibase Agent"
msgstr ""

#: ../docs/use_cases/agents/wikibase_agent.ipynb:10004
msgid ""
"This notebook demonstrates a very simple wikibase agent that uses sparql "
"generation. Although this code is intended to work against any wikibase "
"instance, we use http://wikidata.org for testing."
msgstr ""

#: ../docs/use_cases/agents/wikibase_agent.ipynb:10007
msgid ""
"If you are interested in wikibases and sparql, please consider helping to "
"improve this agent. Look [here](https://github.com/donaldziff/langchain-"
"wikibase) for more details and open questions."
msgstr ""

#: ../docs/use_cases/agents/wikibase_agent.ipynb:20002
msgid "Preliminaries"
msgstr ""

#: ../docs/use_cases/agents/wikibase_agent.ipynb:30002
msgid "API keys and other secrats"
msgstr ""

#: ../docs/use_cases/agents/wikibase_agent.ipynb:30004
msgid "We use an `.ini` file, like this:"
msgstr ""

#: ../docs/use_cases/agents/wikibase_agent.ipynb:50002
msgid "OpenAI API Key"
msgstr ""

#: ../docs/use_cases/agents/wikibase_agent.ipynb:50004
msgid ""
"An OpenAI API key is required unless you modify the code below to use "
"another LLM provider."
msgstr ""

#: ../docs/use_cases/agents/wikibase_agent.ipynb:70002
msgid "Wikidata user-agent header"
msgstr ""

#: ../docs/use_cases/agents/wikibase_agent.ipynb:70004
msgid ""
"Wikidata policy requires a user-agent header. See https://meta.wikimedia.org/"
"wiki/User-Agent_policy. However, at present this policy is not strictly "
"enforced."
msgstr ""

#: ../docs/use_cases/agents/wikibase_agent.ipynb:90002
msgid "Enable tracing if desired"
msgstr ""

#: ../docs/use_cases/agents/wikibase_agent.ipynb:110004
msgid "Three tools are provided for this simple agent:"
msgstr ""

#: ../docs/use_cases/agents/wikibase_agent.ipynb:110005
msgid "`ItemLookup`: for finding the q-number of an item"
msgstr ""

#: ../docs/use_cases/agents/wikibase_agent.ipynb:110006
msgid "`PropertyLookup`: for finding the p-number of a property"
msgstr ""

#: ../docs/use_cases/agents/wikibase_agent.ipynb:110007
msgid "`SparqlQueryRunner`: for running a sparql query"
msgstr ""

#: ../docs/use_cases/agents/wikibase_agent.ipynb:120002
msgid "Item and Property lookup"
msgstr ""

#: ../docs/use_cases/agents/wikibase_agent.ipynb:120004
msgid ""
"Item and Property lookup are implemented in a single method, using an "
"elastic search endpoint. Not all wikibase instances have it, but wikidata "
"does, and that's where we'll start."
msgstr ""

#: ../docs/use_cases/agents/wikibase_agent.ipynb:170002
msgid "Sparql runner"
msgstr ""

#: ../docs/use_cases/agents/wikibase_agent.ipynb:180002
msgid "This tool runs sparql - by default, wikidata is used."
msgstr ""

#: ../docs/use_cases/agents/wikibase_agent.ipynb:210002
msgid "Agent"
msgstr ""

#: ../docs/use_cases/agents/wikibase_agent.ipynb:220002
msgid "Wrap the tools"
msgstr ""

#: ../docs/use_cases/agents/wikibase_agent.ipynb:290002
msgid "Output parser"
msgstr ""

#: ../docs/use_cases/agents/wikibase_agent.ipynb:290003
msgid "This is unchanged from langchain docs"
msgstr ""

#: ../docs/use_cases/agents/wikibase_agent.ipynb:320002
msgid "Specify the LLM model"
msgstr ""

#: ../docs/use_cases/agents/wikibase_agent.ipynb:340002
msgid "Agent and agent executor"
msgstr ""

#: ../docs/use_cases/agents/wikibase_agent.ipynb:380002
msgid "Run it!"
msgstr ""

#: ../docs/use_cases/apis.md:1
msgid "Interacting with APIs"
msgstr ""

#: ../docs/use_cases/apis.md:3
msgid "[Conceptual Guide](https://docs.langchain.com/docs/use-cases/apis)"
msgstr ""

#: ../docs/use_cases/apis.md:6
msgid ""
"Lots of data and information is stored behind APIs. This page covers all "
"resources available in LangChain for working with APIs."
msgstr ""

#: ../docs/use_cases/apis.md:11
msgid ""
"If you are just getting started, and you have relatively simple apis, you "
"should get started with chains. Chains are a sequence of predetermined "
"steps, so they are good to get started with as they give you more control "
"and let you  understand what is happening better."
msgstr ""

#: ../docs/use_cases/apis.md:15
msgid "[API Chain](../modules/chains/examples/api.ipynb)"
msgstr ""

#: ../docs/use_cases/apis.md:19
msgid ""
"Agents are more complex, and involve multiple queries to the LLM to "
"understand what to do. The downside of agents are that you have less "
"control. The upside is that they are more powerful, which allows you to use "
"them on larger and more complex schemas."
msgstr ""

#: ../docs/use_cases/apis.md:23
msgid "[OpenAPI Agent](../modules/agents/toolkits/examples/openapi.ipynb)"
msgstr ""

#: ../docs/use_cases/autonomous_agents.md:4
msgid ""
"Autonomous Agents are agents that designed to be more long running. You give "
"them one or multiple long term goals, and they independently execute towards "
"those goals. The applications combine tool usage and long term memory."
msgstr ""

#: ../docs/use_cases/autonomous_agents.md:8
msgid ""
"At the moment, Autonomous Agents are fairly experimental and based off of "
"other open-source projects. By implementing these open source projects in "
"LangChain primitives we can get the benefits of LangChain -  easy switching "
"an experimenting with multiple LLMs, usage of different vectorstores as "
"memory,  usage of LangChain's collection of tools."
msgstr ""

#: ../docs/use_cases/autonomous_agents.md:13
msgid "Baby AGI ([Original Repo](https://github.com/yoheinakajima/babyagi))"
msgstr ""

#: ../docs/use_cases/autonomous_agents.md:15
msgid ""
"[Baby AGI](autonomous_agents/baby_agi.ipynb): a notebook implementing "
"BabyAGI as LLM Chains"
msgstr ""

#: ../docs/use_cases/autonomous_agents.md:16
msgid ""
"[Baby AGI with Tools](autonomous_agents/baby_agi_with_agent.ipynb): building "
"off the above notebook, this example substitutes in an agent with tools as "
"the execution tools, allowing it to actually take actions."
msgstr ""

#: ../docs/use_cases/autonomous_agents.md:19
msgid ""
"AutoGPT ([Original Repo](https://github.com/Significant-Gravitas/Auto-GPT))"
msgstr ""

#: ../docs/use_cases/autonomous_agents.md:20
msgid ""
"[AutoGPT](autonomous_agents/autogpt.ipynb): a notebook implementing AutoGPT "
"in LangChain primitives"
msgstr ""

#: ../docs/use_cases/autonomous_agents.md:21
msgid ""
"[WebSearch Research Assistant](autonomous_agents/marathon_times.ipynb): a "
"notebook showing how to use AutoGPT plus specific tools to act as research "
"assistant that can use the web."
msgstr ""

#: ../docs/use_cases/autonomous_agents.md:23
msgid "MetaPrompt ([Original Repo](https://github.com/ngoodman/metaprompt))"
msgstr ""

#: ../docs/use_cases/autonomous_agents.md:24
msgid ""
"[Meta-Prompt](autonomous_agents/meta_prompt.ipynb): a notebook implementing "
"Meta-Prompt in LangChain primitives"
msgstr ""

#: ../docs/use_cases/autonomous_agents/autogpt.ipynb:10002
msgid "AutoGPT"
msgstr ""

#: ../docs/use_cases/autonomous_agents/autogpt.ipynb:10004
msgid ""
"Implementation of https://github.com/Significant-Gravitas/Auto-GPT but with "
"LangChain primitives (LLMs, PromptTemplates, VectorStores, Embeddings, Tools)"
msgstr ""

#: ../docs/use_cases/autonomous_agents/autogpt.ipynb:20002
#: ../docs/use_cases/autonomous_agents/marathon_times.ipynb:50002
msgid "Set up tools"
msgstr ""

#: ../docs/use_cases/autonomous_agents/autogpt.ipynb:20004
msgid ""
"We'll set up an AutoGPT with a search tool, and write-file tool, and a read-"
"file tool"
msgstr ""

#: ../docs/use_cases/autonomous_agents/autogpt.ipynb:40002
#: ../docs/use_cases/autonomous_agents/marathon_times.ipynb:140002
msgid "Set up memory"
msgstr ""

#: ../docs/use_cases/autonomous_agents/autogpt.ipynb:40004
#: ../docs/use_cases/autonomous_agents/marathon_times.ipynb:140004
msgid "The memory here is used for the agents intermediate steps"
msgstr ""

#: ../docs/use_cases/autonomous_agents/autogpt.ipynb:70002
#: ../docs/use_cases/autonomous_agents/marathon_times.ipynb:160002
msgid "Setup model and AutoGPT"
msgstr ""

#: ../docs/use_cases/autonomous_agents/autogpt.ipynb:70004
msgid "Initialize everything! We will use ChatOpenAI model"
msgstr ""

#: ../docs/use_cases/autonomous_agents/autogpt.ipynb:100002
msgid "Run an example"
msgstr ""

#: ../docs/use_cases/autonomous_agents/autogpt.ipynb:100004
msgid "Here we will make it write a weather report for SF"
msgstr ""

#: ../docs/use_cases/autonomous_agents/marathon_times.ipynb:10002
msgid "AutoGPT example finding Winning Marathon Times"
msgstr ""

#: ../docs/use_cases/autonomous_agents/marathon_times.ipynb:10004
msgid "Implementation of https://github.com/Significant-Gravitas/Auto-GPT"
msgstr ""

#: ../docs/use_cases/autonomous_agents/marathon_times.ipynb:10005
msgid ""
"With LangChain primitives (LLMs, PromptTemplates, VectorStores, Embeddings, "
"Tools)"
msgstr ""

#: ../docs/use_cases/autonomous_agents/marathon_times.ipynb:50004
msgid ""
"We'll set up an AutoGPT with a `search` tool, and `write-file` tool, and a "
"`read-file` tool, a web browsing tool, and a tool to interact with a CSV "
"file via a python REPL"
msgstr ""

#: ../docs/use_cases/autonomous_agents/marathon_times.ipynb:60002
msgid "Define any other `tools` you want to use below:"
msgstr ""

#: ../docs/use_cases/autonomous_agents/marathon_times.ipynb:80002
msgid "**Browse a web page with PlayWright**"
msgstr ""

#: ../docs/use_cases/autonomous_agents/marathon_times.ipynb:110002
msgid "**Q&A Over a webpage**"
msgstr ""

#: ../docs/use_cases/autonomous_agents/marathon_times.ipynb:110004
msgid ""
"Help the model ask more directed questions of web pages to avoid cluttering "
"its memory"
msgstr ""

#: ../docs/use_cases/autonomous_agents/marathon_times.ipynb:160004
msgid "`Model set-up`"
msgstr ""

#: ../docs/use_cases/autonomous_agents/marathon_times.ipynb:200002
msgid "AutoGPT for Querying the Web"
msgstr ""

#: ../docs/use_cases/autonomous_agents/marathon_times.ipynb:200005
msgid ""
"I've spent a lot of time over the years crawling data sources and cleaning "
"data. Let's see if AutoGPT can help with this!"
msgstr ""

#: ../docs/use_cases/autonomous_agents/marathon_times.ipynb:200007
msgid ""
"Here is the prompt for looking up recent boston marathon times and "
"converting them to tabular form."
msgstr ""

#: ../docs/use_cases/autonomous_agents/meta_prompt.ipynb:10002
msgid "Meta-Prompt"
msgstr ""

#: ../docs/use_cases/autonomous_agents/meta_prompt.ipynb:10004
msgid ""
"This is a LangChain implementation of [Meta-Prompt](https://noahgoodman."
"substack.com/p/meta-prompt-a-simple-self-improving), by [Noah Goodman]"
"(https://cocolab.stanford.edu/ndg), for building self-improving agents."
msgstr ""

#: ../docs/use_cases/autonomous_agents/meta_prompt.ipynb:10006
msgid ""
"The key idea behind Meta-Prompt is to prompt the agent to reflect on its own "
"performance and modify its own instructions."
msgstr ""

#: ../docs/use_cases/autonomous_agents/meta_prompt.ipynb:10008
msgid ""
"![figure](https://substackcdn.com/image/fetch/f_auto,q_auto:good,"
"fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com"
"%2Fpublic%2Fimages%2F468217b9-96d9-47c0-a08b-dbf6b21b9f49_492x384.png)"
msgstr ""

#: ../docs/use_cases/autonomous_agents/meta_prompt.ipynb:10008
msgid "figure"
msgstr ""

#: ../docs/use_cases/autonomous_agents/meta_prompt.ipynb:10010
msgid ""
"Here is a description from the [original blog post](https://noahgoodman."
"substack.com/p/meta-prompt-a-simple-self-improving):"
msgstr ""

#: ../docs/use_cases/autonomous_agents/meta_prompt.ipynb:10013
msgid ""
"The agent is a simple loop that starts with no instructions and follows "
"these steps:"
msgstr ""

#: ../docs/use_cases/autonomous_agents/meta_prompt.ipynb:10015
msgid ""
"Engage in conversation with a user, who may provide requests, instructions, "
"or feedback."
msgstr ""

#: ../docs/use_cases/autonomous_agents/meta_prompt.ipynb:10017
msgid ""
"At the end of the episode, generate self-criticism and a new instruction "
"using the meta-prompt"
msgstr ""

#: ../docs/use_cases/autonomous_agents/meta_prompt.ipynb:10032
msgid "Repeat."
msgstr ""

#: ../docs/use_cases/autonomous_agents/meta_prompt.ipynb:10034
msgid ""
"The only fixed instructions for this system (which I call Meta-prompt) is "
"the meta-prompt that governs revision of the agentâ€™s instructions. The agent "
"has no memory between episodes except for the instruction it modifies for "
"itself each time. Despite its simplicity, this agent can learn over time and "
"self-improve by incorporating useful details into its instructions."
msgstr ""

#: ../docs/use_cases/autonomous_agents/meta_prompt.ipynb:20003
msgid ""
"We define two chains. One serves as the `Assistant`, and the other is a "
"\"meta-chain\" that critiques the `Assistant`'s performance and modifies the "
"instructions to the `Assistant`."
msgstr ""

#: ../docs/use_cases/autonomous_agents/meta_prompt.ipynb:60002
msgid "Specify a task and interact with the agent"
msgstr ""

#: ../docs/use_cases/chatbots.md:1
msgid "Chatbots"
msgstr ""

#: ../docs/use_cases/chatbots.md:3
msgid "[Conceptual Guide](https://docs.langchain.com/docs/use-cases/chatbots)"
msgstr ""

#: ../docs/use_cases/chatbots.md:6
msgid ""
"Since language models are good at producing text, that makes them ideal for "
"creating chatbots. Aside from the base prompts/LLMs, an important concept to "
"know for Chatbots is `memory`. Most chat based applications rely on "
"remembering what happened in previous interactions, which `memory` is "
"designed to help with."
msgstr ""

#: ../docs/use_cases/chatbots.md:10 ../docs/use_cases/question_answering.md:60
#: ../docs/use_cases/question_answering.md:77
#: ../docs/use_cases/summarization.md:17
msgid "The following resources exist:"
msgstr ""

#: ../docs/use_cases/chatbots.md:11
msgid ""
"[ChatGPT Clone](../modules/agents/agent_executors/examples/chatgpt_clone."
"ipynb): A notebook walking through how to recreate a ChatGPT-like experience "
"with LangChain."
msgstr ""

#: ../docs/use_cases/chatbots.md:12
msgid ""
"[Conversation Memory](../modules/memory/getting_started.ipynb): A notebook "
"walking through how to use different types of conversational memory."
msgstr ""

#: ../docs/use_cases/chatbots.md:13
msgid ""
"[Conversation Agent](../modules/agents/agents/examples/conversational_agent."
"ipynb): A notebook walking through how to create an agent optimized for "
"conversation."
msgstr ""

#: ../docs/use_cases/chatbots.md:16 ../docs/use_cases/question_answering.md:84
#: ../docs/use_cases/summarization.md:20
msgid "Additional related resources include:"
msgstr ""

#: ../docs/use_cases/chatbots.md:17
msgid ""
"[Memory Key Concepts](../modules/memory.rst): Explanation of key concepts "
"related to memory."
msgstr ""

#: ../docs/use_cases/chatbots.md:18
msgid ""
"[Memory Examples](../modules/memory/how_to_guides.rst): A collection of how-"
"to examples for working with memory."
msgstr ""

#: ../docs/use_cases/chatbots.md:20
msgid "More end-to-end examples include:"
msgstr ""

#: ../docs/use_cases/chatbots.md:21
msgid ""
"[Voice Assistant](chatbots/voice_assistant.ipynb): A notebook walking "
"through how to create a voice assistant using LangChain."
msgstr ""

#: ../docs/use_cases/chatbots/voice_assistant.ipynb:10002
msgid "Voice Assistant"
msgstr ""

#: ../docs/use_cases/chatbots/voice_assistant.ipynb:10004
msgid ""
"This chain creates a clone of ChatGPT with a few modifications to make it a "
"voice assistant.  It uses the `pyttsx3` and `speech_recognition` libraries "
"to convert text to speech and speech to text respectively. The prompt "
"template is also changed to make it more suitable for voice assistant use."
msgstr ""

#: ../docs/use_cases/code.md:1
msgid "Code Understanding"
msgstr ""

#: ../docs/use_cases/code.md:5
msgid ""
"LangChain is a useful tool designed to parse GitHub code repositories. By "
"leveraging VectorStores, Conversational RetrieverChain, and GPT-4, it can "
"answer questions in the context of an entire GitHub repository or generate "
"new code. This documentation page outlines the essential components of the "
"system and guides using LangChain for better code comprehension, contextual "
"question answering, and code generation in GitHub repositories."
msgstr ""

#: ../docs/use_cases/code.md:7
msgid "Conversational Retriever Chain"
msgstr ""

#: ../docs/use_cases/code.md:9
msgid ""
"Conversational RetrieverChain is a retrieval-focused system that interacts "
"with the data stored in a VectorStore. Utilizing advanced techniques, like "
"context-aware filtering and ranking, it retrieves the most relevant code "
"snippets and information for a given user query. Conversational "
"RetrieverChain is engineered to deliver high-quality, pertinent results "
"while considering conversation history and context."
msgstr ""

#: ../docs/use_cases/code.md:11
msgid "LangChain Workflow for Code Understanding and Generation"
msgstr ""

#: ../docs/use_cases/code.md:13
msgid ""
"Index the code base: Clone the target repository, load all files within, "
"chunk the files, and execute the indexing process. Optionally, you can skip "
"this step and use an already indexed dataset."
msgstr ""

#: ../docs/use_cases/code.md:15
msgid ""
"Embedding and Code Store: Code snippets are embedded using a code-aware "
"embedding model and stored in a VectorStore. Query Understanding: GPT-4 "
"processes user queries, grasping the context and extracting relevant details."
msgstr ""

#: ../docs/use_cases/code.md:18
msgid ""
"Construct the Retriever: Conversational RetrieverChain searches the "
"VectorStore to identify the most relevant code snippets for a given query."
msgstr ""

#: ../docs/use_cases/code.md:20
msgid ""
"Build the Conversational Chain: Customize the retriever settings and define "
"any user-defined filters as needed."
msgstr ""

#: ../docs/use_cases/code.md:22
msgid ""
"Ask questions: Define a list of questions to ask about the codebase, and "
"then use the ConversationalRetrievalChain to generate context-aware answers. "
"The LLM (GPT-4) generates comprehensive, context-aware answers based on "
"retrieved code snippets and conversation history."
msgstr ""

#: ../docs/use_cases/code.md:24
msgid "The full tutorial is available below."
msgstr ""

#: ../docs/use_cases/code.md:25
msgid ""
"[Twitter the-algorithm codebase analysis with Deep Lake](code/twitter-the-"
"algorithm-analysis-deeplake.ipynb): A notebook walking through how to parse "
"github source code and run queries conversation."
msgstr ""

#: ../docs/use_cases/code.md:26
msgid ""
"[LangChain codebase analysis with Deep Lake](code/code-analysis-deeplake."
"ipynb): A notebook walking through how to analyze and do question answering "
"over THIS code base."
msgstr ""

#: ../docs/use_cases/code/code-analysis-deeplake.ipynb:10002
msgid "Use LangChain, GPT and Deep Lake to work with code base"
msgstr ""

#: ../docs/use_cases/code/code-analysis-deeplake.ipynb:10003
msgid ""
"In this tutorial, we are going to use Langchain + Deep Lake with GPT to "
"analyze the code base of the LangChain itself."
msgstr ""

#: ../docs/use_cases/code/code-analysis-deeplake.ipynb:20002
msgid "Design"
msgstr ""

#: ../docs/use_cases/code/code-analysis-deeplake.ipynb:30002
msgid "Prepare data:"
msgstr ""

#: ../docs/use_cases/code/code-analysis-deeplake.ipynb:30003
msgid ""
"Upload all python project files using the `langchain.document_loaders."
"TextLoader`. We will call these files the **documents**."
msgstr ""

#: ../docs/use_cases/code/code-analysis-deeplake.ipynb:30004
msgid ""
"Split all documents to chunks using the `langchain.text_splitter."
"CharacterTextSplitter`."
msgstr ""

#: ../docs/use_cases/code/code-analysis-deeplake.ipynb:30005
msgid ""
"Embed chunks and upload them into the DeepLake using `langchain.embeddings."
"openai.OpenAIEmbeddings` and `langchain.vectorstores.DeepLake`"
msgstr ""

#: ../docs/use_cases/code/code-analysis-deeplake.ipynb:30006
msgid "Question-Answering:"
msgstr ""

#: ../docs/use_cases/code/code-analysis-deeplake.ipynb:30007
msgid ""
"Build a chain from `langchain.chat_models.ChatOpenAI` and `langchain.chains."
"ConversationalRetrievalChain`"
msgstr ""

#: ../docs/use_cases/code/code-analysis-deeplake.ipynb:30008
msgid "Prepare questions."
msgstr ""

#: ../docs/use_cases/code/code-analysis-deeplake.ipynb:30009
msgid "Get answers running the chain."
msgstr ""

#: ../docs/use_cases/code/code-analysis-deeplake.ipynb:40002
msgid "Implementation"
msgstr ""

#: ../docs/use_cases/code/code-analysis-deeplake.ipynb:50002
msgid "Integration preparations"
msgstr ""

#: ../docs/use_cases/code/code-analysis-deeplake.ipynb:60002
msgid ""
"We need to set up keys for external services and install necessary python "
"libraries."
msgstr ""

#: ../docs/use_cases/code/code-analysis-deeplake.ipynb:80002
msgid ""
"Set up OpenAI embeddings, Deep Lake multi-modal vector store api and "
"authenticate."
msgstr ""

#: ../docs/use_cases/code/code-analysis-deeplake.ipynb:80004
msgid ""
"For full documentation of Deep Lake please follow https://docs.activeloop."
"ai/ and API reference https://docs.deeplake.ai/en/latest/"
msgstr ""

#: ../docs/use_cases/code/code-analysis-deeplake.ipynb:100002
msgid ""
"Authenticate into Deep Lake if you want to create your own dataset and "
"publish it. You can get an API key from the platform at [app.activeloop.ai]"
"(https://app.activeloop.ai)"
msgstr ""

#: ../docs/use_cases/code/code-analysis-deeplake.ipynb:120002
msgid "Prepare data"
msgstr ""

#: ../docs/use_cases/code/code-analysis-deeplake.ipynb:130002
msgid ""
"Load all repository files. Here we assume this notebook is downloaded as the "
"part of the langchain fork and we work with the python files of the "
"`langchain` repo."
msgstr ""

#: ../docs/use_cases/code/code-analysis-deeplake.ipynb:130004
msgid ""
"If you want to use files from different repo, change `root_dir` to the root "
"dir of your repo."
msgstr ""

#: ../docs/use_cases/code/code-analysis-deeplake.ipynb:150002
#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:110002
msgid "Then, chunk the files"
msgstr ""

#: ../docs/use_cases/code/code-analysis-deeplake.ipynb:170002
msgid "Then embed chunks and upload them to the DeepLake."
msgstr ""

#: ../docs/use_cases/code/code-analysis-deeplake.ipynb:170004
msgid "This can take several minutes."
msgstr ""

#: ../docs/use_cases/code/code-analysis-deeplake.ipynb:200002
#: ../docs/use_cases/evaluation/question_answering.ipynb:10002
msgid "Question Answering"
msgstr ""

#: ../docs/use_cases/code/code-analysis-deeplake.ipynb:200003
#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:150003
msgid ""
"First load the dataset, construct the retriever, then construct the "
"Conversational Chain"
msgstr ""

#: ../docs/use_cases/code/code-analysis-deeplake.ipynb:230002
#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:180002
msgid ""
"You can also specify user defined functions using [Deep Lake filters]"
"(https://docs.deeplake.ai/en/latest/deeplake.core.dataset.html#deeplake.core."
"dataset.Dataset.filter)"
msgstr ""

#: ../docs/use_cases/code/code-analysis-deeplake.ipynb:270002
msgid "-> **Question**: What is the class hierarchy?"
msgstr ""

#: ../docs/use_cases/code/code-analysis-deeplake.ipynb:270004
msgid ""
"**Answer**: There are several class hierarchies in the provided code, so "
"I'll list a few:"
msgstr ""

#: ../docs/use_cases/code/code-analysis-deeplake.ipynb:270006
msgid ""
"`BaseModel` -> `ConstitutionalPrinciple`: `ConstitutionalPrinciple` is a "
"subclass of `BaseModel`."
msgstr ""

#: ../docs/use_cases/code/code-analysis-deeplake.ipynb:270007
msgid ""
"`BasePromptTemplate` -> `StringPromptTemplate`, `AIMessagePromptTemplate`, "
"`BaseChatPromptTemplate`, `ChatMessagePromptTemplate`, `ChatPromptTemplate`, "
"`HumanMessagePromptTemplate`, `MessagesPlaceholder`, "
"`SystemMessagePromptTemplate`, `FewShotPromptTemplate`, "
"`FewShotPromptWithTemplates`, `Prompt`, `PromptTemplate`: All of these "
"classes are subclasses of `BasePromptTemplate`."
msgstr ""

#: ../docs/use_cases/code/code-analysis-deeplake.ipynb:270008
msgid ""
"`APIChain`, `Chain`, `MapReduceDocumentsChain`, `MapRerankDocumentsChain`, "
"`RefineDocumentsChain`, `StuffDocumentsChain`, "
"`HypotheticalDocumentEmbedder`, `LLMChain`, `LLMBashChain`, "
"`LLMCheckerChain`, `LLMMathChain`, `LLMRequestsChain`, `PALChain`, "
"`QAWithSourcesChain`, `VectorDBQAWithSourcesChain`, `VectorDBQA`, "
"`SQLDatabaseChain`: All of these classes are subclasses of `Chain`."
msgstr ""

#: ../docs/use_cases/code/code-analysis-deeplake.ipynb:270009
msgid "`BaseLoader`: `BaseLoader` is a subclass of `ABC`."
msgstr ""

#: ../docs/use_cases/code/code-analysis-deeplake.ipynb:270010
msgid ""
"`BaseTracer` -> `ChainRun`, `LLMRun`, `SharedTracer`, `ToolRun`, `Tracer`, "
"`TracerException`, `TracerSession`: All of these classes are subclasses of "
"`BaseTracer`."
msgstr ""

#: ../docs/use_cases/code/code-analysis-deeplake.ipynb:270011
msgid ""
"`OpenAIEmbeddings`, `HuggingFaceEmbeddings`, `CohereEmbeddings`, "
"`JinaEmbeddings`, `LlamaCppEmbeddings`, `HuggingFaceHubEmbeddings`, "
"`TensorflowHubEmbeddings`, `SagemakerEndpointEmbeddings`, "
"`HuggingFaceInstructEmbeddings`, `SelfHostedEmbeddings`, "
"`SelfHostedHuggingFaceEmbeddings`, "
"`SelfHostedHuggingFaceInstructEmbeddings`, `FakeEmbeddings`, "
"`AlephAlphaAsymmetricSemanticEmbedding`, "
"`AlephAlphaSymmetricSemanticEmbedding`: All of these classes are subclasses "
"of `BaseLLM`."
msgstr ""

#: ../docs/use_cases/code/code-analysis-deeplake.ipynb:270014
msgid "-> **Question**: What classes are derived from the Chain class?"
msgstr ""

#: ../docs/use_cases/code/code-analysis-deeplake.ipynb:270016
msgid ""
"**Answer**: There are multiple classes that are derived from the Chain "
"class. Some of them are:"
msgstr ""

#: ../docs/use_cases/code/code-analysis-deeplake.ipynb:270017
msgid "APIChain"
msgstr ""

#: ../docs/use_cases/code/code-analysis-deeplake.ipynb:270018
msgid "AnalyzeDocumentChain"
msgstr ""

#: ../docs/use_cases/code/code-analysis-deeplake.ipynb:270019
msgid "ChatVectorDBChain"
msgstr ""

#: ../docs/use_cases/code/code-analysis-deeplake.ipynb:270020
msgid "CombineDocumentsChain"
msgstr ""

#: ../docs/use_cases/code/code-analysis-deeplake.ipynb:270021
msgid "ConstitutionalChain"
msgstr ""

#: ../docs/use_cases/code/code-analysis-deeplake.ipynb:270022
msgid "ConversationChain"
msgstr ""

#: ../docs/use_cases/code/code-analysis-deeplake.ipynb:270023
msgid "GraphQAChain"
msgstr ""

#: ../docs/use_cases/code/code-analysis-deeplake.ipynb:270024
msgid "HypotheticalDocumentEmbedder"
msgstr ""

#: ../docs/use_cases/code/code-analysis-deeplake.ipynb:270025
msgid "LLMChain"
msgstr ""

#: ../docs/use_cases/code/code-analysis-deeplake.ipynb:270026
msgid "LLMCheckerChain"
msgstr ""

#: ../docs/use_cases/code/code-analysis-deeplake.ipynb:270027
msgid "LLMRequestsChain"
msgstr ""

#: ../docs/use_cases/code/code-analysis-deeplake.ipynb:270028
msgid "LLMSummarizationCheckerChain"
msgstr ""

#: ../docs/use_cases/code/code-analysis-deeplake.ipynb:270029
msgid "MapReduceChain"
msgstr ""

#: ../docs/use_cases/code/code-analysis-deeplake.ipynb:270030
msgid "OpenAPIEndpointChain"
msgstr ""

#: ../docs/use_cases/code/code-analysis-deeplake.ipynb:270031
msgid "PALChain"
msgstr ""

#: ../docs/use_cases/code/code-analysis-deeplake.ipynb:270032
msgid "QAWithSourcesChain"
msgstr ""

#: ../docs/use_cases/code/code-analysis-deeplake.ipynb:270033
msgid "RetrievalQA"
msgstr ""

#: ../docs/use_cases/code/code-analysis-deeplake.ipynb:270034
msgid "RetrievalQAWithSourcesChain"
msgstr ""

#: ../docs/use_cases/code/code-analysis-deeplake.ipynb:270035
msgid "SequentialChain"
msgstr ""

#: ../docs/use_cases/code/code-analysis-deeplake.ipynb:270036
msgid "SQLDatabaseChain"
msgstr ""

#: ../docs/use_cases/code/code-analysis-deeplake.ipynb:270037
msgid "TransformChain"
msgstr ""

#: ../docs/use_cases/code/code-analysis-deeplake.ipynb:270038
msgid "VectorDBQA"
msgstr ""

#: ../docs/use_cases/code/code-analysis-deeplake.ipynb:270039
msgid "VectorDBQAWithSourcesChain"
msgstr ""

#: ../docs/use_cases/code/code-analysis-deeplake.ipynb:270041
msgid ""
"There might be more classes that are derived from the Chain class as it is "
"possible to create custom classes that extend the Chain class."
msgstr ""

#: ../docs/use_cases/code/code-analysis-deeplake.ipynb:270044
msgid ""
"-> **Question**: What classes and functions in the ./langchain/utilities/ "
"forlder are not covered by unit tests?"
msgstr ""

#: ../docs/use_cases/code/code-analysis-deeplake.ipynb:270046
msgid ""
"**Answer**: All classes and functions in the `./langchain/utilities/` folder "
"seem to have unit tests written for them."
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:10002
msgid ""
"Analysis of Twitter the-algorithm source code with LangChain, GPT4 and Deep "
"Lake"
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:10003
msgid ""
"In this tutorial, we are going to use Langchain + Deep Lake with GPT4 to "
"analyze the code base of the twitter algorithm."
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:30002
msgid ""
"Define OpenAI embeddings, Deep Lake multi-modal vector store api and "
"authenticate. For full documentation of Deep Lake please follow [docs]"
"(https://docs.activeloop.ai/) and [API reference](https://docs.deeplake.ai/"
"en/latest/)."
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:30004
msgid ""
"Authenticate into Deep Lake if you want to create your own dataset and "
"publish it. You can get an API key from the [platform](https://app."
"activeloop.ai)"
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:60002
msgid ""
"disallowed_special=() is required to avoid `Exception: 'utf-8' codec can't "
"decode byte 0xff in position 0: invalid start byte` from tiktoken for some "
"repositories"
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:70002
msgid "1. Index the code base (optional)"
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:70003
msgid ""
"You can directly skip this part and directly jump into using already indexed "
"dataset. To begin with, first we will clone the repository, then parse and "
"chunk the code base and use OpenAI indexing."
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:90002
msgid "Load all files inside the repository"
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:130002
msgid ""
"Execute the indexing. This will take about ~4 mins to compute embeddings and "
"upload to Activeloop. You can then publish the dataset to be public."
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:150002
msgid "2. Question Answering on Twitter algorithm codebase"
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:220002
msgid "-> **Question**: What does favCountParams do?"
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:220004
msgid ""
"**Answer**: `favCountParams` is an optional ThriftLinearFeatureRankingParams "
"instance that represents the parameters related to the \"favorite count\" "
"feature in the ranking process. It is used to control the weight of the "
"favorite count feature while ranking tweets. The favorite count is the "
"number of times a tweet has been marked as a favorite by users, and it is "
"considered an important signal in the ranking of tweets. By using "
"`favCountParams`, the system can adjust the importance of the favorite count "
"while calculating the final ranking score of a tweet."
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:220006
msgid "-> **Question**: is it Likes + Bookmarks, or not clear from the code?"
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:220008
msgid ""
"**Answer**: From the provided code, it is not clear if the favorite count "
"metric is determined by the sum of likes and bookmarks. The favorite count "
"is mentioned in the code, but there is no explicit reference to how it is "
"calculated in terms of likes and bookmarks."
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:220010
msgid ""
"-> **Question**: What are the major negative modifiers that lower your "
"linear ranking parameters?"
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:220012
msgid ""
"**Answer**: In the given code, major negative modifiers that lower the "
"linear ranking parameters are:"
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:220014
msgid ""
"`scoringData.querySpecificScore`: This score adjustment is based on the "
"query-specific information. If its value is negative, it will lower the "
"linear ranking parameters."
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:220016
msgid ""
"`scoringData.authorSpecificScore`: This score adjustment is based on the "
"author-specific information. If its value is negative, it will also lower "
"the linear ranking parameters."
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:220018
msgid ""
"Please note that I cannot provide more information on the exact calculations "
"of these negative modifiers, as the code for their determination is not "
"provided."
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:220020
msgid "-> **Question**: How do you get assigned to SimClusters?"
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:220022
msgid ""
"**Answer**: The assignment to SimClusters occurs through a Metropolis-"
"Hastings sampling-based community detection algorithm that is run on the "
"Producer-Producer similarity graph. This graph is created by computing the "
"cosine similarity scores between the users who follow each producer. The "
"algorithm identifies communities or clusters of Producers with similar "
"followers, and takes a parameter *k* for specifying the number of "
"communities to be detected."
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:220024
msgid ""
"After the community detection, different users and content are represented "
"as sparse, interpretable vectors within these identified communities "
"(SimClusters). The resulting SimClusters embeddings can be used for various "
"recommendation tasks."
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:220026
msgid ""
"-> **Question**: What is needed to migrate from one SimClusters to another "
"SimClusters?"
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:220028
msgid ""
"**Answer**: To migrate from one SimClusters representation to another, you "
"can follow these general steps:"
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:220030
msgid ""
"**Prepare the new representation**: Create the new SimClusters "
"representation using any necessary updates or changes in the clustering "
"algorithm, similarity measures, or other model parameters. Ensure that this "
"new representation is properly stored and indexed as needed."
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:220032
msgid ""
"**Update the relevant code and configurations**: Modify the relevant code "
"and configuration files to reference the new SimClusters representation. "
"This may involve updating paths or dataset names to point to the new "
"representation, as well as changing code to use the new clustering method or "
"similarity functions if applicable."
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:220034
msgid ""
"**Test the new representation**: Before deploying the changes to production, "
"thoroughly test the new SimClusters representation to ensure its "
"effectiveness and stability. This may involve running offline jobs like "
"candidate generation and label candidates, validating the output, as well as "
"testing the new representation in the evaluation environment using "
"evaluation tools like TweetSimilarityEvaluationAdhocApp."
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:220036
msgid ""
"**Deploy the changes**: Once the new representation has been tested and "
"validated, deploy the changes to production. This may involve creating a zip "
"file, uploading it to the packer, and then scheduling it with Aurora. Be "
"sure to monitor the system to ensure a smooth transition between "
"representations and verify that the new representation is being used in "
"recommendations as expected."
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:220038
msgid ""
"**Monitor and assess the new representation**: After the new representation "
"has been deployed, continue to monitor its performance and impact on "
"recommendations. Take note of any improvements or issues that arise and be "
"prepared to iterate on the new representation if needed. Always ensure that "
"the results and performance metrics align with the system's goals and "
"objectives."
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:220040
msgid "-> **Question**: How much do I get boosted within my cluster?"
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:220042
msgid ""
"**Answer**: It's not possible to determine the exact amount your content is "
"boosted within your cluster in the SimClusters representation without "
"specific data about your content and its engagement metrics. However, a "
"combination of factors, such as the favorite score and follow score, "
"alongside other engagement signals and SimCluster calculations, influence "
"the boosting of content."
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:220044
msgid "-> **Question**: How does Heavy ranker work. what are itâ€™s main inputs?"
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:220046
msgid ""
"**Answer**: The Heavy Ranker is a machine learning model that plays a "
"crucial role in ranking and scoring candidates within the recommendation "
"algorithm. Its primary purpose is to predict the likelihood of a user "
"engaging with a tweet or connecting with another user on the platform."
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:220048
msgid "Main inputs to the Heavy Ranker consist of:"
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:220050
msgid ""
"Static Features: These are features that can be computed directly from a "
"tweet at the time it's created, such as whether it has a URL, has cards, has "
"quotes, etc. These features are produced by the Index Ingester as the tweets "
"are generated and stored in the index."
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:220052
msgid ""
"Real-time Features: These per-tweet features can change after the tweet has "
"been indexed. They mostly consist of social engagements like retweet count, "
"favorite count, reply count, and some spam signals that are computed with "
"later activities. The Signal Ingester, which is part of a Heron topology, "
"processes multiple event streams to collect and compute these real-time "
"features."
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:220054
msgid ""
"User Table Features: These per-user features are obtained from the User "
"Table Updater that processes a stream written by the user service. This "
"input is used to store sparse real-time user information, which is later "
"propagated to the tweet being scored by looking up the author of the tweet."
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:220056
msgid ""
"Search Context Features: These features represent the context of the current "
"searcher, like their UI language, their content consumption, and the current "
"time (implied). They are combined with Tweet Data to compute some of the "
"features used in scoring."
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:220058
msgid ""
"These inputs are then processed by the Heavy Ranker to score and rank "
"candidates based on their relevance and likelihood of engagement by the user."
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:220060
msgid "-> **Question**: How can one influence Heavy ranker?"
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:220062
msgid ""
"**Answer**: To influence the Heavy Ranker's output or ranking of content, "
"consider the following actions:"
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:220064
msgid ""
"Improve content quality: Create high-quality and engaging content that is "
"relevant, informative, and valuable to users. High-quality content is more "
"likely to receive positive user engagement, which the Heavy Ranker considers "
"when ranking content."
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:220066
msgid ""
"Increase user engagement: Encourage users to interact with content through "
"likes, retweets, replies, and comments. Higher engagement levels can lead to "
"better ranking in the Heavy Ranker's output."
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:220068
msgid ""
"Optimize your user profile: A user's reputation, based on factors such as "
"their follower count and follower-to-following ratio, may impact the ranking "
"of their content. Maintain a good reputation by following relevant users, "
"keeping a reasonable follower-to-following ratio and engaging with your "
"followers."
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:220070
msgid ""
"Enhance content discoverability: Use relevant keywords, hashtags, and "
"mentions in your tweets, making it easier for users to find and engage with "
"your content. This increased discoverability may help improve the ranking of "
"your content by the Heavy Ranker."
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:220072
msgid ""
"Leverage multimedia content: Experiment with different content formats, such "
"as videos, images, and GIFs, which may capture users' attention and increase "
"engagement, resulting in better ranking by the Heavy Ranker."
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:220074
msgid ""
"User feedback: Monitor and respond to feedback for your content. Positive "
"feedback may improve your ranking, while negative feedback provides an "
"opportunity to learn and improve."
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:220076
msgid ""
"Note that the Heavy Ranker uses a combination of machine learning models and "
"various features to rank the content. While the above actions may help "
"influence the ranking, there are no guarantees as the ranking process is "
"determined by a complex algorithm, which evolves over time."
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:220078
msgid ""
"-> **Question**: why threads and long tweets do so well on the platform?"
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:220080
msgid ""
"**Answer**: Threads and long tweets perform well on the platform for several "
"reasons:"
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:220082
msgid ""
"**More content and context**: Threads and long tweets provide more "
"information and context about a topic, which can make the content more "
"engaging and informative for users. People tend to appreciate a well-"
"structured and detailed explanation of a subject or a story, and threads and "
"long tweets can do that effectively."
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:220084
msgid ""
"**Increased user engagement**: As threads and long tweets provide more "
"content, they also encourage users to engage with the tweets through "
"replies, retweets, and likes. This increased engagement can lead to better "
"visibility of the content, as the Twitter algorithm considers user "
"engagement when ranking and surfacing tweets."
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:220086
msgid ""
"**Narrative structure**: Threads enable users to tell stories or present "
"arguments in a step-by-step manner, making the information more accessible "
"and easier to follow. This narrative structure can capture users' attention "
"and encourage them to read through the entire thread and interact with the "
"content."
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:220088
msgid ""
"**Expanded reach**: When users engage with a thread, their interactions can "
"bring the content to the attention of their followers, helping to expand the "
"reach of the thread. This increased visibility can lead to more interactions "
"and higher performance for the threaded tweets."
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:220090
msgid ""
"**Higher content quality**: Generally, threads and long tweets require more "
"thought and effort to create, which may lead to higher quality content. "
"Users are more likely to appreciate and interact with high-quality, well-"
"reasoned content, further improving the performance of these tweets within "
"the platform."
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:220092
msgid ""
"Overall, threads and long tweets perform well on Twitter because they "
"encourage user engagement and provide a richer, more informative experience "
"that users find valuable."
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:220094
msgid ""
"-> **Question**: Are thread and long tweet creators building a following "
"that reacts to only threads?"
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:220096
msgid ""
"**Answer**: Based on the provided code and context, there isn't enough "
"information to conclude if the creators of threads and long tweets primarily "
"build a following that engages with only thread-based content. The code "
"provided is focused on Twitter's recommendation and ranking algorithms, as "
"well as infrastructure components like Kafka, partitions, and the Follow "
"Recommendations Service (FRS). To answer your question, data analysis of "
"user engagement and results of specific edge cases would be required."
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:220098
msgid ""
"-> **Question**: Do you need to follow different strategies to get most "
"followers vs to get most likes and bookmarks per tweet?"
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:220100
msgid ""
"**Answer**: Yes, different strategies need to be followed to maximize the "
"number of followers compared to maximizing likes and bookmarks per tweet. "
"While there may be some overlap in the approaches, they target different "
"aspects of user engagement."
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:220102
msgid ""
"Maximizing followers: The primary focus is on growing your audience on the "
"platform. Strategies include:"
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:220104
msgid ""
"Consistently sharing high-quality content related to your niche or industry."
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:220105
msgid ""
"Engaging with others on the platform by replying, retweeting, and mentioning "
"other users."
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:220106
msgid "Using relevant hashtags and participating in trending conversations."
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:220107
msgid "Collaborating with influencers and other users with a large following."
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:220108
msgid "Posting at optimal times when your target audience is most active."
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:220109
msgid ""
"Optimizing your profile by using a clear profile picture, catchy bio, and "
"relevant links."
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:220111
msgid ""
"Maximizing likes and bookmarks per tweet: The focus is on creating content "
"that resonates with your existing audience and encourages engagement. "
"Strategies include:"
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:220113
msgid ""
"Crafting engaging and well-written tweets that encourage users to like or "
"save them."
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:220114
msgid ""
"Incorporating visually appealing elements, such as images, GIFs, or videos, "
"that capture attention."
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:220115
msgid ""
"Asking questions, sharing opinions, or sparking conversations that encourage "
"users to engage with your tweets."
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:220116
msgid ""
"Using analytics to understand the type of content that resonates with your "
"audience and tailoring your tweets accordingly."
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:220117
msgid ""
"Posting a mix of educational, entertaining, and promotional content to "
"maintain variety and interest."
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:220118
msgid ""
"Timing your tweets strategically to maximize engagement, likes, and "
"bookmarks per tweet."
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:220120
msgid ""
"Both strategies can overlap, and you may need to adapt your approach by "
"understanding your target audience's preferences and analyzing your "
"account's performance. However, it's essential to recognize that maximizing "
"followers and maximizing likes and bookmarks per tweet have different "
"focuses and require specific strategies."
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:220122
msgid ""
"-> **Question**: Content meta data and how it impacts virality (e.g. ALT in "
"images)."
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:220124
msgid ""
"**Answer**: There is no direct information in the provided context about how "
"content metadata, such as ALT text in images, impacts the virality of a "
"tweet or post. However, it's worth noting that including ALT text can "
"improve the accessibility of your content for users who rely on screen "
"readers, which may lead to increased engagement for a broader audience. "
"Additionally, metadata can be used in search engine optimization, which "
"might improve the visibility of the content, but the context provided does "
"not mention any specific correlation with virality."
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:220126
msgid ""
"-> **Question**: What are some unexpected fingerprints for spam factors?"
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:220128
msgid ""
"**Answer**: In the provided context, an unusual indicator of spam factors is "
"when a tweet contains a non-media, non-news link. If the tweet has a link "
"but does not have an image URL, video URL, or news URL, it is considered a "
"potential spam vector, and a threshold for user reputation "
"(tweepCredThreshold) is set to MIN_TWEEPCRED_WITH_LINK."
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:220130
msgid ""
"While this rule may not cover all possible unusual spam indicators, it is "
"derived from the specific codebase and logic shared in the context."
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:220132
msgid ""
"-> **Question**: Is there any difference between company verified checkmarks "
"and blue verified individual checkmarks?"
msgstr ""

#: ../docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb:220134
msgid ""
"**Answer**: Yes, there is a distinction between the verified checkmarks for "
"companies and blue verified checkmarks for individuals. The code snippet "
"provided mentions \"Blue-verified account boost\" which indicates that there "
"is a separate category for blue verified accounts. Typically, blue verified "
"checkmarks are used to indicate notable individuals, while verified "
"checkmarks are for companies or organizations."
msgstr ""

#: ../docs/use_cases/evaluation.rst:2
#: ../docs/use_cases/evaluation/huggingface_datasets.ipynb:130002
#: ../docs/use_cases/evaluation/question_answering.ipynb:110002
msgid "Evaluation"
msgstr ""

#: ../docs/use_cases/evaluation.rst:5
msgid ""
"`Conceptual Guide <https://docs.langchain.com/docs/use-cases/evaluation>`_"
msgstr ""

#: ../docs/use_cases/evaluation.rst:8
msgid ""
"This section of documentation covers how we approach and think about "
"evaluation in LangChain. Both evaluation of internal chains/agents, but also "
"how we would recommend people building on top of LangChain approach "
"evaluation."
msgstr ""

#: ../docs/use_cases/evaluation.rst:12
msgid "The Problem"
msgstr ""

#: ../docs/use_cases/evaluation.rst:14
msgid ""
"It can be really hard to evaluate LangChain chains and agents. There are two "
"main reasons for this:"
msgstr ""

#: ../docs/use_cases/evaluation.rst:17 ../docs/use_cases/evaluation.rst:41
msgid "**# 1: Lack of data**"
msgstr ""

#: ../docs/use_cases/evaluation.rst:19
msgid ""
"You generally don't have a ton of data to evaluate your chains/agents over "
"before starting a project. This is usually because Large Language Models "
"(the core of most chains/agents) are terrific few-shot and zero shot "
"learners, meaning you are almost always able to get started on a particular "
"task (text-to-SQL, question answering, etc) without a large dataset of "
"examples. This is in stark contrast to traditional machine learning where "
"you had to first collect a bunch of datapoints before even getting started "
"using a model."
msgstr ""

#: ../docs/use_cases/evaluation.rst:26 ../docs/use_cases/evaluation.rst:53
msgid "**# 2: Lack of metrics**"
msgstr ""

#: ../docs/use_cases/evaluation.rst:28
msgid ""
"Most chains/agents are performing tasks for which there are not very good "
"metrics to evaluate performance. For example, one of the most common use "
"cases is generating text of some form. Evaluating generated text is much "
"more complicated than evaluating a classification prediction, or a numeric "
"prediction."
msgstr ""

#: ../docs/use_cases/evaluation.rst:33
msgid "The Solution"
msgstr ""

#: ../docs/use_cases/evaluation.rst:35
msgid ""
"LangChain attempts to tackle both of those issues. What we have so far are "
"initial passes at solutions - we do not think we have a perfect solution. So "
"we very much welcome feedback, contributions, integrations, and thoughts on "
"this."
msgstr ""

#: ../docs/use_cases/evaluation.rst:39
msgid "Here is what we have for each problem so far:"
msgstr ""

#: ../docs/use_cases/evaluation.rst:43
msgid ""
"We have started `LangChainDatasets <https://huggingface.co/"
"LangChainDatasets>`_ a Community space on Hugging Face. We intend this to be "
"a collection of open source datasets for evaluating common chains and "
"agents. We have contributed five datasets of our own to start, but we highly "
"intend this to be a community effort. In order to contribute a dataset, you "
"simply need to join the community and then you will be able to upload "
"datasets."
msgstr ""

#: ../docs/use_cases/evaluation.rst:48
msgid ""
"We're also aiming to make it as easy as possible for people to create their "
"own datasets. As a first pass at this, we've added a QAGenerationChain, "
"which given a document comes up with question-answer pairs that can be used "
"to evaluate question-answering tasks over that document down the line. See "
"`this notebook <./evaluation/qa_generation.html>`_ for an example of how to "
"use this chain."
msgstr ""

#: ../docs/use_cases/evaluation.rst:55
msgid "We have two solutions to the lack of metrics."
msgstr ""

#: ../docs/use_cases/evaluation.rst:57
msgid ""
"The first solution is to use no metrics, and rather just rely on looking at "
"results by eye to get a sense for how the chain/agent is performing. To "
"assist in this, we have developed (and will continue to develop) `tracing "
"<../tracing.html>`_, a UI-based visualizer of your chain and agent runs."
msgstr ""

#: ../docs/use_cases/evaluation.rst:60
msgid ""
"The second solution we recommend is to use Language Models themselves to "
"evaluate outputs. For this we have a few different chains and prompts aimed "
"at tackling this issue."
msgstr ""

#: ../docs/use_cases/evaluation.rst:64
msgid "The Examples"
msgstr ""

#: ../docs/use_cases/evaluation.rst:66
msgid ""
"We have created a bunch of examples combining the above two solutions to "
"show how we internally evaluate chains and agents when we are developing. In "
"addition to the examples we've curated, we also highly welcome contributions "
"here. To facilitate that, we've included a `template notebook <./evaluation/"
"benchmarking_template.html>`_ for community members to use to build their "
"own examples."
msgstr ""

#: ../docs/use_cases/evaluation.rst:70
msgid "The existing examples we have are:"
msgstr ""

#: ../docs/use_cases/evaluation.rst:72
msgid ""
"`Question Answering (State of Union) <./evaluation/qa_benchmarking_sota."
"html>`_: A notebook showing evaluation of a question-answering task over a "
"State-of-the-Union address."
msgstr ""

#: ../docs/use_cases/evaluation.rst:74
msgid ""
"`Question Answering (Paul Graham Essay) <./evaluation/qa_benchmarking_pg."
"html>`_: A notebook showing evaluation of a question-answering task over a "
"Paul Graham essay."
msgstr ""

#: ../docs/use_cases/evaluation.rst:76
msgid ""
"`SQL Question Answering (Chinook) <./evaluation/sql_qa_benchmarking_chinook."
"html>`_: A notebook showing evaluation of a question-answering task over a "
"SQL database (the Chinook database)."
msgstr ""

#: ../docs/use_cases/evaluation.rst:78
msgid ""
"`Agent Vectorstore <./evaluation/agent_vectordb_sota_pg.html>`_: A notebook "
"showing evaluation of an agent doing question answering while routing "
"between two different vector databases."
msgstr ""

#: ../docs/use_cases/evaluation.rst:80
msgid ""
"`Agent Search + Calculator <./evaluation/agent_benchmarking.html>`_: A "
"notebook showing evaluation of an agent doing question answering using a "
"Search engine and a Calculator as tools."
msgstr ""

#: ../docs/use_cases/evaluation.rst:82
msgid ""
"`Evaluating an OpenAPI Chain <./evaluation/openapi_eval.html>`_: A notebook "
"showing evaluation of an OpenAPI chain, including how to generate test data "
"if you don't have any."
msgstr ""

#: ../docs/use_cases/evaluation.rst:86
msgid "Other Examples"
msgstr ""

#: ../docs/use_cases/evaluation.rst:88
msgid "In addition, we also have some more generic resources for evaluation."
msgstr ""

#: ../docs/use_cases/evaluation.rst:90
msgid ""
"`Question Answering <./evaluation/question_answering.html>`_: An overview of "
"LLMs aimed at evaluating question answering systems in general."
msgstr ""

#: ../docs/use_cases/evaluation.rst:92
msgid ""
"`Data Augmented Question Answering <./evaluation/"
"data_augmented_question_answering.html>`_: An end-to-end example of "
"evaluating a question answering system focused on a specific document (a "
"RetrievalQAChain to be precise). This example highlights how to use LLMs to "
"come up with question/answer examples to evaluate over, and then highlights "
"how to use LLMs to evaluate performance on those generated examples."
msgstr ""

#: ../docs/use_cases/evaluation.rst:94
msgid ""
"`Hugging Face Datasets <./evaluation/huggingface_datasets.html>`_: Covers an "
"example of loading and using a dataset from Hugging Face for evaluation."
msgstr ""

#: ../docs/use_cases/evaluation/agent_benchmarking.ipynb:10002
msgid "Agent Benchmarking: Search + Calculator"
msgstr ""

#: ../docs/use_cases/evaluation/agent_benchmarking.ipynb:10004
msgid ""
"Here we go over how to benchmark performance of an agent on tasks where it "
"has access to a calculator and a search tool."
msgstr ""

#: ../docs/use_cases/evaluation/agent_benchmarking.ipynb:10006
#: ../docs/use_cases/evaluation/agent_vectordb_sota_pg.ipynb:10006
#: ../docs/use_cases/evaluation/benchmarking_template.ipynb:20002
#: ../docs/use_cases/evaluation/qa_benchmarking_pg.ipynb:10006
#: ../docs/use_cases/evaluation/qa_benchmarking_sota.ipynb:10006
#: ../docs/use_cases/evaluation/sql_qa_benchmarking_chinook.ipynb:10006
msgid ""
"It is highly reccomended that you do any evaluation/benchmarking with "
"tracing enabled. See [here](https://langchain.readthedocs.io/en/latest/"
"tracing.html) for an explanation of what tracing is and how to set it up."
msgstr ""

#: ../docs/use_cases/evaluation/agent_benchmarking.ipynb:30002
#: ../docs/use_cases/evaluation/agent_vectordb_sota_pg.ipynb:30002
#: ../docs/use_cases/evaluation/benchmarking_template.ipynb:40002
#: ../docs/use_cases/evaluation/qa_benchmarking_pg.ipynb:30002
#: ../docs/use_cases/evaluation/qa_benchmarking_sota.ipynb:30002
#: ../docs/use_cases/evaluation/sql_qa_benchmarking_chinook.ipynb:30002
msgid "Loading the data"
msgstr ""

#: ../docs/use_cases/evaluation/agent_benchmarking.ipynb:30003
#: ../docs/use_cases/evaluation/agent_vectordb_sota_pg.ipynb:30003
#: ../docs/use_cases/evaluation/benchmarking_template.ipynb:40004
#: ../docs/use_cases/evaluation/qa_benchmarking_pg.ipynb:30003
#: ../docs/use_cases/evaluation/qa_benchmarking_sota.ipynb:30003
#: ../docs/use_cases/evaluation/sql_qa_benchmarking_chinook.ipynb:30004
msgid "First, let's load the data."
msgstr ""

#: ../docs/use_cases/evaluation/agent_benchmarking.ipynb:50002
#: ../docs/use_cases/evaluation/agent_vectordb_sota_pg.ipynb:70002
#: ../docs/use_cases/evaluation/benchmarking_template.ipynb:60002
#: ../docs/use_cases/evaluation/llm_math.ipynb:40002
#: ../docs/use_cases/evaluation/qa_benchmarking_pg.ipynb:50002
#: ../docs/use_cases/evaluation/qa_benchmarking_sota.ipynb:50002
#: ../docs/use_cases/evaluation/sql_qa_benchmarking_chinook.ipynb:60002
msgid "Setting up a chain"
msgstr ""

#: ../docs/use_cases/evaluation/agent_benchmarking.ipynb:50003
msgid "Now we need to load an agent capable of answering these questions."
msgstr ""

#: ../docs/use_cases/evaluation/agent_benchmarking.ipynb:70002
#: ../docs/use_cases/evaluation/agent_vectordb_sota_pg.ipynb:210002
#: ../docs/use_cases/evaluation/benchmarking_template.ipynb:80002
#: ../docs/use_cases/evaluation/qa_benchmarking_pg.ipynb:120002
#: ../docs/use_cases/evaluation/qa_benchmarking_sota.ipynb:120002
#: ../docs/use_cases/evaluation/sql_qa_benchmarking_chinook.ipynb:110002
msgid "Make a prediction"
msgstr ""

#: ../docs/use_cases/evaluation/agent_benchmarking.ipynb:70004
#: ../docs/use_cases/evaluation/agent_vectordb_sota_pg.ipynb:210004
#: ../docs/use_cases/evaluation/benchmarking_template.ipynb:80004
#: ../docs/use_cases/evaluation/qa_benchmarking_pg.ipynb:120004
#: ../docs/use_cases/evaluation/qa_benchmarking_sota.ipynb:120004
#: ../docs/use_cases/evaluation/sql_qa_benchmarking_chinook.ipynb:110004
msgid ""
"First, we can make predictions one datapoint at a time. Doing it at this "
"level of granularity allows use to explore the outputs in detail, and also "
"is a lot cheaper than running over multiple datapoints"
msgstr ""

#: ../docs/use_cases/evaluation/agent_benchmarking.ipynb:90002
#: ../docs/use_cases/evaluation/agent_vectordb_sota_pg.ipynb:230002
#: ../docs/use_cases/evaluation/benchmarking_template.ipynb:100002
#: ../docs/use_cases/evaluation/qa_benchmarking_pg.ipynb:140002
#: ../docs/use_cases/evaluation/qa_benchmarking_sota.ipynb:140002
#: ../docs/use_cases/evaluation/sql_qa_benchmarking_chinook.ipynb:130002
msgid "Make many predictions"
msgstr ""

#: ../docs/use_cases/evaluation/agent_benchmarking.ipynb:90003
#: ../docs/use_cases/evaluation/agent_vectordb_sota_pg.ipynb:230003
#: ../docs/use_cases/evaluation/qa_benchmarking_pg.ipynb:140003
#: ../docs/use_cases/evaluation/qa_benchmarking_sota.ipynb:140003
msgid "Now we can make predictions"
msgstr ""

#: ../docs/use_cases/evaluation/agent_benchmarking.ipynb:120002
#: ../docs/use_cases/evaluation/agent_vectordb_sota_pg.ipynb:250002
#: ../docs/use_cases/evaluation/benchmarking_template.ipynb:120002
#: ../docs/use_cases/evaluation/qa_benchmarking_pg.ipynb:160002
#: ../docs/use_cases/evaluation/qa_benchmarking_sota.ipynb:160002
#: ../docs/use_cases/evaluation/sql_qa_benchmarking_chinook.ipynb:150002
msgid "Evaluate performance"
msgstr ""

#: ../docs/use_cases/evaluation/agent_benchmarking.ipynb:120003
#: ../docs/use_cases/evaluation/agent_vectordb_sota_pg.ipynb:250003
#: ../docs/use_cases/evaluation/qa_benchmarking_pg.ipynb:160003
#: ../docs/use_cases/evaluation/qa_benchmarking_sota.ipynb:160003
msgid ""
"Now we can evaluate the predictions. The first thing we can do is look at "
"them by eye."
msgstr ""

#: ../docs/use_cases/evaluation/agent_benchmarking.ipynb:140002
#: ../docs/use_cases/evaluation/agent_vectordb_sota_pg.ipynb:270002
#: ../docs/use_cases/evaluation/qa_benchmarking_pg.ipynb:180002
#: ../docs/use_cases/evaluation/qa_benchmarking_sota.ipynb:180002
msgid "Next, we can use a language model to score them programatically"
msgstr ""

#: ../docs/use_cases/evaluation/agent_benchmarking.ipynb:170002
#: ../docs/use_cases/evaluation/agent_vectordb_sota_pg.ipynb:300002
#: ../docs/use_cases/evaluation/qa_benchmarking_pg.ipynb:210002
#: ../docs/use_cases/evaluation/qa_benchmarking_sota.ipynb:210002
#: ../docs/use_cases/evaluation/sql_qa_benchmarking_chinook.ipynb:180002
msgid ""
"We can add in the graded output to the `predictions` dict and then get a "
"count of the grades."
msgstr ""

#: ../docs/use_cases/evaluation/agent_benchmarking.ipynb:200002
#: ../docs/use_cases/evaluation/agent_vectordb_sota_pg.ipynb:330002
#: ../docs/use_cases/evaluation/qa_benchmarking_pg.ipynb:240002
#: ../docs/use_cases/evaluation/qa_benchmarking_sota.ipynb:240002
#: ../docs/use_cases/evaluation/sql_qa_benchmarking_chinook.ipynb:210002
msgid ""
"We can also filter the datapoints to the incorrect examples and look at them."
msgstr ""

#: ../docs/use_cases/evaluation/agent_vectordb_sota_pg.ipynb:10002
msgid "Agent VectorDB Question Answering Benchmarking"
msgstr ""

#: ../docs/use_cases/evaluation/agent_vectordb_sota_pg.ipynb:10004
msgid ""
"Here we go over how to benchmark performance on a question answering task "
"using an agent to route between multiple vectordatabases."
msgstr ""

#: ../docs/use_cases/evaluation/agent_vectordb_sota_pg.ipynb:70003
msgid ""
"Now we need to create some pipelines for doing question answering. Step one "
"in that is creating indexes over the data in question."
msgstr ""

#: ../docs/use_cases/evaluation/agent_vectordb_sota_pg.ipynb:110002
#: ../docs/use_cases/evaluation/qa_benchmarking_pg.ipynb:90002
#: ../docs/use_cases/evaluation/qa_benchmarking_sota.ipynb:90002
msgid "Now we can create a question answering chain."
msgstr ""

#: ../docs/use_cases/evaluation/agent_vectordb_sota_pg.ipynb:140002
msgid "Now we do the same for the Paul Graham data."
msgstr ""

#: ../docs/use_cases/evaluation/agent_vectordb_sota_pg.ipynb:180002
msgid "We can now set up an agent to route between them."
msgstr ""

#: ../docs/use_cases/evaluation/benchmarking_template.ipynb:10002
msgid "Benchmarking Template"
msgstr ""

#: ../docs/use_cases/evaluation/benchmarking_template.ipynb:10004
msgid ""
"This is an example notebook that can be used to create a benchmarking "
"notebook for a task of your choice. Evaluation is really hard, and so we "
"greatly welcome any contributions that can make it easier for people to "
"experiment"
msgstr ""

#: ../docs/use_cases/evaluation/benchmarking_template.ipynb:60004
msgid ""
"This next section should have an example of setting up a chain that can be "
"run on this dataset."
msgstr ""

#: ../docs/use_cases/evaluation/benchmarking_template.ipynb:100003
msgid "Now we can make predictions."
msgstr ""

#: ../docs/use_cases/evaluation/benchmarking_template.ipynb:120004
msgid ""
"Any guide to evaluating performance in a more systematic manner goes here."
msgstr ""

#: ../docs/use_cases/evaluation/data_augmented_question_answering.ipynb:10002
msgid "Data Augmented Question Answering"
msgstr ""

#: ../docs/use_cases/evaluation/data_augmented_question_answering.ipynb:10004
msgid ""
"This notebook uses some generic prompts/language models to evaluate an "
"question answering system that uses other sources of data besides what is in "
"the model. For example, this can be used to evaluate a question answering "
"system over your proprietary data."
msgstr ""

#: ../docs/use_cases/evaluation/data_augmented_question_answering.ipynb:10007
msgid ""
"Let's set up an example with our favorite example - the state of the union "
"address."
msgstr ""

#: ../docs/use_cases/evaluation/data_augmented_question_answering.ipynb:40002
#: ../docs/use_cases/evaluation/huggingface_datasets.ipynb:60002
#: ../docs/use_cases/evaluation/question_answering.ipynb:60002
msgid "Examples"
msgstr ""

#: ../docs/use_cases/evaluation/data_augmented_question_answering.ipynb:40003
msgid "Now we need some examples to evaluate. We can do this in two ways:"
msgstr ""

#: ../docs/use_cases/evaluation/data_augmented_question_answering.ipynb:40005
msgid "Hard code some examples ourselves"
msgstr ""

#: ../docs/use_cases/evaluation/data_augmented_question_answering.ipynb:40006
msgid "Generate examples automatically, using a language model"
msgstr ""

#: ../docs/use_cases/evaluation/data_augmented_question_answering.ipynb:100002
msgid "Evaluate"
msgstr ""

#: ../docs/use_cases/evaluation/data_augmented_question_answering.ipynb:100003
msgid ""
"Now that we have examples, we can use the question answering evaluator to "
"evaluate our question answering chain."
msgstr ""

#: ../docs/use_cases/evaluation/data_augmented_question_answering.ipynb:160002
msgid "Evaluate with Other Metrics"
msgstr ""

#: ../docs/use_cases/evaluation/data_augmented_question_answering.ipynb:160004
msgid ""
"In addition to predicting whether the answer is correct or incorrect using a "
"language model, we can also use other metrics to get a more nuanced view on "
"the quality of the answers. To do so, we can use the [Critique](https://docs."
"inspiredco.ai/critique/) library, which allows for simple calculation of "
"various metrics over generated text."
msgstr ""

#: ../docs/use_cases/evaluation/data_augmented_question_answering.ipynb:160006
msgid ""
"First you can get an API key from the [Inspired Cognition Dashboard](https://"
"dashboard.inspiredco.ai) and do some setup:"
msgstr ""

#: ../docs/use_cases/evaluation/data_augmented_question_answering.ipynb:180002
msgid ""
"Then run the following code to set up the configuration and calculate the "
"[ROUGE](https://docs.inspiredco.ai/critique/metric_rouge.html), [chrf]"
"(https://docs.inspiredco.ai/critique/metric_chrf.html), [BERTScore](https://"
"docs.inspiredco.ai/critique/metric_bert_score.html), and [UniEval](https://"
"docs.inspiredco.ai/critique/metric_uni_eval.html) (you can choose [other "
"metrics](https://docs.inspiredco.ai/critique/metrics.html) too):"
msgstr ""

#: ../docs/use_cases/evaluation/data_augmented_question_answering.ipynb:210002
msgid ""
"Finally, we can print out the results. We can see that overall the scores "
"are higher when the output is semantically correct, and also when the output "
"closely matches with the gold-standard answer."
msgstr ""

#: ../docs/use_cases/evaluation/generic_agent_evaluation.ipynb:10002
msgid "Generic Agent Evaluation"
msgstr ""

#: ../docs/use_cases/evaluation/generic_agent_evaluation.ipynb:10004
msgid ""
"Good evaluation is key for quickly iterating on your agent's prompts and "
"tools. Here we provide an example of how to use the TrajectoryEvalChain to "
"evaluate your agent."
msgstr ""

#: ../docs/use_cases/evaluation/generic_agent_evaluation.ipynb:20004
msgid "Let's start by defining our agent."
msgstr ""

#: ../docs/use_cases/evaluation/generic_agent_evaluation.ipynb:40002
msgid "Testing the Agent"
msgstr ""

#: ../docs/use_cases/evaluation/generic_agent_evaluation.ipynb:40004
msgid "Now let's try our agent out on some example queries."
msgstr ""

#: ../docs/use_cases/evaluation/generic_agent_evaluation.ipynb:60002
msgid "This looks good! Let's try it out on another query."
msgstr ""

#: ../docs/use_cases/evaluation/generic_agent_evaluation.ipynb:80002
msgid "This doesn't look so good. Let's try running some evaluation."
msgstr ""

#: ../docs/use_cases/evaluation/generic_agent_evaluation.ipynb:80004
msgid "Evaluating the Agent"
msgstr ""

#: ../docs/use_cases/evaluation/generic_agent_evaluation.ipynb:80006
msgid "Let's start by defining the TrajectoryEvalChain."
msgstr ""

#: ../docs/use_cases/evaluation/generic_agent_evaluation.ipynb:100002
msgid "Let's try evaluating the first query."
msgstr ""

#: ../docs/use_cases/evaluation/generic_agent_evaluation.ipynb:120002
msgid "That seems about right. Let's try the second query."
msgstr ""

#: ../docs/use_cases/evaluation/generic_agent_evaluation.ipynb:140002
msgid ""
"That also sounds about right. In conclusion, the TrajectoryEvalChain allows "
"us to use GPT-4 to score both our agent's outputs and tool use in addition "
"to giving us the reasoning behind the evaluation."
msgstr ""

#: ../docs/use_cases/evaluation/huggingface_datasets.ipynb:10002
msgid "Using Hugging Face Datasets"
msgstr ""

#: ../docs/use_cases/evaluation/huggingface_datasets.ipynb:10004
msgid ""
"This example shows how to use Hugging Face datasets to evaluate models. "
"Specifically, we show how to load examples to evaluate models on from "
"Hugging Face's dataset package."
msgstr ""

#: ../docs/use_cases/evaluation/huggingface_datasets.ipynb:20004
msgid ""
"For demonstration purposes, we will just evaluate a simple question "
"answering system."
msgstr ""

#: ../docs/use_cases/evaluation/huggingface_datasets.ipynb:60004
msgid ""
"Now we load a dataset from Hugging Face, and then convert it to a list of "
"dictionaries for easier usage."
msgstr ""

#: ../docs/use_cases/evaluation/huggingface_datasets.ipynb:100002
#: ../docs/use_cases/evaluation/question_answering.ipynb:80002
msgid "Predictions"
msgstr ""

#: ../docs/use_cases/evaluation/huggingface_datasets.ipynb:100004
#: ../docs/use_cases/evaluation/question_answering.ipynb:80004
msgid "We can now make and inspect the predictions for these questions."
msgstr ""

#: ../docs/use_cases/evaluation/huggingface_datasets.ipynb:130004
msgid ""
"Because these answers are more complex than multiple choice, we can now "
"evaluate their accuracy using a language model."
msgstr ""

#: ../docs/use_cases/evaluation/llm_math.ipynb:10002
msgid "LLM Math"
msgstr ""

#: ../docs/use_cases/evaluation/llm_math.ipynb:10004
msgid "Evaluating chains that know how to do math."
msgstr ""

#: ../docs/use_cases/evaluation/llm_math.ipynb:40003
msgid "Now we need to create some pipelines for doing math."
msgstr ""

#: ../docs/use_cases/evaluation/openapi_eval.ipynb:10002
msgid "Evaluating an OpenAPI Chain"
msgstr ""

#: ../docs/use_cases/evaluation/openapi_eval.ipynb:10004
msgid ""
"This notebook goes over ways to semantically evaluate an [OpenAPI Chain]"
"(openapi.ipynb), which calls an endpoint defined by the OpenAPI "
"specification using purely natural language."
msgstr ""

#: ../docs/use_cases/evaluation/openapi_eval.ipynb:30002
msgid "Load the API Chain"
msgstr ""

#: ../docs/use_cases/evaluation/openapi_eval.ipynb:30004
msgid ""
"Load a wrapper of the spec (so we can work with it more easily). You can "
"load from a url or from a local file."
msgstr ""

#: ../docs/use_cases/evaluation/openapi_eval.ipynb:50002
msgid "*Optional*: Generate Input Questions and Request Ground Truth Queries"
msgstr ""

#: ../docs/use_cases/evaluation/openapi_eval.ipynb:50004
msgid ""
"See [Generating Test Datasets](#Generating-Test-Datasets) at the end of this "
"notebook for more details."
msgstr ""

#: ../docs/use_cases/evaluation/openapi_eval.ipynb:80002
msgid "Run the API Chain"
msgstr ""

#: ../docs/use_cases/evaluation/openapi_eval.ipynb:80004
msgid "The two simplest questions a user of the API Chain are:"
msgstr ""

#: ../docs/use_cases/evaluation/openapi_eval.ipynb:80005
msgid "Did the chain succesfully access the endpoint?"
msgstr ""

#: ../docs/use_cases/evaluation/openapi_eval.ipynb:80006
msgid "Did the action accomplish the correct result?"
msgstr ""

#: ../docs/use_cases/evaluation/openapi_eval.ipynb:160002
msgid "Evaluate the requests chain"
msgstr ""

#: ../docs/use_cases/evaluation/openapi_eval.ipynb:160004
msgid "The API Chain has two main components:"
msgstr ""

#: ../docs/use_cases/evaluation/openapi_eval.ipynb:160005
msgid "Translate the user query to an API request (request synthesizer)"
msgstr ""

#: ../docs/use_cases/evaluation/openapi_eval.ipynb:160006
msgid "Translate the API response to a natural language response"
msgstr ""

#: ../docs/use_cases/evaluation/openapi_eval.ipynb:160008
msgid ""
"Here, we construct an evaluation chain to grade the request synthesizer "
"against selected human queries"
msgstr ""

#: ../docs/use_cases/evaluation/openapi_eval.ipynb:220002
msgid "Evaluate the Response Chain"
msgstr ""

#: ../docs/use_cases/evaluation/openapi_eval.ipynb:220004
msgid ""
"The second component translated the structured API response to a natural "
"language response. Evaluate this against the user's original question."
msgstr ""

#: ../docs/use_cases/evaluation/openapi_eval.ipynb:290002
msgid "Generating Test Datasets"
msgstr ""

#: ../docs/use_cases/evaluation/openapi_eval.ipynb:290004
msgid ""
"To evaluate a chain against your own endpoint, you'll want to generate a "
"test dataset that's conforms to the API."
msgstr ""

#: ../docs/use_cases/evaluation/openapi_eval.ipynb:290006
msgid "This section provides an overview of how to bootstrap the process."
msgstr ""

#: ../docs/use_cases/evaluation/openapi_eval.ipynb:290008
msgid ""
"First, we'll parse the OpenAPI Spec. For this example, we'll [Speak](https://"
"www.speak.com/)'s OpenAPI specification."
msgstr ""

#: ../docs/use_cases/evaluation/openapi_eval.ipynb:390002
msgid ""
"**Now you can use the `ground_truth` as shown above in [Evaluate the "
"Requests Chain](#Evaluate-the-requests-chain)!**"
msgstr ""

#: ../docs/use_cases/evaluation/qa_benchmarking_pg.ipynb:10002
msgid "Question Answering Benchmarking: Paul Graham Essay"
msgstr ""

#: ../docs/use_cases/evaluation/qa_benchmarking_pg.ipynb:10004
msgid ""
"Here we go over how to benchmark performance on a question answering task "
"over a Paul Graham essay."
msgstr ""

#: ../docs/use_cases/evaluation/qa_benchmarking_pg.ipynb:50003
#: ../docs/use_cases/evaluation/qa_benchmarking_sota.ipynb:50003
msgid ""
"Now we need to create some pipelines for doing question answering. Step one "
"in that is creating an index over the data in question."
msgstr ""

#: ../docs/use_cases/evaluation/qa_benchmarking_sota.ipynb:10002
msgid "Question Answering Benchmarking: State of the Union Address"
msgstr ""

#: ../docs/use_cases/evaluation/qa_benchmarking_sota.ipynb:10004
msgid ""
"Here we go over how to benchmark performance on a question answering task "
"over a state of the union address."
msgstr ""

#: ../docs/use_cases/evaluation/qa_generation.ipynb:10002
msgid "QA Generation"
msgstr ""

#: ../docs/use_cases/evaluation/qa_generation.ipynb:10003
msgid ""
"This notebook shows how to use the `QAGenerationChain` to come up with "
"question-answer pairs over a specific document. This is important because "
"often times you may not have data to evaluate your question-answer system "
"over, so this is a cheap and lightweight way to generate it!"
msgstr ""

#: ../docs/use_cases/evaluation/question_answering.ipynb:10004
msgid ""
"This notebook covers how to evaluate generic question answering problems. "
"This is a situation where you have an example containing a question and its "
"corresponding ground truth answer, and you want to measure how well the "
"language model does at answering those questions."
msgstr ""

#: ../docs/use_cases/evaluation/question_answering.ipynb:20004
msgid ""
"For demonstration purposes, we will just evaluate a simple question "
"answering system that only evaluates the model's internal knowledge. Please "
"see other notebooks for examples where it evaluates how the model does at "
"question answering over data not present in what the model was trained on."
msgstr ""

#: ../docs/use_cases/evaluation/question_answering.ipynb:60003
msgid ""
"For this purpose, we will just use two simple hardcoded examples, but see "
"other notebooks for tips on how to get and/or generate these examples."
msgstr ""

#: ../docs/use_cases/evaluation/question_answering.ipynb:110004
msgid ""
"We can see that if we tried to just do exact match on the answer answers "
"(`11` and `No`) they would not match what the language model answered. "
"However, semantically the language model is correct in both cases. In order "
"to account for this, we can use a language model itself to evaluate the "
"answers."
msgstr ""

#: ../docs/use_cases/evaluation/question_answering.ipynb:150002
msgid "Customize Prompt"
msgstr ""

#: ../docs/use_cases/evaluation/question_answering.ipynb:150004
msgid ""
"You can also customize the prompt that is used. Here is an example prompting "
"it using a score from 0 to 10. The custom prompt requires 3 input variables: "
"\"query\", \"answer\" and \"result\". Where \"query\" is the question, "
"\"answer\" is the ground truth answer, and \"result\" is the predicted "
"answer."
msgstr ""

#: ../docs/use_cases/evaluation/question_answering.ipynb:180002
msgid "Evaluation without Ground Truth"
msgstr ""

#: ../docs/use_cases/evaluation/question_answering.ipynb:180003
msgid ""
"Its possible to evaluate question answering systems without ground truth. "
"You would need a `\"context\"` input that reflects what the information the "
"LLM uses to answer the question. This context can be obtained by any "
"retreival system. Here's an example of how it works:"
msgstr ""

#: ../docs/use_cases/evaluation/question_answering.ipynb:230002
msgid "Comparing to other evaluation metrics"
msgstr ""

#: ../docs/use_cases/evaluation/question_answering.ipynb:230003
msgid ""
"We can compare the evaluation results we get to other common evaluation "
"metrics. To do this, let's load some evaluation metrics from HuggingFace's "
"`evaluate` package."
msgstr ""

#: ../docs/use_cases/evaluation/sql_qa_benchmarking_chinook.ipynb:10002
msgid "SQL Question Answering Benchmarking: Chinook"
msgstr ""

#: ../docs/use_cases/evaluation/sql_qa_benchmarking_chinook.ipynb:10004
msgid ""
"Here we go over how to benchmark performance on a question answering task "
"over a SQL database."
msgstr ""

#: ../docs/use_cases/evaluation/sql_qa_benchmarking_chinook.ipynb:60003
msgid ""
"This uses the example Chinook database. To set it up follow the instructions "
"on https://database.guide/2-sample-databases-sqlite/, placing the `.db` file "
"in a notebooks folder at the root of this repository."
msgstr ""

#: ../docs/use_cases/evaluation/sql_qa_benchmarking_chinook.ipynb:60006
msgid ""
"Note that here we load a simple chain. If you want to experiment with more "
"complex chains, or an agent, just create the `chain` object in a different "
"way."
msgstr ""

#: ../docs/use_cases/evaluation/sql_qa_benchmarking_chinook.ipynb:90002
msgid "Now we can create a SQL database chain."
msgstr ""

#: ../docs/use_cases/evaluation/sql_qa_benchmarking_chinook.ipynb:130003
msgid ""
"Now we can make predictions. Note that we add a try-except because this "
"chain can sometimes error (if SQL is written incorrectly, etc)"
msgstr ""

#: ../docs/use_cases/evaluation/sql_qa_benchmarking_chinook.ipynb:150003
msgid ""
"Now we can evaluate the predictions. We can use a language model to score "
"them programatically"
msgstr ""

#: ../docs/use_cases/extraction.md:1
msgid "Extraction"
msgstr ""

#: ../docs/use_cases/extraction.md:3
msgid ""
"[Conceptual Guide](https://docs.langchain.com/docs/use-cases/extraction)"
msgstr ""

#: ../docs/use_cases/extraction.md:6
msgid ""
"Most APIs and databases still deal with structured information. Therefore, "
"in order to better work with those, it can be useful to extract structured "
"information from text. Examples of this include:"
msgstr ""

#: ../docs/use_cases/extraction.md:10
msgid "Extracting a structured row to insert into a database from a sentence"
msgstr ""

#: ../docs/use_cases/extraction.md:11
msgid "Extracting multiple rows to insert into a database from a long document"
msgstr ""

#: ../docs/use_cases/extraction.md:12
msgid "Extracting the correct API parameters from a user query"
msgstr ""

#: ../docs/use_cases/extraction.md:14
msgid ""
"This work is extremely related to [output parsing](../modules/prompts/"
"output_parsers.rst). Output parsers are responsible for instructing the LLM "
"to respond in a specific format. In this case, the output parsers specify "
"the format of the data you would like to extract from the document. Then, in "
"addition to the output format instructions, the prompt should also contain "
"the data you would like to extract information from."
msgstr ""

#: ../docs/use_cases/extraction.md:19
msgid ""
"While normal output parsers are good enough for basic structuring of "
"response data, when doing extraction you often want to extract more "
"complicated or nested structures. For a deep dive on extraction, we "
"recommend checking out [`kor`](https://eyurtsev.github.io/kor/), a library "
"that uses the existing LangChain chain and OutputParser abstractions but "
"deep dives on allowing extraction of more complicated schemas."
msgstr ""

#: ../docs/use_cases/personal_assistants.md:1
msgid "Personal Assistants (Agents)"
msgstr ""

#: ../docs/use_cases/personal_assistants.md:3
msgid ""
"[Conceptual Guide](https://docs.langchain.com/docs/use-cases/personal-"
"assistants)"
msgstr ""

#: ../docs/use_cases/personal_assistants.md:6
msgid ""
"We use \"personal assistant\" here in a very broad sense. Personal "
"assistants have a few characteristics:"
msgstr ""

#: ../docs/use_cases/personal_assistants.md:9
msgid "They can interact with the outside world"
msgstr ""

#: ../docs/use_cases/personal_assistants.md:10
msgid "They have knowledge of your data"
msgstr ""

#: ../docs/use_cases/personal_assistants.md:11
msgid "They remember your interactions"
msgstr ""

#: ../docs/use_cases/personal_assistants.md:13
msgid ""
"Really all of the functionality in LangChain is relevant for building a "
"personal assistant. Highlighting specific parts:"
msgstr ""

#: ../docs/use_cases/personal_assistants.md:16
msgid ""
"[Agent Documentation](../modules/agents.rst) (for interacting with the "
"outside world)"
msgstr ""

#: ../docs/use_cases/personal_assistants.md:17
msgid ""
"[Index Documentation](../modules/indexes.rst) (for giving them knowledge of "
"your data)"
msgstr ""

#: ../docs/use_cases/personal_assistants.md:18
msgid ""
"[Memory](../modules/memory.rst) (for helping them remember interactions)"
msgstr ""

#: ../docs/use_cases/personal_assistants.md:20
msgid "Specific examples of this include:"
msgstr ""

#: ../docs/use_cases/personal_assistants.md:22
msgid ""
"[AI Plugins](agents/custom_agent_with_plugin_retrieval.ipynb): an "
"implementation of an agent that is designed to be able to use all AI Plugins."
msgstr ""

#: ../docs/use_cases/personal_assistants.md:23
msgid ""
"[Plug-and-PlAI (Plugins Database)](agents/"
"custom_agent_with_plugin_retrieval_using_plugnplai.ipynb): an implementation "
"of an agent that is designed to be able to use all AI Plugins retrieved from "
"PlugNPlAI."
msgstr ""

#: ../docs/use_cases/personal_assistants.md:24
msgid ""
"[Wikibase Agent](agents/wikibase_agent.ipynb): an implementation of an agent "
"that is designed to interact with Wikibase."
msgstr ""

#: ../docs/use_cases/personal_assistants.md:25
msgid ""
"[Sales GPT](agents/sales_agent_with_context.ipynb): This notebook "
"demonstrates an implementation of a Context-Aware AI Sales agent."
msgstr ""

#: ../docs/use_cases/question_answering.md:1
msgid "Question Answering over Docs"
msgstr ""

#: ../docs/use_cases/question_answering.md:3
msgid "[Conceptual Guide](https://docs.langchain.com/docs/use-cases/qa-docs)"
msgstr ""

#: ../docs/use_cases/question_answering.md:5
msgid ""
"Question answering in this context refers to question answering over your "
"document data. For question answering over other types of data, please see "
"other sources documentation like [SQL database Question Answering](./tabular."
"md) or [Interacting with APIs](./apis.md)."
msgstr ""

#: ../docs/use_cases/question_answering.md:8
msgid ""
"For question answering over many documents, you almost always want to create "
"an index over the data. This can be used to smartly access the most relevant "
"documents for a given question, allowing you to avoid having to pass all the "
"documents to the LLM (saving you time and money)."
msgstr ""

#: ../docs/use_cases/question_answering.md:11
msgid ""
"See [this notebook](../modules/indexes/getting_started.ipynb) for a more "
"detailed introduction to this, but for a super quick start the steps "
"involved are:"
msgstr ""

#: ../docs/use_cases/question_answering.md:13
msgid "**Load Your Documents**"
msgstr ""

#: ../docs/use_cases/question_answering.md:20
msgid ""
"See [here](../modules/indexes/document_loaders.rst) for more information on "
"how to get started with document loading."
msgstr ""

#: ../docs/use_cases/question_answering.md:22
msgid "**Create Your Index**"
msgstr ""

#: ../docs/use_cases/question_answering.md:29
msgid ""
"The best and most popular index by far at the moment is the VectorStore "
"index."
msgstr ""

#: ../docs/use_cases/question_answering.md:31
msgid "**Query Your Index**"
msgstr ""

#: ../docs/use_cases/question_answering.md:38
msgid ""
"Alternatively, use `query_with_sources` to also get back the sources involved"
msgstr ""

#: ../docs/use_cases/question_answering.md:45
msgid ""
"Again, these high level interfaces obfuscate a lot of what is going on under "
"the hood, so please see [this notebook](../modules/indexes/getting_started."
"ipynb) for a lower level walkthrough."
msgstr ""

#: ../docs/use_cases/question_answering.md:47
msgid "Document Question Answering"
msgstr ""

#: ../docs/use_cases/question_answering.md:49
msgid ""
"Question answering involves fetching multiple documents, and then asking a "
"question of them. The LLM response will contain the answer to your question, "
"based on the content of the documents."
msgstr ""

#: ../docs/use_cases/question_answering.md:52
msgid "The recommended way to get started using a question answering chain is:"
msgstr ""

#: ../docs/use_cases/question_answering.md:62
msgid ""
"[Question Answering Notebook](../modules/chains/index_examples/"
"question_answering.ipynb): A notebook walking through how to accomplish this "
"task."
msgstr ""

#: ../docs/use_cases/question_answering.md:63
msgid ""
"[VectorDB Question Answering Notebook](../modules/chains/index_examples/"
"vector_db_qa.ipynb): A notebook walking through how to do question answering "
"over a vector database. This can often be useful for when you have a LOT of "
"documents, and you don't want to pass them all to the LLM, but rather first "
"want to do some semantic search over embeddings."
msgstr ""

#: ../docs/use_cases/question_answering.md:65
msgid "Adding in sources"
msgstr ""

#: ../docs/use_cases/question_answering.md:67
msgid ""
"There is also a variant of this, where in addition to responding with the "
"answer the language model will also cite its sources (eg which of the "
"documents passed in it used)."
msgstr ""

#: ../docs/use_cases/question_answering.md:69
msgid ""
"The recommended way to get started using a question answering with sources "
"chain is:"
msgstr ""

#: ../docs/use_cases/question_answering.md:79
msgid ""
"[QA With Sources Notebook](../modules/chains/index_examples/qa_with_sources."
"ipynb): A notebook walking through how to accomplish this task."
msgstr ""

#: ../docs/use_cases/question_answering.md:80
msgid ""
"[VectorDB QA With Sources Notebook](../modules/chains/index_examples/"
"vector_db_qa_with_sources.ipynb): A notebook walking through how to do "
"question answering with sources over a vector database. This can often be "
"useful for when you have a LOT of documents, and you don't want to pass them "
"all to the LLM, but rather first want to do some semantic search over "
"embeddings."
msgstr ""

#: ../docs/use_cases/question_answering.md:82
msgid "Additional Related Resources"
msgstr ""

#: ../docs/use_cases/question_answering.md:86
msgid ""
"[Utilities for working with Documents](/modules/utils/how_to_guides.rst): "
"Guides on how to use several of the utilities which will prove helpful for "
"this task, including Text Splitters (for splitting up long documents) and "
"Embeddings & Vectorstores (useful for the above Vector DB example)."
msgstr ""

#: ../docs/use_cases/question_answering.md:87
msgid ""
"[CombineDocuments Chains](/modules/indexes/combine_docs.md): A conceptual "
"overview of specific types of chains by which you can accomplish this task."
msgstr ""

#: ../docs/use_cases/question_answering.md:89
msgid "End-to-end examples"
msgstr ""

#: ../docs/use_cases/question_answering.md:91
msgid ""
"For examples to this done in an end-to-end manner, please see the following "
"resources:"
msgstr ""

#: ../docs/use_cases/question_answering.md:93
msgid ""
"[Semantic search over a group chat with Sources Notebook](question_answering/"
"semantic-search-over-chat.ipynb): A notebook that semantically searches over "
"a group chat conversation."
msgstr ""

#: ../docs/use_cases/question_answering/semantic-search-over-chat.ipynb:10002
msgid "Question answering over a group chat messages"
msgstr ""

#: ../docs/use_cases/question_answering/semantic-search-over-chat.ipynb:10003
msgid ""
"In this tutorial, we are going to use Langchain + Deep Lake with GPT4 to "
"semantically search and ask questions over a group chat."
msgstr ""

#: ../docs/use_cases/question_answering/semantic-search-over-chat.ipynb:10005
msgid ""
"View a working demo [here](https://twitter.com/thisissukh_/"
"status/1647223328363679745)"
msgstr ""

#: ../docs/use_cases/question_answering/semantic-search-over-chat.ipynb:20002
msgid "1. Install required packages"
msgstr ""

#: ../docs/use_cases/question_answering/semantic-search-over-chat.ipynb:40002
msgid "2. Add API keys"
msgstr ""

#: ../docs/use_cases/question_answering/semantic-search-over-chat.ipynb:70004
msgid "2. Create sample data"
msgstr ""

#: ../docs/use_cases/question_answering/semantic-search-over-chat.ipynb:80002
msgid ""
"You can generate a sample group chat conversation using ChatGPT with this "
"prompt:"
msgstr ""

#: ../docs/use_cases/question_answering/semantic-search-over-chat.ipynb:80008
msgid ""
"I've already generated such a chat in `messages.txt`. We can keep it simple "
"and use this for our example."
msgstr ""

#: ../docs/use_cases/question_answering/semantic-search-over-chat.ipynb:80010
msgid "3. Ingest chat embeddings"
msgstr ""

#: ../docs/use_cases/question_answering/semantic-search-over-chat.ipynb:80012
msgid ""
"We load the messages in the text file, chunk and upload to ActiveLoop Vector "
"store."
msgstr ""

#: ../docs/use_cases/question_answering/semantic-search-over-chat.ipynb:100002
msgid "4. Ask questions"
msgstr ""

#: ../docs/use_cases/question_answering/semantic-search-over-chat.ipynb:100004
msgid ""
"Now we can ask a question and get an answer back with a semantic search:"
msgstr ""

#: ../docs/use_cases/summarization.md:1
msgid "Summarization"
msgstr ""

#: ../docs/use_cases/summarization.md:3
msgid ""
"[Conceptual Guide](https://docs.langchain.com/docs/use-cases/summarization)"
msgstr ""

#: ../docs/use_cases/summarization.md:6
msgid ""
"Summarization involves creating a smaller summary of multiple longer "
"documents. This can be useful for distilling long documents into the core "
"pieces of information."
msgstr ""

#: ../docs/use_cases/summarization.md:9
msgid "The recommended way to get started using a summarization chain is:"
msgstr ""

#: ../docs/use_cases/summarization.md:18
msgid ""
"[Summarization Notebook](../modules/chains/index_examples/summarize.ipynb): "
"A notebook walking through how to accomplish this task."
msgstr ""

#: ../docs/use_cases/summarization.md:21
msgid ""
"[Utilities for working with Documents](../reference/utils.rst): Guides on "
"how to use several of the utilities which will prove helpful for this task, "
"including Text Splitters (for splitting up long documents)."
msgstr ""

#: ../docs/use_cases/tabular.md:1
msgid "Querying Tabular Data"
msgstr ""

#: ../docs/use_cases/tabular.md:3
msgid ""
"[Conceptual Guide](https://docs.langchain.com/docs/use-cases/qa-tabular)"
msgstr ""

#: ../docs/use_cases/tabular.md:6
msgid ""
"Lots of data and information is stored in tabular data, whether it be csvs, "
"excel sheets, or SQL tables. This page covers all resources available in "
"LangChain for working with data in this format."
msgstr ""

#: ../docs/use_cases/tabular.md:9
msgid "Document Loading"
msgstr ""

#: ../docs/use_cases/tabular.md:10
msgid ""
"If you have text data stored in a tabular format, you may want to load the "
"data into a Document and then index it as you would other text/unstructured "
"data. For this, you should use a document loader like the [CSVLoader](../"
"modules/indexes/document_loaders/examples/csv.ipynb) and then you should "
"[create an index](../modules/indexes.rst) over that data, and [query it that "
"way](../modules/chains/index_examples/vector_db_qa.ipynb)."
msgstr ""

#: ../docs/use_cases/tabular.md:14
msgid "Querying"
msgstr ""

#: ../docs/use_cases/tabular.md:15
msgid ""
"If you have more numeric tabular data, or have a large amount of data and "
"don't want to index it, you should get started by looking at various chains "
"and agents we have for dealing with this data."
msgstr ""

#: ../docs/use_cases/tabular.md:20
msgid ""
"If you are just getting started, and you have relatively small/simple "
"tabular data, you should get started with chains. Chains are a sequence of "
"predetermined steps, so they are good to get started with as they give you "
"more control and let you  understand what is happening better."
msgstr ""

#: ../docs/use_cases/tabular.md:24
msgid "[SQL Database Chain](../modules/chains/examples/sqlite.ipynb)"
msgstr ""

#: ../docs/use_cases/tabular.md:28
msgid ""
"Agents are more complex, and involve multiple queries to the LLM to "
"understand what to do. The downside of agents are that you have less "
"control. The upside is that they are more powerful, which allows you to use "
"them on larger databases and more complex schemas."
msgstr ""

#: ../docs/use_cases/tabular.md:32
msgid "[SQL Agent](../modules/agents/toolkits/examples/sql_database.ipynb)"
msgstr ""

#: ../docs/use_cases/tabular.md:33
msgid "[Pandas Agent](../modules/agents/toolkits/examples/pandas.ipynb)"
msgstr ""

#: ../docs/use_cases/tabular.md:34
msgid "[CSV Agent](../modules/agents/toolkits/examples/csv.ipynb)"
msgstr ""

#: ../docs/youtube.md:1
msgid "YouTube"
msgstr ""

#: ../docs/youtube.md:3
msgid "This is a collection of `LangChain` tutorials and videos on `YouTube`."
msgstr ""

#: ../docs/youtube.md:5
msgid "Introduction to LangChain with Harrison Chase, creator of LangChain"
msgstr ""

#: ../docs/youtube.md:6
msgid ""
"[Building the Future with LLMs, `LangChain`, & `Pinecone`](https://youtu.be/"
"nMniwlGyX-c) by [Pinecone](https://www.youtube.com/@pinecone-io)"
msgstr ""

#: ../docs/youtube.md:7
msgid ""
"[LangChain and Weaviate with Harrison Chase and Bob van Luijt - Weaviate "
"Podcast #36](https://youtu.be/lhby7Ql7hbk) by [Weaviate â€¢ Vector Database]"
"(https://www.youtube.com/@Weaviate)"
msgstr ""

#: ../docs/youtube.md:8
msgid ""
"[LangChain Demo + Q&A with Harrison Chase](https://youtu.be/zaYTXQFR0_s?"
"t=788) by [Full Stack Deep Learning](https://www.youtube.com/"
"@FullStackDeepLearning)"
msgstr ""

#: ../docs/youtube.md:10
msgid "Tutorials"
msgstr ""

#: ../docs/youtube.md:12
msgid ""
"[LangChain Crash Course - Build apps with language models](https://youtu.be/"
"LbT1yp6quS8) by [Patrick Loeber](https://www.youtube.com/@patloeber)"
msgstr ""

#: ../docs/youtube.md:14
msgid ""
"[LangChain for Gen AI and LLMs](https://www.youtube.com/playlist?"
"list=PLIUOU7oqGTLieV9uTIFMm6_4PXg-hlN6F) by [James Briggs](https://www."
"youtube.com/@jamesbriggs):"
msgstr ""

#: ../docs/youtube.md:15
msgid ""
"#1 [Getting Started with `GPT-3` vs. Open Source LLMs](https://youtu.be/"
"nE2skSRWTTs)"
msgstr ""

#: ../docs/youtube.md:16
msgid ""
"#2 [Prompt Templates for `GPT 3.5` and other LLMs](https://youtu.be/"
"RflBcK0oDH0)"
msgstr ""

#: ../docs/youtube.md:17
msgid ""
"#3 [LLM Chains using `GPT 3.5` and other LLMs](https://youtu.be/S8j9Tk0lZHU)"
msgstr ""

#: ../docs/youtube.md:18
msgid ""
"#4 [Chatbot Memory for `Chat-GPT`, `Davinci` + other LLMs](https://youtu.be/"
"X05uK0TZozM)"
msgstr ""

#: ../docs/youtube.md:19
msgid "#5 [Chat with OpenAI in LangChain](https://youtu.be/CnAgB3A5OlU)"
msgstr ""

#: ../docs/youtube.md:20
msgid ""
"#6 [LangChain Agents Deep Dive with `GPT 3.5`](https://youtu.be/jSP-gSEyVeI)"
msgstr ""

#: ../docs/youtube.md:21
msgid ""
"[Prompt Engineering with OpenAI's GPT-3 and other LLMs](https://youtu.be/"
"BP9fi_0XTlw)"
msgstr ""

#: ../docs/youtube.md:23
msgid ""
"[LangChain 101](https://www.youtube.com/playlist?"
"list=PLqZXAkvF1bPNQER9mLmDbntNfSpzdDIU5) by [Data Independent](https://www."
"youtube.com/@DataIndependent):"
msgstr ""

#: ../docs/youtube.md:24
msgid ""
"[What Is LangChain? - LangChain + `ChatGPT` Overview](https://youtu.be/"
"_v_fgW2SkkQ)"
msgstr ""

#: ../docs/youtube.md:25
msgid "[Quickstart Guide](https://youtu.be/kYRB-vJFy38)"
msgstr ""

#: ../docs/youtube.md:26
msgid "[Beginner Guide To 7 Essential Concepts](https://youtu.be/2xxziIWmaSA)"
msgstr ""

#: ../docs/youtube.md:27
msgid "[`OpenAI` + `Wolfram Alpha`](https://youtu.be/UijbzCIJ99g)"
msgstr ""

#: ../docs/youtube.md:28
msgid ""
"[Ask Questions On Your Custom (or Private) Files](https://youtu.be/EnT-"
"ZTrcPrg)"
msgstr ""

#: ../docs/youtube.md:29
msgid ""
"[Connect `Google Drive Files` To `OpenAI`](https://youtu.be/IqqHqDcXLww)"
msgstr ""

#: ../docs/youtube.md:30
msgid "[`YouTube Transcripts` + `OpenAI`](https://youtu.be/pNcQ5XXMgH4)"
msgstr ""

#: ../docs/youtube.md:31
msgid ""
"[Question A 300 Page Book (w/ `OpenAI` + `Pinecone`)](https://youtu.be/"
"h0DHDp1FbmQ)"
msgstr ""

#: ../docs/youtube.md:32
msgid ""
"[Workaround `OpenAI's` Token Limit With Chain Types](https://youtu.be/"
"f9_BWhCI4Zo)"
msgstr ""

#: ../docs/youtube.md:33
msgid ""
"[Build Your Own OpenAI + LangChain Web App in 23 Minutes](https://youtu.be/"
"U_eV8wfMkXU)"
msgstr ""

#: ../docs/youtube.md:34
msgid "[Working With The New `ChatGPT API`](https://youtu.be/e9P7FLi5Zy8)"
msgstr ""

#: ../docs/youtube.md:35
msgid ""
"[OpenAI + LangChain Wrote Me 100 Custom Sales Emails](https://youtu.be/"
"y1pyAQM-3Bo)"
msgstr ""

#: ../docs/youtube.md:36
msgid ""
"[Structured Output From `OpenAI` (Clean Dirty Data)](https://youtu.be/"
"KwAXfey-xQk)"
msgstr ""

#: ../docs/youtube.md:37
msgid ""
"[Connect `OpenAI` To +5,000 Tools (LangChain + `Zapier`)](https://youtu."
"be/7tNm0yiDigU)"
msgstr ""

#: ../docs/youtube.md:38
msgid ""
"[Use LLMs To Extract Data From Text (Expert Mode)](https://youtu.be/"
"xZzvwR9jdPA)"
msgstr ""

#: ../docs/youtube.md:40
msgid ""
"[LangChain How to and guides](https://www.youtube.com/playlist?"
"list=PL8motc6AQftk1Bs42EW45kwYbyJ4jOdiZ) by [Sam Witteveen](https://www."
"youtube.com/@samwitteveenai):"
msgstr ""

#: ../docs/youtube.md:41
msgid ""
"[LangChain Basics - LLMs & PromptTemplates with Colab](https://youtu.be/"
"J_0qvRt4LNk)"
msgstr ""

#: ../docs/youtube.md:42
msgid "[LangChain Basics - Tools and Chains](https://youtu.be/hI2BY7yl_Ac)"
msgstr ""

#: ../docs/youtube.md:43
msgid ""
"[`ChatGPT API` Announcement & Code Walkthrough with LangChain](https://youtu."
"be/phHqvLHCwH4)"
msgstr ""

#: ../docs/youtube.md:44
msgid ""
"[Conversations with Memory (explanation & code walkthrough)](https://youtu."
"be/X550Zbz_ROE)"
msgstr ""

#: ../docs/youtube.md:45
msgid "[Chat with `Flan20B`](https://youtu.be/VW5LBavIfY4)"
msgstr ""

#: ../docs/youtube.md:46
msgid ""
"[Using `Hugging Face Models` locally (code walkthrough)](https://youtu.be/"
"Kn7SX2Mx_Jk)"
msgstr ""

#: ../docs/youtube.md:47
msgid ""
"[`PAL` : Program-aided Language Models with LangChain code](https://youtu.be/"
"dy7-LvDu-3s)"
msgstr ""

#: ../docs/youtube.md:48
msgid ""
"[Building a Summarization System with LangChain and `GPT-3` - Part 1]"
"(https://youtu.be/LNq_2s_H01Y)"
msgstr ""

#: ../docs/youtube.md:49
msgid ""
"[Building a Summarization System with LangChain and `GPT-3` - Part 2]"
"(https://youtu.be/d-yeHDLgKHw)"
msgstr ""

#: ../docs/youtube.md:50
msgid ""
"[Microsoft's `Visual ChatGPT` using LangChain](https://youtu.be/7YEiEyfPF5U)"
msgstr ""

#: ../docs/youtube.md:51
msgid ""
"[LangChain Agents - Joining Tools and Chains with Decisions](https://youtu."
"be/ziu87EXZVUE)"
msgstr ""

#: ../docs/youtube.md:52
msgid "[Comparing LLMs with LangChain](https://youtu.be/rFNG0MIEuW0)"
msgstr ""

#: ../docs/youtube.md:53
msgid "[Using `Constitutional AI` in LangChain](https://youtu.be/uoVqNFDwpX4)"
msgstr ""

#: ../docs/youtube.md:54
msgid ""
"[Talking to `Alpaca` with LangChain - Creating an Alpaca Chatbot](https://"
"youtu.be/v6sF8Ed3nTE)"
msgstr ""

#: ../docs/youtube.md:55
msgid ""
"[Talk to your `CSV` & `Excel` with LangChain](https://youtu.be/xQ3mZhw69bc)"
msgstr ""

#: ../docs/youtube.md:56
msgid ""
"[`BabyAGI`: Discover the Power of Task-Driven Autonomous Agents!](https://"
"youtu.be/QBcDLSE2ERA)"
msgstr ""

#: ../docs/youtube.md:57
msgid "[Improve your `BabyAGI` with LangChain](https://youtu.be/DRgPyOXZ-oE)"
msgstr ""

#: ../docs/youtube.md:59
msgid ""
"[LangChain](https://www.youtube.com/playlist?"
"list=PLVEEucA9MYhOu89CX8H3MBZqayTbcCTMr) by [Prompt Engineering](https://www."
"youtube.com/@engineerprompt):"
msgstr ""

#: ../docs/youtube.md:60
msgid ""
"[LangChain Crash Course - All You Need to Know to Build Powerful Apps with "
"LLMs](https://youtu.be/5-fc4Tlgmro)"
msgstr ""

#: ../docs/youtube.md:61
msgid ""
"[Working with MULTIPLE `PDF` Files in LangChain: `ChatGPT` for your Data]"
"(https://youtu.be/s5LhRdh5fu4)"
msgstr ""

#: ../docs/youtube.md:62
msgid ""
"[`ChatGPT` for YOUR OWN `PDF` files with LangChain](https://youtu.be/"
"TLf90ipMzfE)"
msgstr ""

#: ../docs/youtube.md:63
msgid ""
"[Talk to YOUR DATA without OpenAI APIs: LangChain](https://youtu.be/wrD-"
"fZvT6UI)"
msgstr ""

#: ../docs/youtube.md:65
msgid "LangChain by [Chat with data](https://www.youtube.com/@chatwithdata)"
msgstr ""

#: ../docs/youtube.md:66
msgid ""
"[LangChain Beginner's Tutorial for `Typescript`/`Javascript`](https://youtu."
"be/bH722QgRlhQ)"
msgstr ""

#: ../docs/youtube.md:67
msgid ""
"[`GPT-4` Tutorial: How to Chat With Multiple `PDF` Files (~1000 pages of "
"Tesla's 10-K Annual Reports)](https://youtu.be/Ix9WIZpArm0)"
msgstr ""

#: ../docs/youtube.md:68
msgid ""
"[`GPT-4` & LangChain Tutorial: How to Chat With A 56-Page `PDF` Document (w/"
"`Pinecone`)](https://youtu.be/ih9PBGVVOO4)"
msgstr ""

#: ../docs/youtube.md:70
msgid "Videos (sorted by views)"
msgstr ""

#: ../docs/youtube.md:72
msgid ""
"[Building AI LLM Apps with LangChain (and more?) - LIVE STREAM](https://www."
"youtube.com/live/M-2Cj_2fzWI?feature=share) by [Nicholas Renotte](https://"
"www.youtube.com/@NicholasRenotte)"
msgstr ""

#: ../docs/youtube.md:73
msgid ""
"[First look - `ChatGPT` + `WolframAlpha` (`GPT-3.5` and Wolfram|Alpha via "
"LangChain by James Weaver)](https://youtu.be/wYGbY811oMo) by [Dr Alan D. "
"Thompson](https://www.youtube.com/@DrAlanDThompson)"
msgstr ""

#: ../docs/youtube.md:74
msgid ""
"[LangChain explained - The hottest new Python framework](https://youtu.be/"
"RoR4XJw8wIc) by [AssemblyAI](https://www.youtube.com/@AssemblyAI)"
msgstr ""

#: ../docs/youtube.md:75
msgid ""
"[Chatbot with INFINITE MEMORY using `OpenAI` & `Pinecone` - `GPT-3`, "
"`Embeddings`, `ADA`, `Vector DB`, `Semantic`](https://youtu.be/2xNzB7xq8nk) "
"by [David Shapiro ~ AI](https://www.youtube.com/@DavidShapiroAutomator)"
msgstr ""

#: ../docs/youtube.md:76
msgid ""
"[LangChain for LLMs is... basically just an Ansible playbook](https://youtu."
"be/X51N9C-OhlE) by [David Shapiro ~ AI](https://www.youtube.com/"
"@DavidShapiroAutomator)"
msgstr ""

#: ../docs/youtube.md:77
msgid ""
"[Build your own LLM Apps with LangChain & `GPT-Index`](https://youtu."
"be/-75p09zFUJY) by [1littlecoder](https://www.youtube.com/@1littlecoder)"
msgstr ""

#: ../docs/youtube.md:78
msgid ""
"[`BabyAGI` - New System of Autonomous AI Agents with LangChain](https://"
"youtu.be/lg3kJvf1kXo) by [1littlecoder](https://www.youtube.com/"
"@1littlecoder)"
msgstr ""

#: ../docs/youtube.md:79
msgid ""
"[Run `BabyAGI` with Langchain Agents (with Python Code)](https://youtu.be/"
"WosPGHPObx8) by [1littlecoder](https://www.youtube.com/@1littlecoder)"
msgstr ""

#: ../docs/youtube.md:80
msgid ""
"[How to Use Langchain With `Zapier` | Write and Send Email with GPT-3 | "
"OpenAI API Tutorial](https://youtu.be/p9v2-xEa9A0) by [StarMorph AI](https://"
"www.youtube.com/@starmorph)"
msgstr ""

#: ../docs/youtube.md:81
msgid ""
"[Use Your Locally Stored Files To Get Response From GPT - `OpenAI` | "
"Langchain | Python](https://youtu.be/NC1Ni9KS-rk) by [Shweta Lodha](https://"
"www.youtube.com/@shweta-lodha)"
msgstr ""

#: ../docs/youtube.md:82
msgid ""
"[`Langchain JS` | How to Use GPT-3, GPT-4 to Reference your own Data | "
"`OpenAI Embeddings` Intro](https://youtu.be/veV2I-NEjaM) by [StarMorph AI]"
"(https://www.youtube.com/@starmorph)"
msgstr ""

#: ../docs/youtube.md:83
msgid ""
"[The easiest way to work with large language models | Learn LangChain in "
"10min](https://youtu.be/kmbS6FDQh7c) by [Sophia Yang](https://www.youtube."
"com/@SophiaYangDS)"
msgstr ""

#: ../docs/youtube.md:84
msgid ""
"[4 Autonomous AI Agents: â€œWestworldâ€ simulation `BabyAGI`, `AutoGPT`, "
"`Camel`, `LangChain`](https://youtu.be/yWbnH6inT_U) by [Sophia Yang](https://"
"www.youtube.com/@SophiaYangDS)"
msgstr ""

#: ../docs/youtube.md:85
msgid ""
"[AI CAN SEARCH THE INTERNET? Langchain Agents + OpenAI ChatGPT](https://"
"youtu.be/J-GL0htqda8) by [tylerwhatsgood](https://www.youtube.com/"
"@tylerwhatsgood)"
msgstr ""

#: ../docs/youtube.md:86
msgid ""
"[`Weaviate` + LangChain for LLM apps presented by Erika Cardenas](https://"
"youtu.be/7AGj4Td5Lgw) by [`Weaviate` â€¢ Vector Database](https://www.youtube."
"com/@Weaviate)"
msgstr ""

#: ../docs/youtube.md:87
msgid ""
"[Analyze Custom `CSV` Data with `GPT-4` using Langchain](https://youtu.be/"
"Ew3sGdX8at4) by [Venelin Valkov](https://www.youtube.com/@venelin_valkov)"
msgstr ""

#: ../docs/youtube.md:88
msgid ""
"[Langchain Overview - How to Use Langchain & `ChatGPT`](https://youtu.be/"
"oYVYIq0lOtI) by [Python In Office](https://www.youtube.com/"
"@pythoninoffice6568)"
msgstr ""

#: ../docs/youtube.md:89
msgid ""
"[Custom langchain Agent & Tools with memory. Turn any `Python function` into "
"langchain tool with Gpt 3](https://youtu.be/NIG8lXk0ULg) by [echohive]"
"(https://www.youtube.com/@echohive)"
msgstr ""

#: ../docs/youtube.md:90
msgid ""
"[`ChatGPT` with any `YouTube` video using langchain and `chromadb`](https://"
"youtu.be/TQZfB2bzVwU) by [echohive](https://www.youtube.com/@echohive)"
msgstr ""

#: ../docs/youtube.md:91
msgid ""
"[How to Talk to a `PDF` using LangChain and `ChatGPT`](https://youtu.be/"
"v2i1YDtrIwk) by [Automata Learning Lab](https://www.youtube.com/"
"@automatalearninglab)"
msgstr ""

#: ../docs/youtube.md:92
msgid ""
"[Langchain Document Loaders Part 1: Unstructured Files](https://youtu.be/"
"O5C0wfsen98) by [Merk](https://www.youtube.com/@merksworld)"
msgstr ""

#: ../docs/youtube.md:93
msgid ""
"[LangChain - Prompt Templates (what all the best prompt engineers use)]"
"(https://youtu.be/1aRu8b0XNOQ) by [Nick Daigler](https://www.youtube.com/"
"@nick_daigs)"
msgstr ""

#: ../docs/youtube.md:94
msgid ""
"[LangChain. Crear aplicaciones Python impulsadas por GPT](https://youtu.be/"
"DkW_rDndts8) by [JesÃºs Conde](https://www.youtube.com/@0utKast)"
msgstr ""

#: ../docs/youtube.md:95
msgid ""
"[Easiest Way to Use GPT In Your Products | LangChain Basics Tutorial]"
"(https://youtu.be/fLy0VenZyGc) by [Rachel Woods](https://www.youtube.com/"
"@therachelwoods)"
msgstr ""

#: ../docs/youtube.md:96
msgid ""
"[`BabyAGI` + `GPT-4` Langchain Agent with Internet Access](https://youtu.be/"
"wx1z_hs5P6E) by [tylerwhatsgood](https://www.youtube.com/@tylerwhatsgood)"
msgstr ""

#: ../docs/youtube.md:97
msgid ""
"[Learning LLM Agents. How does it actually work? LangChain, AutoGPT & OpenAI]"
"(https://youtu.be/mb_YAABSplk) by [Arnoldas Kemeklis](https://www.youtube."
"com/@processusAI)"
msgstr ""

#: ../docs/youtube.md:98
msgid ""
"[Get Started with LangChain in `Node.js`](https://youtu.be/Wxx1KUWJFv4) by "
"[Developers Digest](https://www.youtube.com/@DevelopersDigest)"
msgstr ""

#: ../docs/youtube.md:99
msgid ""
"[LangChain + `OpenAI` tutorial: Building a Q&A system w/ own text data]"
"(https://youtu.be/DYOU_Z0hAwo) by [Samuel Chan](https://www.youtube.com/"
"@SamuelChan)"
msgstr ""

#: ../docs/youtube.md:100
msgid ""
"[Langchain + `Zapier` Agent](https://youtu.be/yribLAb-pxA) by [Merk](https://"
"www.youtube.com/@merksworld)"
msgstr ""

#: ../docs/youtube.md:101
msgid ""
"[Connecting the Internet with `ChatGPT` (LLMs) using Langchain And Answers "
"Your Questions](https://youtu.be/9Y0TBC63yZg) by [Kamalraj M M](https://www."
"youtube.com/@insightbuilder)"
msgstr ""

#: ../docs/youtube.md:102
msgid ""
"[Build More Powerful LLM Applications for Businessâ€™s with LangChain "
"(Beginners Guide)](https://youtu.be/sp3-WLKEcBg) by[ No Code Blackbox]"
"(https://www.youtube.com/@nocodeblackbox)"
msgstr ""
