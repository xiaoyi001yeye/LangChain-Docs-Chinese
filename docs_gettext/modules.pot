# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2023, Harrison Chase
# This file is distributed under the same license as the ü¶úüîó LangChain package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: ü¶úüîó LangChain 0.0.150\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2023-04-27 12:46+0000\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#: ../docs/modules/agents.rst:2
#: ../docs/modules/agents/agents.rst:2
msgid "Agents"
msgstr ""

#: ../docs/modules/agents.rst:5
msgid "`Conceptual Guide <https://docs.langchain.com/docs/components/agents>`_"
msgstr ""

#: ../docs/modules/agents.rst:8
msgid "Some applications will require not just a predetermined chain of calls to LLMs/other tools, but potentially an unknown chain that depends on the user's input. In these types of chains, there is a ‚Äúagent‚Äù which has access to a suite of tools. Depending on the user input, the agent can then decide which, if any, of these tools to call."
msgstr ""

#: ../docs/modules/agents.rst:13
msgid "In this section of documentation, we first start with a Getting Started notebook to cover how to use all things related to agents in an end-to-end manner."
msgstr ""

#: ../docs/modules/agents.rst:22
msgid "We then split the documentation into the following sections:"
msgstr ""

#: ../docs/modules/agents.rst:24
msgid "**Tools**"
msgstr ""

#: ../docs/modules/agents.rst:26
msgid "An overview of the various tools LangChain supports."
msgstr ""

#: ../docs/modules/agents.rst:29
msgid "**Agents**"
msgstr ""

#: ../docs/modules/agents.rst:31
msgid "An overview of the different agent types."
msgstr ""

#: ../docs/modules/agents.rst:34
msgid "**Toolkits**"
msgstr ""

#: ../docs/modules/agents.rst:36
msgid "An overview of toolkits, and examples of the different ones LangChain supports."
msgstr ""

#: ../docs/modules/agents.rst:39
msgid "**Agent Executor**"
msgstr ""

#: ../docs/modules/agents.rst:41
msgid "An overview of the Agent Executor class and examples of how to use it."
msgstr ""

#: ../docs/modules/agents.rst:44
#: ../docs/modules/indexes.rst:49
#: ../docs/modules/models.rst:33
#: ../docs/modules/prompts.rst:41
msgid "Go Deeper"
msgstr ""

#: ../docs/modules/agents/agent_executors.rst:2
msgid "Agent Executors"
msgstr ""

#: ../docs/modules/agents/agent_executors.rst:5
msgid "`Conceptual Guide <https://docs.langchain.com/docs/components/agents/agent-executor>`_"
msgstr ""

#: ../docs/modules/agents/agent_executors.rst:7
msgid "Agent executors take an agent and tools and use the agent to decide which tools to call and in what order."
msgstr ""

#: ../docs/modules/agents/agent_executors.rst:9
msgid "In this part of the documentation we cover other related functionality to agent executors"
msgstr ""

#: ../docs/modules/agents/agent_executors/examples/agent_vectorstore.ipynb:10002
msgid "How to combine agents and vectorstores"
msgstr ""

#: ../docs/modules/agents/agent_executors/examples/agent_vectorstore.ipynb:10004
msgid "This notebook covers how to combine agents and vectorstores. The use case for this is that you've ingested your data into a vectorstore and want to interact with it in an agentic manner."
msgstr ""

#: ../docs/modules/agents/agent_executors/examples/agent_vectorstore.ipynb:10006
msgid "The recommended method for doing so is to create a RetrievalQA and then use that as a tool in the overall agent. Let's take a look at doing this below. You can do this with multiple different vectordbs, and use the agent as a way to route between them. There are two different ways of doing this - you can either let the agent use the vectorstores as normal tools, or you can set `return_direct=True` to really just use the agent as a router."
msgstr ""

#: ../docs/modules/agents/agent_executors/examples/agent_vectorstore.ipynb:20002
msgid "Create the Vectorstore"
msgstr ""

#: ../docs/modules/agents/agent_executors/examples/agent_vectorstore.ipynb:110002
#: ../docs/modules/agents/toolkits/examples/openapi_nla.ipynb:60002
msgid "Create the Agent"
msgstr ""

#: ../docs/modules/agents/agent_executors/examples/agent_vectorstore.ipynb:170002
msgid "Use the Agent solely as a router"
msgstr ""

#: ../docs/modules/agents/agent_executors/examples/agent_vectorstore.ipynb:180002
msgid "You can also set `return_direct=True` if you intend to use the agent as a router and just want to directly return the result of the RetrievalQAChain."
msgstr ""

#: ../docs/modules/agents/agent_executors/examples/agent_vectorstore.ipynb:180004
msgid "Notice that in the above examples the agent did some extra work after querying the RetrievalQAChain. You can avoid that and just return the result directly."
msgstr ""

#: ../docs/modules/agents/agent_executors/examples/agent_vectorstore.ipynb:230002
msgid "Multi-Hop vectorstore reasoning"
msgstr ""

#: ../docs/modules/agents/agent_executors/examples/agent_vectorstore.ipynb:230004
msgid "Because vectorstores are easily usable as tools in agents, it is easy to use answer multi-hop questions that depend on vectorstores using the existing agent framework"
msgstr ""

#: ../docs/modules/agents/agent_executors/examples/async_agent.ipynb:10002
msgid "How to use the async API for Agents"
msgstr ""

#: ../docs/modules/agents/agent_executors/examples/async_agent.ipynb:10004
msgid "LangChain provides async support for Agents by leveraging the [asyncio](https://docs.python.org/3/library/asyncio.html) library."
msgstr ""

#: ../docs/modules/agents/agent_executors/examples/async_agent.ipynb:10006
msgid "Async methods are currently supported for the following `Tools`: [`SerpAPIWrapper`](https://github.com/hwchase17/langchain/blob/master/langchain/serpapi.py) and [`LLMMathChain`](https://github.com/hwchase17/langchain/blob/master/langchain/chains/llm_math/base.py). Async support for other agent tools are on the roadmap."
msgstr ""

#: ../docs/modules/agents/agent_executors/examples/async_agent.ipynb:10008
msgid "For `Tool`s that have a `coroutine` implemented (the two mentioned above), the `AgentExecutor` will `await` them directly. Otherwise, the `AgentExecutor` will call the `Tool`'s `func` via `asyncio.get_event_loop().run_in_executor` to avoid blocking the main runloop."
msgstr ""

#: ../docs/modules/agents/agent_executors/examples/async_agent.ipynb:10010
msgid "You can use `arun` to call an `AgentExecutor` asynchronously."
msgstr ""

#: ../docs/modules/agents/agent_executors/examples/async_agent.ipynb:20002
msgid "Serial vs. Concurrent Execution"
msgstr ""

#: ../docs/modules/agents/agent_executors/examples/async_agent.ipynb:20004
msgid "In this example, we kick off agents to answer some questions serially vs. concurrently. You can see that concurrent execution significantly speeds this up."
msgstr ""

#: ../docs/modules/agents/agent_executors/examples/async_agent.ipynb:60002
msgid "Using Tracing with Asynchronous Agents"
msgstr ""

#: ../docs/modules/agents/agent_executors/examples/async_agent.ipynb:60004
msgid "To use tracing with async agents, you must pass in a custom `CallbackManager` with `LangChainTracer` to each agent running asynchronously. This way, you avoid collisions while the trace is being collected."
msgstr ""

#: ../docs/modules/agents/agent_executors/examples/chatgpt_clone.ipynb:10002
msgid "How to create ChatGPT Clone"
msgstr ""

#: ../docs/modules/agents/agent_executors/examples/chatgpt_clone.ipynb:10004
msgid "This chain replicates ChatGPT by combining (1) a specific prompt, and (2) the concept of memory."
msgstr ""

#: ../docs/modules/agents/agent_executors/examples/chatgpt_clone.ipynb:10006
msgid "Shows off the example as in https://www.engraved.blog/building-a-virtual-machine-inside/"
msgstr ""

#: ../docs/modules/agents/agent_executors/examples/intermediate_steps.ipynb:10002
msgid "How to access intermediate steps"
msgstr ""

#: ../docs/modules/agents/agent_executors/examples/intermediate_steps.ipynb:10004
msgid "In order to get more visibility into what an agent is doing, we can also return intermediate steps. This comes in the form of an extra key in the return value, which is a list of (action, observation) tuples."
msgstr ""

#: ../docs/modules/agents/agent_executors/examples/intermediate_steps.ipynb:30002
msgid "Initialize the components needed for the agent."
msgstr ""

#: ../docs/modules/agents/agent_executors/examples/intermediate_steps.ipynb:50002
msgid "Initialize the agent with `return_intermediate_steps=True`"
msgstr ""

#: ../docs/modules/agents/agent_executors/examples/max_iterations.ipynb:10002
msgid "How to cap the max number of iterations"
msgstr ""

#: ../docs/modules/agents/agent_executors/examples/max_iterations.ipynb:10004
msgid "This notebook walks through how to cap an agent at taking a certain number of steps. This can be useful to ensure that they do not go haywire and take too many steps."
msgstr ""

#: ../docs/modules/agents/agent_executors/examples/max_iterations.ipynb:50002
#: ../docs/modules/agents/agent_executors/examples/max_time_limit.ipynb:50002
msgid "First, let's do a run with a normal agent to show what would happen without this parameter. For this example, we will use a specifically crafter adversarial example that tries to trick it into continuing forever."
msgstr ""

#: ../docs/modules/agents/agent_executors/examples/max_iterations.ipynb:50004
#: ../docs/modules/agents/agent_executors/examples/max_time_limit.ipynb:50004
msgid "Try running the cell below and see what happens!"
msgstr ""

#: ../docs/modules/agents/agent_executors/examples/max_iterations.ipynb:90002
msgid "Now let's try it again with the `max_iterations=2` keyword argument. It now stops nicely after a certain amount of iterations!"
msgstr ""

#: ../docs/modules/agents/agent_executors/examples/max_iterations.ipynb:120002
#: ../docs/modules/agents/agent_executors/examples/max_time_limit.ipynb:120002
msgid "By default, the early stopping uses method `force` which just returns that constant string. Alternatively, you could specify method `generate` which then does one FINAL pass through the LLM to generate an output."
msgstr ""

#: ../docs/modules/agents/agent_executors/examples/max_time_limit.ipynb:10002
msgid "How to use a timeout for the agent"
msgstr ""

#: ../docs/modules/agents/agent_executors/examples/max_time_limit.ipynb:10004
msgid "This notebook walks through how to cap an agent executor after a certain amount of time. This can be useful for safeguarding against long running agent runs."
msgstr ""

#: ../docs/modules/agents/agent_executors/examples/max_time_limit.ipynb:90002
msgid "Now let's try it again with the `max_execution_time=1` keyword argument. It now stops nicely after 1 second (only one iteration usually)"
msgstr ""

#: ../docs/modules/agents/agent_executors/examples/sharedmemory_for_tools.ipynb:10002
msgid "How to add SharedMemory to an Agent and its Tools"
msgstr ""

#: ../docs/modules/agents/agent_executors/examples/sharedmemory_for_tools.ipynb:10004
msgid "This notebook goes over adding memory to **both** of an Agent and its tools. Before going through this notebook, please walk through the following notebooks, as this will build on top of both of them:"
msgstr ""

#: ../docs/modules/agents/agent_executors/examples/sharedmemory_for_tools.ipynb:10006
msgid "[Adding memory to an LLM Chain](../../memory/examples/adding_memory.ipynb)"
msgstr ""

#: ../docs/modules/agents/agent_executors/examples/sharedmemory_for_tools.ipynb:10007
msgid "[Custom Agents](custom_agent.ipynb)"
msgstr ""

#: ../docs/modules/agents/agent_executors/examples/sharedmemory_for_tools.ipynb:10009
msgid "We are going to create a custom Agent. The agent has access to a conversation memory, search tool, and a summarization tool. And, the summarization tool also needs access to the conversation memory."
msgstr ""

#: ../docs/modules/agents/agent_executors/examples/sharedmemory_for_tools.ipynb:60002
#: ../docs/modules/memory/examples/agent_with_memory.ipynb:60002
#: ../docs/modules/memory/examples/agent_with_memory_in_db.ipynb:80002
msgid "We can now construct the LLMChain, with the Memory object, and then create the agent."
msgstr ""

#: ../docs/modules/agents/agent_executors/examples/sharedmemory_for_tools.ipynb:90002
#: ../docs/modules/memory/examples/agent_with_memory.ipynb:90002
#: ../docs/modules/memory/examples/agent_with_memory_in_db.ipynb:110002
msgid "To test the memory of this agent, we can ask a followup question that relies on information in the previous exchange to be answered correctly."
msgstr ""

#: ../docs/modules/agents/agent_executors/examples/sharedmemory_for_tools.ipynb:120002
msgid "Confirm that the memory was correctly updated."
msgstr ""

#: ../docs/modules/agents/agent_executors/examples/sharedmemory_for_tools.ipynb:140002
msgid "For comparison, below is a bad example that uses the same memory for both the Agent and the tool."
msgstr ""

#: ../docs/modules/agents/agent_executors/examples/sharedmemory_for_tools.ipynb:190002
msgid "The final answer is not wrong, but we see the 3rd Human input is actually from the agent in the memory because the memory was modified by the summary tool."
msgstr ""

#: ../docs/modules/agents/agents.rst:5
msgid "`Conceptual Guide <https://docs.langchain.com/docs/components/agents/agent>`_"
msgstr ""

#: ../docs/modules/agents/agents.rst:8
msgid "In this part of the documentation we cover the different types of agents, disregarding which specific tools they are used with."
msgstr ""

#: ../docs/modules/agents/agents.rst:10
msgid "For a high level overview of the different types of agents, see the below documentation."
msgstr ""

#: ../docs/modules/agents/agents.rst:18
msgid "For documentation on how to create a custom agent, see the below."
msgstr ""

#: ../docs/modules/agents/agents.rst:32
msgid "We also have documentation for an in-depth dive into each agent type."
msgstr ""

#: ../docs/modules/agents/agents/agent_types.md:1
#: ../docs/modules/agents/how_to_guides.rst:72
msgid "Agent Types"
msgstr ""

#: ../docs/modules/agents/agents/agent_types.md:3
msgid "Agents use an LLM to determine which actions to take and in what order. An action can either be using a tool and observing its output, or returning a response to the user. Here are the agents available in LangChain."
msgstr ""

#: ../docs/modules/agents/agents/agent_types.md:7
msgid "`zero-shot-react-description`"
msgstr ""

#: ../docs/modules/agents/agents/agent_types.md:9
msgid "This agent uses the ReAct framework to determine which tool to use based solely on the tool's description. Any number of tools can be provided. This agent requires that a description is provided for each tool."
msgstr ""

#: ../docs/modules/agents/agents/agent_types.md:13
msgid "`react-docstore`"
msgstr ""

#: ../docs/modules/agents/agents/agent_types.md:15
msgid "This agent uses the ReAct framework to interact with a docstore. Two tools must be provided: a `Search` tool and a `Lookup` tool (they must be named exactly as so). The `Search` tool should search for a document, while the `Lookup` tool should lookup a term in the most recently found document. This agent is equivalent to the original [ReAct paper](https://arxiv.org/pdf/2210.03629.pdf), specifically the Wikipedia example."
msgstr ""

#: ../docs/modules/agents/agents/agent_types.md:22
msgid "`self-ask-with-search`"
msgstr ""

#: ../docs/modules/agents/agents/agent_types.md:24
msgid "This agent utilizes a single tool that should be named `Intermediate Answer`. This tool should be able to lookup factual answers to questions. This agent is equivalent to the original [self ask with search paper](https://ofir.io/self-ask.pdf), where a Google search API was provided as the tool."
msgstr ""

#: ../docs/modules/agents/agents/agent_types.md:29
msgid "`conversational-react-description`"
msgstr ""

#: ../docs/modules/agents/agents/agent_types.md:31
msgid "This agent is designed to be used in conversational settings. The prompt is designed to make the agent helpful and conversational. It uses the ReAct framework to decide which tool to use, and uses memory to remember the previous conversation interactions."
msgstr ""

#: ../docs/modules/agents/agents/custom_agent.ipynb:10002
msgid "Custom Agent"
msgstr ""

#: ../docs/modules/agents/agents/custom_agent.ipynb:10004
#: ../docs/modules/agents/agents/custom_multi_action_agent.ipynb:10004
msgid "This notebook goes through how to create your own custom agent."
msgstr ""

#: ../docs/modules/agents/agents/custom_agent.ipynb:10006
#: ../docs/modules/agents/agents/custom_multi_action_agent.ipynb:10006
msgid "An agent consists of three parts:"
msgstr ""

#: ../docs/modules/agents/agents/custom_agent.ipynb:10012
msgid "In this notebook we walk through how to create a custom agent."
msgstr ""

#: ../docs/modules/agents/agents/custom_agent_with_tool_retrieval.ipynb:10002
msgid "Custom Agent with Tool Retrieval"
msgstr ""

#: ../docs/modules/agents/agents/custom_agent_with_tool_retrieval.ipynb:10004
msgid "This notebook builds off of [this notebook](custom_llm_agent.ipynb) and assumes familiarity with how agents work."
msgstr ""

#: ../docs/modules/agents/agents/custom_agent_with_tool_retrieval.ipynb:10006
msgid "The novel idea introduced in this notebook is the idea of using retrieval to select the set of tools to use to answer an agent query. This is useful when you have many many tools to select from. You cannot put the description of all the tools in the prompt (because of context length issues) so instead you dynamically select the N tools you do want to consider using at run time."
msgstr ""

#: ../docs/modules/agents/agents/custom_agent_with_tool_retrieval.ipynb:10008
msgid "In this notebook we will create a somewhat contrieved example. We will have one legitimate tool (search) and then 99 fake tools which are just nonsense. We will then add a step in the prompt template that takes the user input and retrieves tool relevant to the query."
msgstr ""

#: ../docs/modules/agents/agents/custom_agent_with_tool_retrieval.ipynb:20002
#: ../docs/modules/agents/agents/custom_llm_agent.ipynb:20002
#: ../docs/modules/agents/agents/custom_llm_chat_agent.ipynb:20002
msgid "Set up environment"
msgstr ""

#: ../docs/modules/agents/agents/custom_agent_with_tool_retrieval.ipynb:20004
#: ../docs/modules/agents/agents/custom_llm_agent.ipynb:20004
#: ../docs/modules/agents/agents/custom_llm_chat_agent.ipynb:20004
msgid "Do necessary imports, etc."
msgstr ""

#: ../docs/modules/agents/agents/custom_agent_with_tool_retrieval.ipynb:40002
msgid "Set up tools"
msgstr ""

#: ../docs/modules/agents/agents/custom_agent_with_tool_retrieval.ipynb:40004
msgid "We will create one legitimate tool (search) and then 99 fake tools"
msgstr ""

#: ../docs/modules/agents/agents/custom_agent_with_tool_retrieval.ipynb:60002
msgid "Tool Retriever"
msgstr ""

#: ../docs/modules/agents/agents/custom_agent_with_tool_retrieval.ipynb:60004
msgid "We will use a vectorstore to create embeddings for each tool description. Then, for an incoming query we can create embeddings for that query and do a similarity search for relevant tools."
msgstr ""

#: ../docs/modules/agents/agents/custom_agent_with_tool_retrieval.ipynb:110002
msgid "We can now test this retriever to see if it seems to work."
msgstr ""

#: ../docs/modules/agents/agents/custom_agent_with_tool_retrieval.ipynb:140002
#: ../docs/modules/agents/agents/custom_llm_agent.ipynb:60002
#: ../docs/modules/agents/agents/custom_llm_chat_agent.ipynb:60002
msgid "Prompt Template"
msgstr ""

#: ../docs/modules/agents/agents/custom_agent_with_tool_retrieval.ipynb:140004
msgid "The prompt template is pretty standard, because we're not actually changing that much logic in the actual prompt template, but rather we are just changing how retrieval is done."
msgstr ""

#: ../docs/modules/agents/agents/custom_agent_with_tool_retrieval.ipynb:160002
msgid "The custom prompt template now has the concept of a tools_getter, which we call on the input to select the tools to use"
msgstr ""

#: ../docs/modules/agents/agents/custom_agent_with_tool_retrieval.ipynb:190002
#: ../docs/modules/agents/agents/custom_llm_agent.ipynb:100002
#: ../docs/modules/agents/agents/custom_llm_chat_agent.ipynb:100002
msgid "Output Parser"
msgstr ""

#: ../docs/modules/agents/agents/custom_agent_with_tool_retrieval.ipynb:190004
msgid "The output parser is unchanged from the previous notebook, since we are not changing anything about the output format."
msgstr ""

#: ../docs/modules/agents/agents/custom_agent_with_tool_retrieval.ipynb:220002
msgid "Set up LLM, stop sequence, and the agent"
msgstr ""

#: ../docs/modules/agents/agents/custom_agent_with_tool_retrieval.ipynb:220004
msgid "Also the same as the previous notebook"
msgstr ""

#: ../docs/modules/agents/agents/custom_agent_with_tool_retrieval.ipynb:260002
#: ../docs/modules/agents/agents/custom_llm_agent.ipynb:190002
#: ../docs/modules/agents/agents/custom_llm_chat_agent.ipynb:190002
msgid "Use the Agent"
msgstr ""

#: ../docs/modules/agents/agents/custom_agent_with_tool_retrieval.ipynb:260004
#: ../docs/modules/agents/agents/custom_llm_agent.ipynb:190004
#: ../docs/modules/agents/agents/custom_llm_chat_agent.ipynb:190004
msgid "Now we can use it!"
msgstr ""

#: ../docs/modules/agents/agents/custom_llm_agent.ipynb:10002
msgid "Custom LLM Agent"
msgstr ""

#: ../docs/modules/agents/agents/custom_llm_agent.ipynb:10004
msgid "This notebook goes through how to create your own custom LLM agent."
msgstr ""

#: ../docs/modules/agents/agents/custom_llm_agent.ipynb:10006
msgid "An LLM agent consists of three parts:"
msgstr ""

#: ../docs/modules/agents/agents/custom_llm_agent.ipynb:10008
#: ../docs/modules/agents/agents/custom_llm_chat_agent.ipynb:10008
msgid "PromptTemplate: This is the prompt template that can be used to instruct the language model on what to do"
msgstr ""

#: ../docs/modules/agents/agents/custom_llm_agent.ipynb:10009
msgid "LLM: This is the language model that powers the agent"
msgstr ""

#: ../docs/modules/agents/agents/custom_llm_agent.ipynb:10010
#: ../docs/modules/agents/agents/custom_llm_chat_agent.ipynb:10010
msgid "`stop` sequence: Instructs the LLM to stop generating as soon as this string is found"
msgstr ""

#: ../docs/modules/agents/agents/custom_llm_agent.ipynb:10011
#: ../docs/modules/agents/agents/custom_llm_chat_agent.ipynb:10011
msgid "OutputParser: This determines how to parse the LLMOutput into an AgentAction or AgentFinish object"
msgstr ""

#: ../docs/modules/agents/agents/custom_llm_agent.ipynb:10014
#: ../docs/modules/agents/agents/custom_llm_chat_agent.ipynb:10014
msgid "The LLMAgent is used in an AgentExecutor. This AgentExecutor can largely be thought of as a loop that:"
msgstr ""

#: ../docs/modules/agents/agents/custom_llm_agent.ipynb:10015
#: ../docs/modules/agents/agents/custom_llm_chat_agent.ipynb:10015
msgid "Passes user input and any previous steps to the Agent (in this case, the LLMAgent)"
msgstr ""

#: ../docs/modules/agents/agents/custom_llm_agent.ipynb:10016
#: ../docs/modules/agents/agents/custom_llm_chat_agent.ipynb:10016
msgid "If the Agent returns an `AgentFinish`, then return that directly to the user"
msgstr ""

#: ../docs/modules/agents/agents/custom_llm_agent.ipynb:10017
#: ../docs/modules/agents/agents/custom_llm_chat_agent.ipynb:10017
msgid "If the Agent returns an `AgentAction`, then use that to call a tool and get an `Observation`"
msgstr ""

#: ../docs/modules/agents/agents/custom_llm_agent.ipynb:10018
#: ../docs/modules/agents/agents/custom_llm_chat_agent.ipynb:10018
msgid "Repeat, passing the `AgentAction` and `Observation` back to the Agent until an `AgentFinish` is emitted."
msgstr ""

#: ../docs/modules/agents/agents/custom_llm_agent.ipynb:10020
#: ../docs/modules/agents/agents/custom_llm_chat_agent.ipynb:10020
msgid "`AgentAction` is a response that consists of `action` and `action_input`. `action` refers to which tool to use, and `action_input` refers to the input to that tool. `log` can also be provided as more context (that can be used for logging, tracing, etc)."
msgstr ""

#: ../docs/modules/agents/agents/custom_llm_agent.ipynb:10022
#: ../docs/modules/agents/agents/custom_llm_chat_agent.ipynb:10022
msgid "`AgentFinish` is a response that contains the final message to be sent back to the user. This should be used to end an agent run."
msgstr ""

#: ../docs/modules/agents/agents/custom_llm_agent.ipynb:10024
#: ../docs/modules/agents/agents/custom_llm_chat_agent.ipynb:10024
msgid "In this notebook we walk through how to create a custom LLM agent."
msgstr ""

#: ../docs/modules/agents/agents/custom_llm_agent.ipynb:40002
#: ../docs/modules/agents/agents/custom_llm_chat_agent.ipynb:40002
msgid "Set up tool"
msgstr ""

#: ../docs/modules/agents/agents/custom_llm_agent.ipynb:40004
#: ../docs/modules/agents/agents/custom_llm_chat_agent.ipynb:40004
msgid "Set up any tools the agent may want to use. This may be necessary to put in the prompt (so that the agent knows to use these tools)."
msgstr ""

#: ../docs/modules/agents/agents/custom_llm_agent.ipynb:60004
#: ../docs/modules/agents/agents/custom_llm_chat_agent.ipynb:60004
msgid "This instructs the agent on what to do. Generally, the template should incorporate:"
msgstr ""

#: ../docs/modules/agents/agents/custom_llm_agent.ipynb:60006
#: ../docs/modules/agents/agents/custom_llm_chat_agent.ipynb:60006
msgid "`tools`: which tools the agent has access and how and when to call them."
msgstr ""

#: ../docs/modules/agents/agents/custom_llm_agent.ipynb:60007
#: ../docs/modules/agents/agents/custom_llm_chat_agent.ipynb:60007
msgid "`intermediate_steps`: These are tuples of previous (`AgentAction`, `Observation`) pairs. These are generally not passed directly to the model, but the prompt template formats them in a specific way."
msgstr ""

#: ../docs/modules/agents/agents/custom_llm_agent.ipynb:60008
#: ../docs/modules/agents/agents/custom_llm_chat_agent.ipynb:60008
msgid "`input`: generic user input"
msgstr ""

#: ../docs/modules/agents/agents/custom_llm_agent.ipynb:100004
#: ../docs/modules/agents/agents/custom_llm_chat_agent.ipynb:100004
msgid "The output parser is responsible for parsing the LLM output into `AgentAction` and `AgentFinish`. This usually depends heavily on the prompt used."
msgstr ""

#: ../docs/modules/agents/agents/custom_llm_agent.ipynb:100006
#: ../docs/modules/agents/agents/custom_llm_chat_agent.ipynb:100006
msgid "This is where you can change the parsing to do retries, handle whitespace, etc"
msgstr ""

#: ../docs/modules/agents/agents/custom_llm_agent.ipynb:130002
#: ../docs/modules/agents/agents/custom_llm_chat_agent.ipynb:130002
msgid "Set up LLM"
msgstr ""

#: ../docs/modules/agents/agents/custom_llm_agent.ipynb:130004
#: ../docs/modules/agents/agents/custom_llm_chat_agent.ipynb:130004
msgid "Choose the LLM you want to use!"
msgstr ""

#: ../docs/modules/agents/agents/custom_llm_agent.ipynb:150002
#: ../docs/modules/agents/agents/custom_llm_chat_agent.ipynb:150002
msgid "Define the stop sequence"
msgstr ""

#: ../docs/modules/agents/agents/custom_llm_agent.ipynb:150004
#: ../docs/modules/agents/agents/custom_llm_chat_agent.ipynb:150004
msgid "This is important because it tells the LLM when to stop generation."
msgstr ""

#: ../docs/modules/agents/agents/custom_llm_agent.ipynb:150006
#: ../docs/modules/agents/agents/custom_llm_chat_agent.ipynb:150006
msgid "This depends heavily on the prompt and model you are using. Generally, you want this to be whatever token you use in the prompt to denote the start of an `Observation` (otherwise, the LLM may hallucinate an observation for you)."
msgstr ""

#: ../docs/modules/agents/agents/custom_llm_agent.ipynb:160002
#: ../docs/modules/agents/agents/custom_llm_chat_agent.ipynb:160002
msgid "Set up the Agent"
msgstr ""

#: ../docs/modules/agents/agents/custom_llm_agent.ipynb:160004
#: ../docs/modules/agents/agents/custom_llm_chat_agent.ipynb:160004
msgid "We can now combine everything to set up our agent"
msgstr ""

#: ../docs/modules/agents/agents/custom_llm_agent.ipynb:220002
msgid "Adding Memory"
msgstr ""

#: ../docs/modules/agents/agents/custom_llm_agent.ipynb:220004
msgid "If you want to add memory to the agent, you'll need to:"
msgstr ""

#: ../docs/modules/agents/agents/custom_llm_agent.ipynb:220006
msgid "Add a place in the custom prompt for the chat_history"
msgstr ""

#: ../docs/modules/agents/agents/custom_llm_agent.ipynb:220007
msgid "Add a memory object to the agent executor."
msgstr ""

#: ../docs/modules/agents/agents/custom_llm_chat_agent.ipynb:10002
msgid "Custom LLM Agent (with a ChatModel)"
msgstr ""

#: ../docs/modules/agents/agents/custom_llm_chat_agent.ipynb:10004
msgid "This notebook goes through how to create your own custom agent based on a chat model."
msgstr ""

#: ../docs/modules/agents/agents/custom_llm_chat_agent.ipynb:10006
msgid "An LLM chat agent consists of three parts:"
msgstr ""

#: ../docs/modules/agents/agents/custom_llm_chat_agent.ipynb:10009
msgid "ChatModel: This is the language model that powers the agent"
msgstr ""

#: ../docs/modules/agents/agents/custom_mrkl_agent.ipynb:10002
msgid "Custom MRKL Agent"
msgstr ""

#: ../docs/modules/agents/agents/custom_mrkl_agent.ipynb:10004
msgid "This notebook goes through how to create your own custom MRKL agent."
msgstr ""

#: ../docs/modules/agents/agents/custom_mrkl_agent.ipynb:10006
msgid "A MRKL agent consists of three parts:"
msgstr ""

#: ../docs/modules/agents/agents/custom_mrkl_agent.ipynb:10013
msgid "In this notebook we walk through how to create a custom MRKL agent by creating a custom LLMChain."
msgstr ""

#: ../docs/modules/agents/agents/custom_mrkl_agent.ipynb:20002
msgid "Custom LLMChain"
msgstr ""

#: ../docs/modules/agents/agents/custom_mrkl_agent.ipynb:20004
msgid "The first way to create a custom agent is to use an existing Agent class, but use a custom LLMChain. This is the simplest way to create a custom Agent. It is highly recommended that you work with the `ZeroShotAgent`, as at the moment that is by far the most generalizable one."
msgstr ""

#: ../docs/modules/agents/agents/custom_mrkl_agent.ipynb:20006
msgid "Most of the work in creating the custom LLMChain comes down to the prompt. Because we are using an existing agent class to parse the output, it is very important that the prompt say to produce text in that format. Additionally, we currently require an `agent_scratchpad` input variable to put notes on previous actions and observations. This should almost always be the final part of the prompt. However, besides those instructions, you can customize the prompt as you wish."
msgstr ""

#: ../docs/modules/agents/agents/custom_mrkl_agent.ipynb:20008
msgid "To ensure that the prompt contains the appropriate instructions, we will utilize a helper method on that class. The helper method for the `ZeroShotAgent` takes the following arguments:"
msgstr ""

#: ../docs/modules/agents/agents/custom_mrkl_agent.ipynb:20010
msgid "tools: List of tools the agent will have access to, used to format the prompt."
msgstr ""

#: ../docs/modules/agents/agents/custom_mrkl_agent.ipynb:20011
msgid "prefix: String to put before the list of tools."
msgstr ""

#: ../docs/modules/agents/agents/custom_mrkl_agent.ipynb:20012
msgid "suffix: String to put after the list of tools."
msgstr ""

#: ../docs/modules/agents/agents/custom_mrkl_agent.ipynb:20013
msgid "input_variables: List of input variables the final prompt will expect."
msgstr ""

#: ../docs/modules/agents/agents/custom_mrkl_agent.ipynb:20015
msgid "For this exercise, we will give our agent access to Google Search, and we will customize it in that we will have it answer as a pirate."
msgstr ""

#: ../docs/modules/agents/agents/custom_mrkl_agent.ipynb:60002
msgid "In case we are curious, we can now take a look at the final prompt template to see what it looks like when its all put together."
msgstr ""

#: ../docs/modules/agents/agents/custom_mrkl_agent.ipynb:80002
msgid "Note that we are able to feed agents a self-defined prompt template, i.e. not restricted to the prompt generated by the `create_prompt` function, assuming it meets the agent's requirements."
msgstr ""

#: ../docs/modules/agents/agents/custom_mrkl_agent.ipynb:80004
msgid "For example, for `ZeroShotAgent`, we will need to ensure that it meets the following requirements. There should a string starting with \"Action:\" and a following string starting with \"Action Input:\", and both should be separated by a newline."
msgstr ""

#: ../docs/modules/agents/agents/custom_mrkl_agent.ipynb:130002
msgid "Multiple inputs"
msgstr ""

#: ../docs/modules/agents/agents/custom_mrkl_agent.ipynb:130003
msgid "Agents can also work with prompts that require multiple inputs."
msgstr ""

#: ../docs/modules/agents/agents/custom_multi_action_agent.ipynb:10002
msgid "Custom MultiAction Agent"
msgstr ""

#: ../docs/modules/agents/agents/custom_multi_action_agent.ipynb:10012
msgid "In this notebook we walk through how to create a custom agent that predicts/takes multiple steps at a time."
msgstr ""

#: ../docs/modules/agents/agents/examples/chat_conversation_agent.ipynb:10002
msgid "Conversation Agent (for Chat Models)"
msgstr ""

#: ../docs/modules/agents/agents/examples/chat_conversation_agent.ipynb:10004
msgid "This notebook walks through using an agent optimized for conversation, using ChatModels. Other agents are often optimized for using tools to figure out the best response, which is not ideal in a conversational setting where you may want the agent to be able to chat with the user as well."
msgstr ""

#: ../docs/modules/agents/agents/examples/chat_conversation_agent.ipynb:10006
msgid "This is accomplished with a specific type of agent (`chat-conversational-react-description`) which expects to be used with a memory component."
msgstr ""

#: ../docs/modules/agents/agents/examples/conversational_agent.ipynb:10002
msgid "Conversation Agent"
msgstr ""

#: ../docs/modules/agents/agents/examples/conversational_agent.ipynb:10004
msgid "This notebook walks through using an agent optimized for conversation. Other agents are often optimized for using tools to figure out the best response, which is not ideal in a conversational setting where you may want the agent to be able to chat with the user as well."
msgstr ""

#: ../docs/modules/agents/agents/examples/conversational_agent.ipynb:10006
msgid "This is accomplished with a specific type of agent (`conversational-react-description`) which expects to be used with a memory component."
msgstr ""

#: ../docs/modules/agents/agents/examples/mrkl.ipynb:10002
msgid "MRKL"
msgstr ""

#: ../docs/modules/agents/agents/examples/mrkl.ipynb:10004
msgid "This notebook showcases using an agent to replicate the MRKL chain."
msgstr ""

#: ../docs/modules/agents/agents/examples/mrkl.ipynb:20002
#: ../docs/modules/agents/agents/examples/mrkl_chat.ipynb:20002
msgid "This uses the example Chinook database. To set it up follow the instructions on https://database.guide/2-sample-databases-sqlite/, placing the `.db` file in a notebooks folder at the root of this repository."
msgstr ""

#: ../docs/modules/agents/agents/examples/mrkl_chat.ipynb:10002
msgid "MRKL Chat"
msgstr ""

#: ../docs/modules/agents/agents/examples/mrkl_chat.ipynb:10004
msgid "This notebook showcases using an agent to replicate the MRKL chain using an agent optimized for chat models."
msgstr ""

#: ../docs/modules/agents/agents/examples/react.ipynb:10002
msgid "ReAct"
msgstr ""

#: ../docs/modules/agents/agents/examples/react.ipynb:10004
msgid "This notebook showcases using an agent to implement the ReAct logic."
msgstr ""

#: ../docs/modules/agents/agents/examples/self_ask_with_search.ipynb:10002
msgid "Self Ask With Search"
msgstr ""

#: ../docs/modules/agents/agents/examples/self_ask_with_search.ipynb:10004
msgid "This notebook showcases the Self Ask With Search chain."
msgstr ""

#: ../docs/modules/agents/getting_started.ipynb:10002
#: ../docs/modules/agents/tools/getting_started.md:1
#: ../docs/modules/chains/getting_started.ipynb:10002
#: ../docs/modules/indexes/getting_started.ipynb:10002
#: ../docs/modules/indexes/text_splitters/getting_started.ipynb:10002
#: ../docs/modules/indexes/vectorstores/getting_started.ipynb:10002
#: ../docs/modules/memory/getting_started.ipynb:10002
#: ../docs/modules/models/chat/getting_started.ipynb:10002
#: ../docs/modules/models/llms/getting_started.ipynb:10002
#: ../docs/modules/prompts/prompt_templates/getting_started.md:1
msgid "Getting Started"
msgstr ""

#: ../docs/modules/agents/getting_started.ipynb:10004
msgid "Agents use an LLM to determine which actions to take and in what order. An action can either be using a tool and observing its output, or returning to the user."
msgstr ""

#: ../docs/modules/agents/getting_started.ipynb:10007
msgid "When used correctly agents can be extremely powerful. The purpose of this notebook is to show you how to easily use agents through the simplest, highest level API."
msgstr ""

#: ../docs/modules/agents/getting_started.ipynb:20002
msgid "In order to load agents, you should understand the following concepts:"
msgstr ""

#: ../docs/modules/agents/getting_started.ipynb:20004
msgid "Tool: A function that performs a specific duty. This can be things like: Google Search, Database lookup, Python REPL, other chains. The interface for a tool is currently a function that is expected to have a string as an input, with a string as an output."
msgstr ""

#: ../docs/modules/agents/getting_started.ipynb:20005
msgid "LLM: The language model powering the agent."
msgstr ""

#: ../docs/modules/agents/getting_started.ipynb:20006
msgid "Agent: The agent to use. This should be a string that references a support agent class. Because this notebook focuses on the simplest, highest level API, this only covers using the standard supported agents. If you want to implement a custom agent, see the documentation for custom agents (coming soon)."
msgstr ""

#: ../docs/modules/agents/getting_started.ipynb:20008
msgid "**Agents**: For a list of supported agents and their specifications, see [here](agents.md)."
msgstr ""

#: ../docs/modules/agents/getting_started.ipynb:20010
msgid "**Tools**: For a list of predefined tools and their specifications, see [here](tools.md)."
msgstr ""

#: ../docs/modules/agents/getting_started.ipynb:40002
msgid "First, let's load the language model we're going to use to control the agent."
msgstr ""

#: ../docs/modules/agents/getting_started.ipynb:60002
msgid "Next, let's load some tools to use. Note that the `llm-math` tool uses an LLM, so we need to pass that in."
msgstr ""

#: ../docs/modules/agents/getting_started.ipynb:80002
msgid "Finally, let's initialize an agent with the tools, the language model, and the type of agent we want to use."
msgstr ""

#: ../docs/modules/agents/getting_started.ipynb:100002
msgid "Now let's test it out!"
msgstr ""

#: ../docs/modules/agents/how_to_guides.rst:2
#: ../docs/modules/chains/how_to_guides.rst:2
#: ../docs/modules/memory/how_to_guides.rst:2
#: ../docs/modules/models/chat/how_to_guides.rst:2
#: ../docs/modules/prompts/output_parsers/how_to_guides.rst:2
#: ../docs/modules/prompts/prompt_templates/how_to_guides.rst:2
msgid "How-To Guides"
msgstr ""

#: ../docs/modules/agents/how_to_guides.rst:4
msgid "There are three types of examples in this section:"
msgstr ""

#: ../docs/modules/agents/how_to_guides.rst:6
msgid "Agent Overview: how-to-guides for generic agent functionality"
msgstr ""

#: ../docs/modules/agents/how_to_guides.rst:7
msgid "Agent Toolkits: how-to-guides for specific agent toolkits (agents optimized for interacting with a certain resource)"
msgstr ""

#: ../docs/modules/agents/how_to_guides.rst:8
msgid "Agent Types: how-to-guides for working with the different agent types"
msgstr ""

#: ../docs/modules/agents/how_to_guides.rst:11
msgid "Agent Overview"
msgstr ""

#: ../docs/modules/agents/how_to_guides.rst:13
msgid "The first category of how-to guides here cover specific parts of working with agents."
msgstr ""

#: ../docs/modules/agents/how_to_guides.rst:15
msgid "`Load From Hub <./examples/load_from_hub.html>`_: This notebook covers how to load agents from `LangChainHub <https://github.com/hwchase17/langchain-hub>`_."
msgstr ""

#: ../docs/modules/agents/how_to_guides.rst:17
msgid "`Custom Tools <./examples/custom_tools.html>`_: How to create custom tools that an agent can use."
msgstr ""

#: ../docs/modules/agents/how_to_guides.rst:19
msgid "`Agents With Vectorstores <./examples/agent_vectorstore.html>`_: How to use vectorstores with agents."
msgstr ""

#: ../docs/modules/agents/how_to_guides.rst:21
msgid "`Intermediate Steps <./examples/intermediate_steps.html>`_: How to access and use intermediate steps to get more visibility into the internals of an agent."
msgstr ""

#: ../docs/modules/agents/how_to_guides.rst:23
msgid "`Custom Agent <./examples/custom_agent.html>`_: How to create a custom agent (specifically, a custom LLM + prompt to drive that agent)."
msgstr ""

#: ../docs/modules/agents/how_to_guides.rst:25
msgid "`Multi Input Tools <./examples/multi_input_tool.html>`_: How to use a tool that requires multiple inputs with an agent."
msgstr ""

#: ../docs/modules/agents/how_to_guides.rst:27
msgid "`Search Tools <./examples/search_tools.html>`_: How to use the different type of search tools that LangChain supports."
msgstr ""

#: ../docs/modules/agents/how_to_guides.rst:29
msgid "`Max Iterations <./examples/max_iterations.html>`_: How to restrict an agent to a certain number of iterations."
msgstr ""

#: ../docs/modules/agents/how_to_guides.rst:31
msgid "`Asynchronous <./examples/async_agent.html>`_: Covering asynchronous functionality."
msgstr ""

#: ../docs/modules/agents/how_to_guides.rst:43
msgid "Agent Toolkits"
msgstr ""

#: ../docs/modules/agents/how_to_guides.rst:45
msgid "The next set of examples covers agents with toolkits. As opposed to the examples above, these examples are not intended to show off an agent `type`, but rather to show off an agent applied to particular use case."
msgstr ""

#: ../docs/modules/agents/how_to_guides.rst:49
msgid "`SQLDatabase Agent <./agent_toolkits/sql_database.html>`_: This notebook covers how to interact with an arbitrary SQL database using an agent."
msgstr ""

#: ../docs/modules/agents/how_to_guides.rst:51
msgid "`JSON Agent <./agent_toolkits/json.html>`_: This notebook covers how to interact with a JSON dictionary using an agent."
msgstr ""

#: ../docs/modules/agents/how_to_guides.rst:53
msgid "`OpenAPI Agent <./agent_toolkits/openapi.html>`_: This notebook covers how to interact with an arbitrary OpenAPI endpoint using an agent."
msgstr ""

#: ../docs/modules/agents/how_to_guides.rst:55
msgid "`VectorStore Agent <./agent_toolkits/vectorstore.html>`_: This notebook covers how to interact with VectorStores using an agent."
msgstr ""

#: ../docs/modules/agents/how_to_guides.rst:57
msgid "`Python Agent <./agent_toolkits/python.html>`_: This notebook covers how to produce and execute python code using an agent."
msgstr ""

#: ../docs/modules/agents/how_to_guides.rst:59
msgid "`Pandas DataFrame Agent <./agent_toolkits/pandas.html>`_: This notebook covers how to do question answering over a pandas dataframe using an agent. Under the hood this calls the Python agent.."
msgstr ""

#: ../docs/modules/agents/how_to_guides.rst:61
msgid "`CSV Agent <./agent_toolkits/csv.html>`_: This notebook covers how to do question answering over a csv file. Under the hood this calls the Pandas DataFrame agent."
msgstr ""

#: ../docs/modules/agents/how_to_guides.rst:74
msgid "The final set of examples are all end-to-end example of different agent types. In all examples there is an Agent with a particular set of tools."
msgstr ""

#: ../docs/modules/agents/how_to_guides.rst:77
msgid "Tools: A tool can be anything that takes in a string and returns a string. This means that you can use both the primitives AND the chains found in `this <../chains.html>`_ documentation. LangChain also provides a list of easily loadable tools. For detailed information on those, please see `this documentation <./tools.html>`_"
msgstr ""

#: ../docs/modules/agents/how_to_guides.rst:78
msgid "Agents: An agent uses an LLMChain to determine which tools to use. For a list of all available agent types, see `here <./agents.html>`_."
msgstr ""

#: ../docs/modules/agents/how_to_guides.rst:80
msgid "**MRKL**"
msgstr ""

#: ../docs/modules/agents/how_to_guides.rst:82
msgid "**Tools used**: Search, SQLDatabaseChain, LLMMathChain"
msgstr ""

#: ../docs/modules/agents/how_to_guides.rst:83
msgid "**Agent used**: `zero-shot-react-description`"
msgstr ""

#: ../docs/modules/agents/how_to_guides.rst:84
msgid "`Paper <https://arxiv.org/pdf/2205.00445.pdf>`_"
msgstr ""

#: ../docs/modules/agents/how_to_guides.rst:85
msgid "**Note**: This is the most general purpose example, so if you are looking to use an agent with arbitrary tools, please start here."
msgstr ""

#: ../docs/modules/agents/how_to_guides.rst:86
msgid "`Example Notebook <./implementations/mrkl.html>`_"
msgstr ""

#: ../docs/modules/agents/how_to_guides.rst:88
msgid "**Self-Ask-With-Search**"
msgstr ""

#: ../docs/modules/agents/how_to_guides.rst:90
msgid "**Tools used**: Search"
msgstr ""

#: ../docs/modules/agents/how_to_guides.rst:91
msgid "**Agent used**: `self-ask-with-search`"
msgstr ""

#: ../docs/modules/agents/how_to_guides.rst:92
msgid "`Paper <https://ofir.io/self-ask.pdf>`_"
msgstr ""

#: ../docs/modules/agents/how_to_guides.rst:93
msgid "`Example Notebook <./implementations/self_ask_with_search.html>`_"
msgstr ""

#: ../docs/modules/agents/how_to_guides.rst:95
msgid "**ReAct**"
msgstr ""

#: ../docs/modules/agents/how_to_guides.rst:97
msgid "**Tools used**: Wikipedia Docstore"
msgstr ""

#: ../docs/modules/agents/how_to_guides.rst:98
msgid "**Agent used**: `react-docstore`"
msgstr ""

#: ../docs/modules/agents/how_to_guides.rst:99
msgid "`Paper <https://arxiv.org/pdf/2210.03629.pdf>`_"
msgstr ""

#: ../docs/modules/agents/how_to_guides.rst:100
msgid "`Example Notebook <./implementations/react.html>`_"
msgstr ""

#: ../docs/modules/agents/toolkits.rst:2
msgid "Toolkits"
msgstr ""

#: ../docs/modules/agents/toolkits.rst:5
msgid "`Conceptual Guide <https://docs.langchain.com/docs/components/agents/toolkit>`_"
msgstr ""

#: ../docs/modules/agents/toolkits.rst:8
msgid "This section of documentation covers agents with toolkits - eg an agent applied to a particular use case."
msgstr ""

#: ../docs/modules/agents/toolkits.rst:10
msgid "See below for a full list of agent toolkits"
msgstr ""

#: ../docs/modules/agents/toolkits/examples/csv.ipynb:10002
msgid "CSV Agent"
msgstr ""

#: ../docs/modules/agents/toolkits/examples/csv.ipynb:10004
msgid "This notebook shows how to use agents to interact with a csv. It is mostly optimized for question answering."
msgstr ""

#: ../docs/modules/agents/toolkits/examples/csv.ipynb:10006
msgid "**NOTE: this agent calls the Pandas DataFrame agent under the hood, which in turn calls the Python agent, which executes LLM generated Python code - this can be bad if the LLM generated Python code is harmful. Use cautiously.**"
msgstr ""

#: ../docs/modules/agents/toolkits/examples/jira.ipynb:10002
msgid "Jira"
msgstr ""

#: ../docs/modules/agents/toolkits/examples/jira.ipynb:10004
msgid "This notebook goes over how to use the Jira tool. The Jira tool allows agents to interact with a given Jira instance, performing actions such as searching for issues and creating issues, the tool wraps the atlassian-python-api library, for more see: https://atlassian-python-api.readthedocs.io/jira.html"
msgstr ""

#: ../docs/modules/agents/toolkits/examples/jira.ipynb:10007
msgid "To use this tool, you must first set as environment variables:     JIRA_API_TOKEN     JIRA_USERNAME     JIRA_INSTANCE_URL"
msgstr ""

#: ../docs/modules/agents/toolkits/examples/json.ipynb:10002
msgid "JSON Agent"
msgstr ""

#: ../docs/modules/agents/toolkits/examples/json.ipynb:10004
msgid "This notebook showcases an agent designed to interact with large JSON/dict objects. This is useful when you want to answer questions about a JSON blob that's too large to fit in the context window of an LLM. The agent is able to iteratively explore the blob to find what it needs to answer the user's question."
msgstr ""

#: ../docs/modules/agents/toolkits/examples/json.ipynb:10006
msgid "In the below example, we are using the OpenAPI spec for the OpenAI API, which you can find [here](https://github.com/openai/openai-openapi/blob/master/openapi.yaml)."
msgstr ""

#: ../docs/modules/agents/toolkits/examples/json.ipynb:10008
msgid "We will use the JSON agent to answer some questions about the API spec."
msgstr ""

#: ../docs/modules/agents/toolkits/examples/json.ipynb:20002
#: ../docs/modules/agents/toolkits/examples/powerbi.ipynb:20002
#: ../docs/modules/agents/toolkits/examples/sql_database.ipynb:20002
msgid "Initialization"
msgstr ""

#: ../docs/modules/agents/toolkits/examples/json.ipynb:50002
msgid "Example: getting the required POST parameters for a request"
msgstr ""

#: ../docs/modules/agents/toolkits/examples/openapi.ipynb:10002
msgid "OpenAPI agents"
msgstr ""

#: ../docs/modules/agents/toolkits/examples/openapi.ipynb:10004
msgid "We can construct agents to consume arbitrary APIs, here APIs conformant to the OpenAPI/Swagger specification."
msgstr ""

#: ../docs/modules/agents/toolkits/examples/openapi.ipynb:20002
msgid "1st example: hierarchical planning agent"
msgstr ""

#: ../docs/modules/agents/toolkits/examples/openapi.ipynb:20004
msgid "In this example, we'll consider an approach called hierarchical planning, common in robotics and appearing in recent works for LLMs X robotics. We'll see it's a viable approach to start working with a massive API spec AND to assist with user queries that require multiple steps against the API."
msgstr ""

#: ../docs/modules/agents/toolkits/examples/openapi.ipynb:20006
msgid "The idea is simple: to get coherent agent behavior over long sequences behavior & to save on tokens, we'll separate concerns: a \"planner\" will be responsible for what endpoints to call and a \"controller\" will be responsible for how to call them."
msgstr ""

#: ../docs/modules/agents/toolkits/examples/openapi.ipynb:20008
msgid "In the initial implementation, the planner is an LLM chain that has the name and a short description for each endpoint in context. The controller is an LLM agent that is instantiated with documentation for only the endpoints for a particular plan. There's a lot left to get this working very robustly :)"
msgstr ""

#: ../docs/modules/agents/toolkits/examples/openapi.ipynb:30002
msgid "To start, let's collect some OpenAPI specs."
msgstr ""

#: ../docs/modules/agents/toolkits/examples/openapi.ipynb:80004
msgid "We'll work with the Spotify API as one of the examples of a somewhat complex API. There's a bit of auth-related setup to do if you want to replicate this."
msgstr ""

#: ../docs/modules/agents/toolkits/examples/openapi.ipynb:80006
msgid "You'll have to set up an application in the Spotify developer console, documented [here](https://developer.spotify.com/documentation/general/guides/authorization/), to get credentials: `CLIENT_ID`, `CLIENT_SECRET`, and `REDIRECT_URI`."
msgstr ""

#: ../docs/modules/agents/toolkits/examples/openapi.ipynb:80007
msgid "To get an access tokens (and keep them fresh), you can implement the oauth flows, or you can use `spotipy`. If you've set your Spotify creedentials as environment variables `SPOTIPY_CLIENT_ID`, `SPOTIPY_CLIENT_SECRET`, and `SPOTIPY_REDIRECT_URI`, you can use the helper functions below:"
msgstr ""

#: ../docs/modules/agents/toolkits/examples/openapi.ipynb:100002
msgid "How big is this spec?"
msgstr ""

#: ../docs/modules/agents/toolkits/examples/openapi.ipynb:130002
msgid "Let's see some examples!"
msgstr ""

#: ../docs/modules/agents/toolkits/examples/openapi.ipynb:130004
msgid "Starting with GPT-4. (Some robustness iterations under way for GPT-3 family.)"
msgstr ""

#: ../docs/modules/agents/toolkits/examples/openapi.ipynb:170002
msgid "Try another API."
msgstr ""

#: ../docs/modules/agents/toolkits/examples/openapi.ipynb:200002
msgid "Takes awhile to get there!"
msgstr ""

#: ../docs/modules/agents/toolkits/examples/openapi.ipynb:210002
msgid "2nd example: \"json explorer\" agent"
msgstr ""

#: ../docs/modules/agents/toolkits/examples/openapi.ipynb:210004
msgid "Here's an agent that's not particularly practical, but neat! The agent has access to 2 toolkits. One comprises tools to interact with json: one tool to list the keys of a json object and another tool to get the value for a given key. The other toolkit comprises `requests` wrappers to send GET and POST requests. This agent consumes a lot calls to the language model, but does a surprisingly decent job."
msgstr ""

#: ../docs/modules/agents/toolkits/examples/openapi_nla.ipynb:10002
msgid "Natural Language APIs"
msgstr ""

#: ../docs/modules/agents/toolkits/examples/openapi_nla.ipynb:10004
msgid "Natural Language API Toolkits (NLAToolkits) permit LangChain Agents to efficiently plan and combine calls across endpoints. This notebook demonstrates a sample composition of the Speak, Klarna, and Spoonacluar APIs."
msgstr ""

#: ../docs/modules/agents/toolkits/examples/openapi_nla.ipynb:10006
msgid "For a detailed walkthrough of the OpenAPI chains wrapped within the NLAToolkit, see the [OpenAPI Operation Chain](openapi.ipynb) notebook."
msgstr ""

#: ../docs/modules/agents/toolkits/examples/openapi_nla.ipynb:10008
msgid "First, import dependencies and load the LLM"
msgstr ""

#: ../docs/modules/agents/toolkits/examples/openapi_nla.ipynb:40002
msgid "Next, load the Natural Language API Toolkits"
msgstr ""

#: ../docs/modules/agents/toolkits/examples/openapi_nla.ipynb:100002
msgid "Using Auth + Adding more Endpoints"
msgstr ""

#: ../docs/modules/agents/toolkits/examples/openapi_nla.ipynb:100004
msgid "Some endpoints may require user authentication via things like access tokens. Here we show how to pass in the authentication information via the `Requests` wrapper object."
msgstr ""

#: ../docs/modules/agents/toolkits/examples/openapi_nla.ipynb:100006
msgid "Since each NLATool exposes a concisee natural language interface to its wrapped API, the top level conversational agent has an easier job incorporating each endpoint to satisfy a user's request."
msgstr ""

#: ../docs/modules/agents/toolkits/examples/openapi_nla.ipynb:110002
msgid "**Adding the Spoonacular endpoints.**"
msgstr ""

#: ../docs/modules/agents/toolkits/examples/openapi_nla.ipynb:110004
msgid "Go to the [Spoonacular API Console](https://spoonacular.com/food-api/console#Profile) and make a free account."
msgstr ""

#: ../docs/modules/agents/toolkits/examples/openapi_nla.ipynb:110005
msgid "Click on `Profile` and copy your API key below."
msgstr ""

#: ../docs/modules/agents/toolkits/examples/openapi_nla.ipynb:180002
msgid "Thank you!"
msgstr ""

#: ../docs/modules/agents/toolkits/examples/pandas.ipynb:10002
msgid "Pandas Dataframe Agent"
msgstr ""

#: ../docs/modules/agents/toolkits/examples/pandas.ipynb:10004
msgid "This notebook shows how to use agents to interact with a pandas dataframe. It is mostly optimized for question answering."
msgstr ""

#: ../docs/modules/agents/toolkits/examples/pandas.ipynb:10006
msgid "**NOTE: this agent calls the Python agent under the hood, which executes LLM generated Python code - this can be bad if the LLM generated Python code is harmful. Use cautiously.**"
msgstr ""

#: ../docs/modules/agents/toolkits/examples/powerbi.ipynb:10002
msgid "PowerBI Dataset Agent"
msgstr ""

#: ../docs/modules/agents/toolkits/examples/powerbi.ipynb:10004
msgid "This notebook showcases an agent designed to interact with a Power BI Dataset. The agent is designed to answer more general questions about a dataset, as well as recover from errors."
msgstr ""

#: ../docs/modules/agents/toolkits/examples/powerbi.ipynb:10006
msgid "Note that, as this agent is in active development, all answers might not be correct. It runs against the [executequery endpoint](https://learn.microsoft.com/en-us/rest/api/power-bi/datasets/execute-queries), which does not allow deletes."
msgstr ""

#: ../docs/modules/agents/toolkits/examples/powerbi.ipynb:10008
msgid "Some notes"
msgstr ""

#: ../docs/modules/agents/toolkits/examples/powerbi.ipynb:10009
msgid "It relies on authentication with the azure.identity package, which can be installed with `pip install azure-identity`. Alternatively you can create the powerbi dataset with a token as a string without supplying the credentials."
msgstr ""

#: ../docs/modules/agents/toolkits/examples/powerbi.ipynb:10010
msgid "You can also supply a username to impersonate for use with datasets that have RLS enabled."
msgstr ""

#: ../docs/modules/agents/toolkits/examples/powerbi.ipynb:10011
msgid "The toolkit uses a LLM to create the query from the question, the agent uses the LLM for the overall execution."
msgstr ""

#: ../docs/modules/agents/toolkits/examples/powerbi.ipynb:10012
msgid "Testing was done mostly with a `text-davinci-003` model, codex models did not seem to perform ver well."
msgstr ""

#: ../docs/modules/agents/toolkits/examples/powerbi.ipynb:50002
#: ../docs/modules/agents/toolkits/examples/sql_database.ipynb:50002
msgid "Example: describing a table"
msgstr ""

#: ../docs/modules/agents/toolkits/examples/powerbi.ipynb:70002
msgid "Example: simple query on a table"
msgstr ""

#: ../docs/modules/agents/toolkits/examples/powerbi.ipynb:70003
msgid "In this example, the agent actually figures out the correct query to get a row count of the table."
msgstr ""

#: ../docs/modules/agents/toolkits/examples/powerbi.ipynb:90002
#: ../docs/modules/agents/toolkits/examples/sql_database.ipynb:90002
msgid "Example: running queries"
msgstr ""

#: ../docs/modules/agents/toolkits/examples/powerbi.ipynb:120002
msgid "Example: add your own few-shot prompts"
msgstr ""

#: ../docs/modules/agents/toolkits/examples/python.ipynb:10002
msgid "Python Agent"
msgstr ""

#: ../docs/modules/agents/toolkits/examples/python.ipynb:10004
msgid "This notebook showcases an agent designed to write and execute python code to answer a question."
msgstr ""

#: ../docs/modules/agents/toolkits/examples/python.ipynb:40002
msgid "Fibonacci Example"
msgstr ""

#: ../docs/modules/agents/toolkits/examples/python.ipynb:40003
msgid "This example was created by [John Wiseman](https://twitter.com/lemonodor/status/1628270074074398720?s=20)."
msgstr ""

#: ../docs/modules/agents/toolkits/examples/python.ipynb:60002
msgid "Training neural net"
msgstr ""

#: ../docs/modules/agents/toolkits/examples/python.ipynb:60003
msgid "This example was created by [Samee Ur Rehman](https://twitter.com/sameeurehman/status/1630130518133207046?s=20)."
msgstr ""

#: ../docs/modules/agents/toolkits/examples/sql_database.ipynb:10002
msgid "SQL Database Agent"
msgstr ""

#: ../docs/modules/agents/toolkits/examples/sql_database.ipynb:10004
msgid "This notebook showcases an agent designed to interact with a sql databases. The agent builds off of [SQLDatabaseChain](https://langchain.readthedocs.io/en/latest/modules/chains/examples/sqlite.html) and is designed to answer more general questions about a database, as well as recover from errors."
msgstr ""

#: ../docs/modules/agents/toolkits/examples/sql_database.ipynb:10006
msgid "Note that, as this agent is in active development, all answers might not be correct. Additionally, it is not guaranteed that the agent won't perform DML statements on your database given certain questions. Be careful running it on sensitive data!"
msgstr ""

#: ../docs/modules/agents/toolkits/examples/sql_database.ipynb:10008
msgid "This uses the example Chinook database. To set it up follow the instructions on https://database.guide/2-sample-databases-sqlite/, placing the .db file in a notebooks folder at the root of this repository."
msgstr ""

#: ../docs/modules/agents/toolkits/examples/sql_database.ipynb:70002
msgid "Example: describing a table, recovering from an error"
msgstr ""

#: ../docs/modules/agents/toolkits/examples/sql_database.ipynb:70004
msgid "In this example, the agent tries to search for a table that doesn't exist, but finds the next best result"
msgstr ""

#: ../docs/modules/agents/toolkits/examples/sql_database.ipynb:120002
msgid "Recovering from an error"
msgstr ""

#: ../docs/modules/agents/toolkits/examples/sql_database.ipynb:120004
msgid "In this example, the agent is able to recover from an error after initially trying to access an attribute (`Track.ArtistId`) which doesn't exist."
msgstr ""

#: ../docs/modules/agents/toolkits/examples/vectorstore.ipynb:10002
msgid "Vectorstore Agent"
msgstr ""

#: ../docs/modules/agents/toolkits/examples/vectorstore.ipynb:10004
msgid "This notebook showcases an agent designed to retrieve information from one or more vectorstores, either with or without sources."
msgstr ""

#: ../docs/modules/agents/toolkits/examples/vectorstore.ipynb:20002
msgid "Create the Vectorstores"
msgstr ""

#: ../docs/modules/agents/toolkits/examples/vectorstore.ipynb:60002
msgid "Initialize Toolkit and Agent"
msgstr ""

#: ../docs/modules/agents/toolkits/examples/vectorstore.ipynb:60004
msgid "First, we'll create an agent with a single vectorstore."
msgstr ""

#: ../docs/modules/agents/toolkits/examples/vectorstore.ipynb:80002
#: ../docs/modules/agents/toolkits/examples/vectorstore.ipynb:140002
#: ../docs/modules/indexes/document_loaders/examples/arxiv.ipynb:70002
#: ../docs/modules/models/llms/integrations/huggingface_hub.ipynb:90002
#: ../docs/modules/prompts/prompt_templates/examples/prompt_serialization.ipynb:160002
msgid "Examples"
msgstr ""

#: ../docs/modules/agents/toolkits/examples/vectorstore.ipynb:110002
msgid "Multiple Vectorstores"
msgstr ""

#: ../docs/modules/agents/toolkits/examples/vectorstore.ipynb:110003
msgid "We can also easily use this initialize an agent with multiple vectorstores and use the agent to route between them. To do this. This agent is optimized for routing, so it is a different toolkit and initializer."
msgstr ""

#: ../docs/modules/agents/tools.rst:2
msgid "Tools"
msgstr ""

#: ../docs/modules/agents/tools.rst:5
msgid "`Conceptual Guide <https://docs.langchain.com/docs/components/agents/tool>`_"
msgstr ""

#: ../docs/modules/agents/tools.rst:9
msgid "Tools are ways that an agent can use to interact with the outside world."
msgstr ""

#: ../docs/modules/agents/tools.rst:11
msgid "For an overview of what a tool is, how to use them, and a full list of examples, please see the getting started documentation"
msgstr ""

#: ../docs/modules/agents/tools.rst:19
msgid "Next, we have some examples of customizing and generically working with tools"
msgstr ""

#: ../docs/modules/agents/tools.rst:30
msgid "In this documentation we cover generic tooling functionality (eg how to create your own) as well as examples of tools and how to use them."
msgstr ""

#: ../docs/modules/agents/tools/custom_tools.ipynb:10002
msgid "Defining Custom Tools"
msgstr ""

#: ../docs/modules/agents/tools/custom_tools.ipynb:10004
msgid "When constructing your own agent, you will need to provide it with a list of Tools that it can use. Besides the actual function that is called, the Tool consists of several components:"
msgstr ""

#: ../docs/modules/agents/tools/custom_tools.ipynb:10006
msgid "name (str), is required and must be unique within a set of tools provided to an agent"
msgstr ""

#: ../docs/modules/agents/tools/custom_tools.ipynb:10007
msgid "description (str), is optional but recommended, as it is used by an agent to determine tool use"
msgstr ""

#: ../docs/modules/agents/tools/custom_tools.ipynb:10008
msgid "return_direct (bool), defaults to False"
msgstr ""

#: ../docs/modules/agents/tools/custom_tools.ipynb:10009
msgid "args_schema (Pydantic BaseModel), is optional but recommended, can be used to provide more information or validation for expected parameters."
msgstr ""

#: ../docs/modules/agents/tools/custom_tools.ipynb:10011
msgid "The function that should be called when the tool is selected should return a single string."
msgstr ""

#: ../docs/modules/agents/tools/custom_tools.ipynb:10013
msgid "There are two ways to define a tool, we will cover both in the example below."
msgstr ""

#: ../docs/modules/agents/tools/custom_tools.ipynb:30002
msgid "Initialize the LLM to use for the agent."
msgstr ""

#: ../docs/modules/agents/tools/custom_tools.ipynb:50002
msgid "Completely New Tools"
msgstr ""

#: ../docs/modules/agents/tools/custom_tools.ipynb:50003
msgid "First, we show how to create completely new tools from scratch."
msgstr ""

#: ../docs/modules/agents/tools/custom_tools.ipynb:50005
msgid "There are two ways to do this: either by using the Tool dataclass, or by subclassing the BaseTool class."
msgstr ""

#: ../docs/modules/agents/tools/custom_tools.ipynb:60002
msgid "Tool dataclass"
msgstr ""

#: ../docs/modules/agents/tools/custom_tools.ipynb:100002
msgid "Subclassing the BaseTool class"
msgstr ""

#: ../docs/modules/agents/tools/custom_tools.ipynb:150002
msgid "Using the `tool` decorator"
msgstr ""

#: ../docs/modules/agents/tools/custom_tools.ipynb:150004
msgid "To make it easier to define custom tools, a `@tool` decorator is provided. This decorator can be used to quickly create a `Tool` from a simple function. The decorator uses the function name as the tool name by default, but this can be overridden by passing a string as the first argument. Additionally, the decorator will use the function's docstring as the tool's description."
msgstr ""

#: ../docs/modules/agents/tools/custom_tools.ipynb:180002
msgid "You can also provide arguments like the tool name and whether to return directly."
msgstr ""

#: ../docs/modules/agents/tools/custom_tools.ipynb:210002
msgid "You can also provide `args_schema` to provide more information about the argument"
msgstr ""

#: ../docs/modules/agents/tools/custom_tools.ipynb:240002
msgid "Modify existing tools"
msgstr ""

#: ../docs/modules/agents/tools/custom_tools.ipynb:240004
msgid "Now, we show how to load existing tools and just modify them. In the example below, we do something really simple and change the Search tool to have the name `Google Search`."
msgstr ""

#: ../docs/modules/agents/tools/custom_tools.ipynb:300002
msgid "Defining the priorities among Tools"
msgstr ""

#: ../docs/modules/agents/tools/custom_tools.ipynb:300003
msgid "When you made a Custom tool, you may want the Agent to use the custom tool more than normal tools."
msgstr ""

#: ../docs/modules/agents/tools/custom_tools.ipynb:300005
msgid "For example, you made a custom tool, which gets information on music from your database. When a user wants information on songs, You want the Agent to use  `the custom tool` more than the normal `Search tool`. But the Agent might prioritize a normal Search tool."
msgstr ""

#: ../docs/modules/agents/tools/custom_tools.ipynb:300007
msgid "This can be accomplished by adding a statement such as `Use this more than the normal search if the question is about Music, like 'who is the singer of yesterday?' or 'what is the most popular song in 2022?'` to the description."
msgstr ""

#: ../docs/modules/agents/tools/custom_tools.ipynb:300009
msgid "An example is below."
msgstr ""

#: ../docs/modules/agents/tools/custom_tools.ipynb:330002
msgid "Using tools to return directly"
msgstr ""

#: ../docs/modules/agents/tools/custom_tools.ipynb:330003
msgid "Often, it can be desirable to have a tool output returned directly to the user, if it‚Äôs called. You can do this easily with LangChain by setting the return_direct flag for a tool to be True."
msgstr ""

#: ../docs/modules/agents/tools/custom_tools.ipynb:370002
msgid "Multi-argument tools"
msgstr ""

#: ../docs/modules/agents/tools/custom_tools.ipynb:370004
msgid "Many functions expect structured inputs. These can also be supported using the Tool decorator or by directly subclassing `BaseTool`! We have to modify the LLM's OutputParser to map its string output to a dictionary to pass to the action, however."
msgstr ""

#: ../docs/modules/agents/tools/examples/apify.ipynb:10002
msgid "Apify"
msgstr ""

#: ../docs/modules/agents/tools/examples/apify.ipynb:10004
msgid "This notebook shows how to use the [Apify integration](../../../../ecosystem/apify.md) for LangChain."
msgstr ""

#: ../docs/modules/agents/tools/examples/apify.ipynb:10006
msgid "[Apify](https://apify.com) is a cloud platform for web scraping and data extraction, which provides an [ecosystem](https://apify.com/store) of more than a thousand ready-made apps called *Actors* for various web scraping, crawling, and data extraction use cases. For example, you can use it to extract Google Search results, Instagram and Facebook profiles, products from Amazon or Shopify, Google Maps reviews, etc. etc."
msgstr ""

#: ../docs/modules/agents/tools/examples/apify.ipynb:10011
msgid "In this example, we'll use the [Website Content Crawler](https://apify.com/apify/website-content-crawler) Actor, which can deeply crawl websites such as documentation, knowledge bases, help centers, or blogs, and extract text content from the web pages. Then we feed the documents into a vector index and answer questions from it."
msgstr ""

#: ../docs/modules/agents/tools/examples/apify.ipynb:20002
msgid "First, import `ApifyWrapper` into your source code:"
msgstr ""

#: ../docs/modules/agents/tools/examples/apify.ipynb:40002
msgid "Initialize it using your [Apify API token](https://console.apify.com/account/integrations) and for the purpose of this example, also with your OpenAI API key:"
msgstr ""

#: ../docs/modules/agents/tools/examples/apify.ipynb:60002
msgid "Then run the Actor, wait for it to finish, and fetch its results from the Apify dataset into a LangChain document loader."
msgstr ""

#: ../docs/modules/agents/tools/examples/apify.ipynb:60004
msgid "Note that if you already have some results in an Apify dataset, you can load them directly using `ApifyDatasetLoader`, as shown in [this notebook](../../../indexes/document_loaders/examples/apify_dataset.ipynb). In that notebook, you'll also find the explanation of the `dataset_mapping_function`, which is used to map fields from the Apify dataset records to LangChain `Document` fields."
msgstr ""

#: ../docs/modules/agents/tools/examples/apify.ipynb:80002
msgid "Initialize the vector index from the crawled documents:"
msgstr ""

#: ../docs/modules/agents/tools/examples/apify.ipynb:100002
msgid "And finally, query the vector index:"
msgstr ""

#: ../docs/modules/agents/tools/examples/arxiv.ipynb:10002
msgid "Arxiv API"
msgstr ""

#: ../docs/modules/agents/tools/examples/arxiv.ipynb:10004
msgid "This notebook goes over how to use the `arxiv` component."
msgstr ""

#: ../docs/modules/agents/tools/examples/arxiv.ipynb:10006
#: ../docs/modules/indexes/document_loaders/examples/arxiv.ipynb:30002
msgid "First, you need to install `arxiv` python package."
msgstr ""

#: ../docs/modules/agents/tools/examples/arxiv.ipynb:40002
msgid "Run a query to get information about some `scientific article`/articles. The query text is limited to 300 characters."
msgstr ""

#: ../docs/modules/agents/tools/examples/arxiv.ipynb:40004
msgid "It returns these article fields:"
msgstr ""

#: ../docs/modules/agents/tools/examples/arxiv.ipynb:40005
msgid "Publishing date"
msgstr ""

#: ../docs/modules/agents/tools/examples/arxiv.ipynb:40006
msgid "Title"
msgstr ""

#: ../docs/modules/agents/tools/examples/arxiv.ipynb:40007
msgid "Authors"
msgstr ""

#: ../docs/modules/agents/tools/examples/arxiv.ipynb:40008
msgid "Summary"
msgstr ""

#: ../docs/modules/agents/tools/examples/arxiv.ipynb:40010
msgid "Next query returns information about one article with arxiv Id equal \"1605.08386\"."
msgstr ""

#: ../docs/modules/agents/tools/examples/arxiv.ipynb:60002
msgid "Now, we want to get information about one author, `Caprice Stanley`."
msgstr ""

#: ../docs/modules/agents/tools/examples/arxiv.ipynb:60004
msgid "This query returns information about three articles. By default, query returns information only about three top articles."
msgstr ""

#: ../docs/modules/agents/tools/examples/arxiv.ipynb:80002
msgid "Now, we are trying to find information about non-existing article. In this case, the response is \"No good Arxiv Result was found\""
msgstr ""

#: ../docs/modules/agents/tools/examples/bash.ipynb:10002
msgid "Bash"
msgstr ""

#: ../docs/modules/agents/tools/examples/bash.ipynb:10003
msgid "It can often be useful to have an LLM generate bash commands, and then run them. A common use case for this is letting the LLM interact with your local file system. We provide an easy util to execute bash commands."
msgstr ""

#: ../docs/modules/agents/tools/examples/bash.ipynb:60002
msgid "Terminal Persistance"
msgstr ""

#: ../docs/modules/agents/tools/examples/bash.ipynb:60004
msgid "By default, the bash command will be executed in a new subprocess each time. To retain a persistent bash session, we can use the `persistent=True` arg."
msgstr ""

#: ../docs/modules/agents/tools/examples/bing_search.ipynb:10002
msgid "Bing Search"
msgstr ""

#: ../docs/modules/agents/tools/examples/bing_search.ipynb:20002
msgid "This notebook goes over how to use the bing search component."
msgstr ""

#: ../docs/modules/agents/tools/examples/bing_search.ipynb:20004
msgid "First, you need to set up the proper API keys and environment variables. To set it up, follow the instructions found [here](https://levelup.gitconnected.com/api-tutorial-how-to-use-bing-web-search-api-in-python-4165d5592a7e)."
msgstr ""

#: ../docs/modules/agents/tools/examples/bing_search.ipynb:20006
#: ../docs/modules/agents/tools/examples/google_search.ipynb:10008
msgid "Then we will need to set some environment variables."
msgstr ""

#: ../docs/modules/agents/tools/examples/bing_search.ipynb:70002
msgid "Number of results"
msgstr ""

#: ../docs/modules/agents/tools/examples/bing_search.ipynb:70003
#: ../docs/modules/agents/tools/examples/google_search.ipynb:60003
msgid "You can use the `k` parameter to set the number of results"
msgstr ""

#: ../docs/modules/agents/tools/examples/bing_search.ipynb:100002
#: ../docs/modules/agents/tools/examples/google_search.ipynb:100002
msgid "Metadata Results"
msgstr ""

#: ../docs/modules/agents/tools/examples/bing_search.ipynb:110002
msgid "Run query through BingSearch and return snippet, title, and link metadata."
msgstr ""

#: ../docs/modules/agents/tools/examples/bing_search.ipynb:110004
#: ../docs/modules/agents/tools/examples/google_search.ipynb:110004
msgid "Snippet: The description of the result."
msgstr ""

#: ../docs/modules/agents/tools/examples/bing_search.ipynb:110005
#: ../docs/modules/agents/tools/examples/google_search.ipynb:110005
msgid "Title: The title of the result."
msgstr ""

#: ../docs/modules/agents/tools/examples/bing_search.ipynb:110006
#: ../docs/modules/agents/tools/examples/google_search.ipynb:110006
msgid "Link: The link to the result."
msgstr ""

#: ../docs/modules/agents/tools/examples/chatgpt_plugins.ipynb:10002
msgid "ChatGPT Plugins"
msgstr ""

#: ../docs/modules/agents/tools/examples/chatgpt_plugins.ipynb:10004
msgid "This example shows how to use ChatGPT Plugins within LangChain abstractions."
msgstr ""

#: ../docs/modules/agents/tools/examples/chatgpt_plugins.ipynb:10006
msgid "Note 1: This currently only works for plugins with no auth."
msgstr ""

#: ../docs/modules/agents/tools/examples/chatgpt_plugins.ipynb:10008
msgid "Note 2: There are almost certainly other ways to do this, this is just a first pass. If you have better ideas, please open a PR!"
msgstr ""

#: ../docs/modules/agents/tools/examples/ddg.ipynb:10002
msgid "DuckDuckGo Search"
msgstr ""

#: ../docs/modules/agents/tools/examples/ddg.ipynb:10004
msgid "This notebook goes over how to use the duck-duck-go search component."
msgstr ""

#: ../docs/modules/agents/tools/examples/google_places.ipynb:10002
msgid "Google Places"
msgstr ""

#: ../docs/modules/agents/tools/examples/google_places.ipynb:10004
msgid "This notebook goes through how to use Google Places API"
msgstr ""

#: ../docs/modules/agents/tools/examples/google_search.ipynb:10002
msgid "Google Search"
msgstr ""

#: ../docs/modules/agents/tools/examples/google_search.ipynb:10004
msgid "This notebook goes over how to use the google search component."
msgstr ""

#: ../docs/modules/agents/tools/examples/google_search.ipynb:10006
msgid "First, you need to set up the proper API keys and environment variables. To set it up, create the GOOGLE_API_KEY in the Google Cloud credential console (https://console.cloud.google.com/apis/credentials) and a GOOGLE_CSE_ID using the Programmable Search Enginge (https://programmablesearchengine.google.com/controlpanel/create). Next, it is good to follow the instructions found [here](https://stackoverflow.com/questions/37083058/programmatically-searching-google-in-python-using-custom-search)."
msgstr ""

#: ../docs/modules/agents/tools/examples/google_search.ipynb:60002
msgid "Number of Results"
msgstr ""

#: ../docs/modules/agents/tools/examples/google_search.ipynb:90002
msgid "'The official home of the Python Programming Language.'"
msgstr ""

#: ../docs/modules/agents/tools/examples/google_search.ipynb:110002
msgid "Run query through GoogleSearch and return snippet, title, and link metadata."
msgstr ""

#: ../docs/modules/agents/tools/examples/google_serper.ipynb:10002
msgid "Google Serper API"
msgstr ""

#: ../docs/modules/agents/tools/examples/google_serper.ipynb:10004
msgid "This notebook goes over how to use the Google Serper component to search the web. First you need to sign up for a free account at [serper.dev](https://serper.dev) and get your api key."
msgstr ""

#: ../docs/modules/agents/tools/examples/google_serper.ipynb:60002
msgid "As part of a Self Ask With Search Chain"
msgstr ""

#: ../docs/modules/agents/tools/examples/gradio_tools.ipynb:10002
msgid "Gradio Tools"
msgstr ""

#: ../docs/modules/agents/tools/examples/gradio_tools.ipynb:10004
msgid "There are many 1000s of Gradio apps on Hugging Face Spaces. This library puts them at the tips of your LLM's fingers ü¶æ"
msgstr ""

#: ../docs/modules/agents/tools/examples/gradio_tools.ipynb:10006
msgid "Specifically, gradio-tools is a Python library for converting Gradio apps into tools that can be leveraged by a large language model (LLM)-based agent to complete its task. For example, an LLM could use a Gradio tool to transcribe a voice recording it finds online and then summarize it for you. Or it could use a different Gradio tool to apply OCR to a document on your Google Drive and then answer questions about it."
msgstr ""

#: ../docs/modules/agents/tools/examples/gradio_tools.ipynb:10008
msgid "It's very easy to create you own tool if you want to use a space that's not one of the pre-built tools. Please see this section of the gradio-tools documentation for information on how to do that. All contributions are welcome!"
msgstr ""

#: ../docs/modules/agents/tools/examples/gradio_tools.ipynb:30002
msgid "Using a tool"
msgstr ""

#: ../docs/modules/agents/tools/examples/gradio_tools.ipynb:90002
msgid "Using within an agent"
msgstr ""

#: ../docs/modules/agents/tools/examples/human_tools.ipynb:10002
msgid "Human as a tool"
msgstr ""

#: ../docs/modules/agents/tools/examples/human_tools.ipynb:10004
msgid "Human are AGI so they can certainly be used as a tool to help out AI agent  when it is confused."
msgstr ""

#: ../docs/modules/agents/tools/examples/human_tools.ipynb:30002
msgid "In the above code you can see the tool takes input directly from command line. You can customize `prompt_func` and `input_func` according to your need."
msgstr ""

#: ../docs/modules/agents/tools/examples/ifttt.ipynb:10002
msgid "IFTTT WebHooks"
msgstr ""

#: ../docs/modules/agents/tools/examples/ifttt.ipynb:10004
msgid "This notebook shows how to use IFTTT Webhooks."
msgstr ""

#: ../docs/modules/agents/tools/examples/ifttt.ipynb:10006
msgid "From https://github.com/SidU/teams-langchain-js/wiki/Connecting-IFTTT-Services."
msgstr ""

#: ../docs/modules/agents/tools/examples/ifttt.ipynb:10008
msgid "Creating a webhook"
msgstr ""

#: ../docs/modules/agents/tools/examples/ifttt.ipynb:10009
msgid "Go to https://ifttt.com/create"
msgstr ""

#: ../docs/modules/agents/tools/examples/ifttt.ipynb:10011
msgid "Configuring the \"If This\""
msgstr ""

#: ../docs/modules/agents/tools/examples/ifttt.ipynb:10012
msgid "Click on the \"If This\" button in the IFTTT interface."
msgstr ""

#: ../docs/modules/agents/tools/examples/ifttt.ipynb:10013
msgid "Search for \"Webhooks\" in the search bar."
msgstr ""

#: ../docs/modules/agents/tools/examples/ifttt.ipynb:10014
msgid "Choose the first option for \"Receive a web request with a JSON payload.\""
msgstr ""

#: ../docs/modules/agents/tools/examples/ifttt.ipynb:10015
msgid "Choose an Event Name that is specific to the service you plan to connect to. This will make it easier for you to manage the webhook URL. For example, if you're connecting to Spotify, you could use \"Spotify\" as your Event Name."
msgstr ""

#: ../docs/modules/agents/tools/examples/ifttt.ipynb:10019
msgid "Click the \"Create Trigger\" button to save your settings and create your webhook."
msgstr ""

#: ../docs/modules/agents/tools/examples/ifttt.ipynb:10021
msgid "Configuring the \"Then That\""
msgstr ""

#: ../docs/modules/agents/tools/examples/ifttt.ipynb:10022
msgid "Tap on the \"Then That\" button in the IFTTT interface."
msgstr ""

#: ../docs/modules/agents/tools/examples/ifttt.ipynb:10023
msgid "Search for the service you want to connect, such as Spotify."
msgstr ""

#: ../docs/modules/agents/tools/examples/ifttt.ipynb:10024
msgid "Choose an action from the service, such as \"Add track to a playlist\"."
msgstr ""

#: ../docs/modules/agents/tools/examples/ifttt.ipynb:10025
msgid "Configure the action by specifying the necessary details, such as the playlist name, e.g., \"Songs from AI\"."
msgstr ""

#: ../docs/modules/agents/tools/examples/ifttt.ipynb:10027
msgid "Reference the JSON Payload received by the Webhook in your action. For the Spotify scenario, choose \"{{JsonPayload}}\" as your search query."
msgstr ""

#: ../docs/modules/agents/tools/examples/ifttt.ipynb:10029
msgid "Tap the \"Create Action\" button to save your action settings."
msgstr ""

#: ../docs/modules/agents/tools/examples/ifttt.ipynb:10030
msgid "Once you have finished configuring your action, click the \"Finish\" button to complete the setup."
msgstr ""

#: ../docs/modules/agents/tools/examples/ifttt.ipynb:10032
msgid "Congratulations! You have successfully connected the Webhook to the desired service, and you're ready to start receiving data and triggering actions üéâ"
msgstr ""

#: ../docs/modules/agents/tools/examples/ifttt.ipynb:10035
msgid "Finishing up"
msgstr ""

#: ../docs/modules/agents/tools/examples/ifttt.ipynb:10036
msgid "To get your webhook URL go to https://ifttt.com/maker_webhooks/settings"
msgstr ""

#: ../docs/modules/agents/tools/examples/ifttt.ipynb:10037
msgid "Copy the IFTTT key value from there. The URL is of the form https://maker.ifttt.com/use/YOUR_IFTTT_KEY. Grab the YOUR_IFTTT_KEY value."
msgstr ""

#: ../docs/modules/agents/tools/examples/openweathermap.ipynb:10002
msgid "OpenWeatherMap API"
msgstr ""

#: ../docs/modules/agents/tools/examples/openweathermap.ipynb:10004
msgid "This notebook goes over how to use the OpenWeatherMap component to fetch weather information."
msgstr ""

#: ../docs/modules/agents/tools/examples/openweathermap.ipynb:10006
msgid "First, you need to sign up for an OpenWeatherMap API key:"
msgstr ""

#: ../docs/modules/agents/tools/examples/openweathermap.ipynb:10008
msgid "Go to OpenWeatherMap and sign up for an API key [here](https://openweathermap.org/api/)"
msgstr ""

#: ../docs/modules/agents/tools/examples/openweathermap.ipynb:10009
msgid "pip install pyowm"
msgstr ""

#: ../docs/modules/agents/tools/examples/openweathermap.ipynb:10011
#: ../docs/modules/agents/tools/examples/wolfram_alpha.ipynb:10012
msgid "Then we will need to set some environment variables:"
msgstr ""

#: ../docs/modules/agents/tools/examples/openweathermap.ipynb:10012
msgid "Save your API KEY into OPENWEATHERMAP_API_KEY env variable"
msgstr ""

#: ../docs/modules/agents/tools/examples/python.ipynb:10002
msgid "Python REPL"
msgstr ""

#: ../docs/modules/agents/tools/examples/python.ipynb:10004
msgid "Sometimes, for complex calculations, rather than have an LLM generate the answer directly, it can be better to have the LLM generate code to calculate the answer, and then run that code to get the answer. In order to easily do that, we provide a simple Python REPL to execute commands in."
msgstr ""

#: ../docs/modules/agents/tools/examples/python.ipynb:10006
msgid "This interface will only return things that are printed - therefor, if you want to use it to calculate an answer, make sure to have it print out the answer."
msgstr ""

#: ../docs/modules/agents/tools/examples/requests.ipynb:10002
msgid "Requests"
msgstr ""

#: ../docs/modules/agents/tools/examples/requests.ipynb:10004
msgid "The web contains a lot of information that LLMs do not have access to. In order to easily let LLMs interact with that information, we provide a wrapper around the Python Requests module that takes in a URL and fetches data from that URL."
msgstr ""

#: ../docs/modules/agents/tools/examples/search_tools.ipynb:10002
msgid "Search Tools"
msgstr ""

#: ../docs/modules/agents/tools/examples/search_tools.ipynb:10004
msgid "This notebook shows off usage of various search tools."
msgstr ""

#: ../docs/modules/agents/tools/examples/search_tools.ipynb:40002
msgid "Google Serper API Wrapper"
msgstr ""

#: ../docs/modules/agents/tools/examples/search_tools.ipynb:40004
msgid "First, let's try to use the Google Serper API tool."
msgstr ""

#: ../docs/modules/agents/tools/examples/search_tools.ipynb:80002
#: ../docs/modules/agents/tools/examples/serpapi.ipynb:10002
msgid "SerpAPI"
msgstr ""

#: ../docs/modules/agents/tools/examples/search_tools.ipynb:80004
msgid "Now, let's use the SerpAPI tool."
msgstr ""

#: ../docs/modules/agents/tools/examples/search_tools.ipynb:120002
msgid "GoogleSearchAPIWrapper"
msgstr ""

#: ../docs/modules/agents/tools/examples/search_tools.ipynb:120004
msgid "Now, let's use the official Google Search API Wrapper."
msgstr ""

#: ../docs/modules/agents/tools/examples/search_tools.ipynb:160002
msgid "SearxNG Meta Search Engine"
msgstr ""

#: ../docs/modules/agents/tools/examples/search_tools.ipynb:160004
msgid "Here we will be using a self hosted SearxNG meta search engine."
msgstr ""

#: ../docs/modules/agents/tools/examples/searx_search.ipynb:10002
msgid "SearxNG Search API"
msgstr ""

#: ../docs/modules/agents/tools/examples/searx_search.ipynb:10004
msgid "This notebook goes over how to use a self hosted SearxNG search API to search the web."
msgstr ""

#: ../docs/modules/agents/tools/examples/searx_search.ipynb:10006
msgid "You can [check this link](https://docs.searxng.org/dev/search_api.html) for more informations about Searx API parameters."
msgstr ""

#: ../docs/modules/agents/tools/examples/searx_search.ipynb:40002
msgid "For some engines, if a direct `answer` is available the warpper will print the answer instead of the full list of search results. You can use the `results` method of the wrapper if you want to obtain all the results."
msgstr ""

#: ../docs/modules/agents/tools/examples/searx_search.ipynb:60002
#: ../docs/modules/agents/tools/examples/serpapi.ipynb:50002
msgid "Custom Parameters"
msgstr ""

#: ../docs/modules/agents/tools/examples/searx_search.ipynb:60004
msgid "SearxNG supports up to [139 search engines](https://docs.searxng.org/admin/engines/configured_engines.html#configured-engines). You can also customize the Searx wrapper with arbitrary named parameters that will be passed to the Searx search API . In the below example we will making a more interesting use of custom search parameters from searx search api."
msgstr ""

#: ../docs/modules/agents/tools/examples/searx_search.ipynb:70002
msgid "In this example we will be using the `engines` parameters to query wikipedia"
msgstr ""

#: ../docs/modules/agents/tools/examples/searx_search.ipynb:100002
msgid "Passing other Searx parameters for searx like `language`"
msgstr ""

#: ../docs/modules/agents/tools/examples/searx_search.ipynb:120002
msgid "Obtaining results with metadata"
msgstr ""

#: ../docs/modules/agents/tools/examples/searx_search.ipynb:130002
msgid "In this example we will be looking for scientific paper using the `categories` parameter and limiting the results to a `time_range` (not all engines support the time range option)."
msgstr ""

#: ../docs/modules/agents/tools/examples/searx_search.ipynb:130004
msgid "We also would like to obtain the results in a structured way including metadata. For this we will be using the `results` method of the wrapper."
msgstr ""

#: ../docs/modules/agents/tools/examples/searx_search.ipynb:160002
msgid "Get papers from arxiv"
msgstr ""

#: ../docs/modules/agents/tools/examples/searx_search.ipynb:180002
msgid "In this example we query for `large language models` under the `it` category. We then filter the results that come from github."
msgstr ""

#: ../docs/modules/agents/tools/examples/searx_search.ipynb:200002
msgid "We could also directly query for results from `github` and other source forges."
msgstr ""

#: ../docs/modules/agents/tools/examples/serpapi.ipynb:10004
msgid "This notebook goes over how to use the SerpAPI component to search the web."
msgstr ""

#: ../docs/modules/agents/tools/examples/serpapi.ipynb:50003
msgid "You can also customize the SerpAPI wrapper with arbitrary parameters. For example, in the below example we will use `bing` instead of `google`."
msgstr ""

#: ../docs/modules/agents/tools/examples/wikipedia.ipynb:10002
msgid "Wikipedia API"
msgstr ""

#: ../docs/modules/agents/tools/examples/wikipedia.ipynb:10004
msgid "This notebook goes over how to use the wikipedia component."
msgstr ""

#: ../docs/modules/agents/tools/examples/wikipedia.ipynb:10006
msgid "First, you need to install `wikipedia` python package."
msgstr ""

#: ../docs/modules/agents/tools/examples/wolfram_alpha.ipynb:10002
msgid "Wolfram Alpha"
msgstr ""

#: ../docs/modules/agents/tools/examples/wolfram_alpha.ipynb:10004
msgid "This notebook goes over how to use the wolfram alpha component."
msgstr ""

#: ../docs/modules/agents/tools/examples/wolfram_alpha.ipynb:10006
msgid "First, you need to set up your Wolfram Alpha developer account and get your APP ID:"
msgstr ""

#: ../docs/modules/agents/tools/examples/wolfram_alpha.ipynb:10008
msgid "Go to wolfram alpha and sign up for a developer account [here](https://developer.wolframalpha.com/)"
msgstr ""

#: ../docs/modules/agents/tools/examples/wolfram_alpha.ipynb:10009
msgid "Create an app and get your APP ID"
msgstr ""

#: ../docs/modules/agents/tools/examples/wolfram_alpha.ipynb:10010
msgid "pip install wolframalpha"
msgstr ""

#: ../docs/modules/agents/tools/examples/wolfram_alpha.ipynb:10013
msgid "Save your APP ID into WOLFRAM_ALPHA_APPID env variable"
msgstr ""

#: ../docs/modules/agents/tools/examples/zapier.ipynb:10002
msgid "Zapier Natural Language Actions API"
msgstr ""

#: ../docs/modules/agents/tools/examples/zapier.ipynb:10003
msgid "\\ Full docs here: https://nla.zapier.com/api/v1/docs"
msgstr ""

#: ../docs/modules/agents/tools/examples/zapier.ipynb:10006
msgid "**Zapier Natural Language Actions** gives you access to the 5k+ apps, 20k+ actions on Zapier's platform through a natural language API interface."
msgstr ""

#: ../docs/modules/agents/tools/examples/zapier.ipynb:10008
msgid "NLA supports apps like Gmail, Salesforce, Trello, Slack, Asana, HubSpot, Google Sheets, Microsoft Teams, and thousands more apps: https://zapier.com/apps"
msgstr ""

#: ../docs/modules/agents/tools/examples/zapier.ipynb:10010
msgid "Zapier NLA handles ALL the underlying API auth and translation from natural language --> underlying API call --> return simplified output for LLMs. The key idea is you, or your users, expose a set of actions via an oauth-like setup window, which you can then query and execute via a REST API."
msgstr ""

#: ../docs/modules/agents/tools/examples/zapier.ipynb:10012
msgid "NLA offers both API Key and OAuth for signing NLA API requests."
msgstr ""

#: ../docs/modules/agents/tools/examples/zapier.ipynb:10014
msgid "Server-side (API Key): for quickly getting started, testing, and production scenarios where LangChain will only use actions exposed in the developer's Zapier account (and will use the developer's connected accounts on Zapier.com)"
msgstr ""

#: ../docs/modules/agents/tools/examples/zapier.ipynb:10016
msgid "User-facing (Oauth): for production scenarios where you are deploying an end-user facing application and LangChain needs access to end-user's exposed actions and connected accounts on Zapier.com"
msgstr ""

#: ../docs/modules/agents/tools/examples/zapier.ipynb:10018
msgid "This quick start will focus on the server-side use case for brevity. Review [full docs](https://nla.zapier.com/api/v1/docs) or reach out to nla@zapier.com for user-facing oauth developer support."
msgstr ""

#: ../docs/modules/agents/tools/examples/zapier.ipynb:10020
msgid "This example goes over how to use the Zapier integration with a `SimpleSequentialChain`, then an `Agent`. In code, below:"
msgstr ""

#: ../docs/modules/agents/tools/examples/zapier.ipynb:40002
msgid "Example with Agent"
msgstr ""

#: ../docs/modules/agents/tools/examples/zapier.ipynb:40003
msgid "Zapier tools can be used with an agent. See the example below."
msgstr ""

#: ../docs/modules/agents/tools/examples/zapier.ipynb:90002
msgid "Example with SimpleSequentialChain"
msgstr ""

#: ../docs/modules/agents/tools/examples/zapier.ipynb:90003
msgid "If you need more explicit control, use a chain, like below."
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:3
msgid "Tools are functions that agents can use to interact with the world. These tools can be generic utilities (e.g. search), other chains, or even other agents."
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:6
msgid "Currently, tools can be loaded with the following snippet:"
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:14
msgid "Some tools (e.g. chains, agents) may require a base LLM to use to initialize them. In that case, you can pass in an LLM as well:"
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:24
msgid "Below is a list of all supported tools and relevant information:"
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:26
msgid "Tool Name: The name the LLM refers to the tool by."
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:27
msgid "Tool Description: The description of the tool that is passed to the LLM."
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:28
msgid "Notes: Notes about the tool that are NOT passed to the LLM."
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:29
msgid "Requires LLM: Whether this tool requires an LLM to be initialized."
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:30
msgid "(Optional) Extra Parameters: What extra parameters are required to initialize this tool."
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:32
msgid "List of Tools"
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:34
msgid "**python_repl**"
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:36
msgid "Tool Name: Python REPL"
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:37
msgid "Tool Description: A Python shell. Use this to execute python commands. Input should be a valid python command. If you expect output it should be printed out."
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:38
msgid "Notes: Maintains state."
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:39
#: ../docs/modules/agents/tools/getting_started.md:46
#: ../docs/modules/agents/tools/getting_started.md:53
#: ../docs/modules/agents/tools/getting_started.md:61
#: ../docs/modules/agents/tools/getting_started.md:68
#: ../docs/modules/agents/tools/getting_started.md:119
#: ../docs/modules/agents/tools/getting_started.md:128
#: ../docs/modules/agents/tools/getting_started.md:136
#: ../docs/modules/agents/tools/getting_started.md:145
#: ../docs/modules/agents/tools/getting_started.md:161
msgid "Requires LLM: No"
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:41
msgid "**serpapi**"
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:43
#: ../docs/modules/agents/tools/getting_started.md:116
#: ../docs/modules/agents/tools/getting_started.md:125
#: ../docs/modules/agents/tools/getting_started.md:133
msgid "Tool Name: Search"
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:44
msgid "Tool Description: A search engine. Useful for when you need to answer questions about current events. Input should be a search query."
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:45
msgid "Notes: Calls the Serp API and then parses results."
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:48
msgid "**wolfram-alpha**"
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:50
msgid "Tool Name: Wolfram Alpha"
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:51
msgid "Tool Description: A wolfram alpha search engine. Useful for when you need to answer questions about Math, Science, Technology, Culture, Society and Everyday Life. Input should be a search query."
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:52
msgid "Notes: Calls the Wolfram Alpha API and then parses results."
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:54
msgid "Extra Parameters: `wolfram_alpha_appid`: The Wolfram Alpha app id."
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:56
msgid "**requests**"
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:58
msgid "Tool Name: Requests"
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:59
msgid "Tool Description: A portal to the internet. Use this when you need to get specific content from a site. Input should be a specific url, and the output will be all the text on that page."
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:60
msgid "Notes: Uses the Python requests module."
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:63
msgid "**terminal**"
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:65
msgid "Tool Name: Terminal"
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:66
msgid "Tool Description: Executes commands in a terminal. Input should be valid commands, and the output will be any output from running that command."
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:67
msgid "Notes: Executes commands with subprocess."
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:70
msgid "**pal-math**"
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:72
msgid "Tool Name: PAL-MATH"
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:73
msgid "Tool Description: A language model that is excellent at solving complex word math problems. Input should be a fully worded hard word math problem."
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:74
#: ../docs/modules/agents/tools/getting_started.md:81
msgid "Notes: Based on [this paper](https://arxiv.org/pdf/2211.10435.pdf)."
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:75
#: ../docs/modules/agents/tools/getting_started.md:82
#: ../docs/modules/agents/tools/getting_started.md:89
#: ../docs/modules/agents/tools/getting_started.md:96
#: ../docs/modules/agents/tools/getting_started.md:103
#: ../docs/modules/agents/tools/getting_started.md:111
#: ../docs/modules/agents/tools/getting_started.md:153
msgid "Requires LLM: Yes"
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:77
msgid "**pal-colored-objects**"
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:79
msgid "Tool Name: PAL-COLOR-OBJ"
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:80
msgid "Tool Description: A language model that is wonderful at reasoning about position and the color attributes of objects. Input should be a fully worded hard reasoning problem. Make sure to include all information about the objects AND the final question you want to answer."
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:84
msgid "**llm-math**"
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:86
msgid "Tool Name: Calculator"
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:87
msgid "Tool Description: Useful for when you need to answer questions about math."
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:88
msgid "Notes: An instance of the `LLMMath` chain."
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:91
msgid "**open-meteo-api**"
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:93
msgid "Tool Name: Open Meteo API"
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:94
msgid "Tool Description: Useful for when you want to get weather information from the OpenMeteo API. The input should be a question in natural language that this API can answer."
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:95
msgid "Notes: A natural language connection to the Open Meteo API (`https://api.open-meteo.com/`), specifically the `/v1/forecast` endpoint."
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:98
msgid "**news-api**"
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:100
msgid "Tool Name: News API"
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:101
msgid "Tool Description: Use this when you want to get information about the top headlines of current news stories. The input should be a question in natural language that this API can answer."
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:102
msgid "Notes: A natural language connection to the News API (`https://newsapi.org`), specifically the `/v2/top-headlines` endpoint."
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:104
msgid "Extra Parameters: `news_api_key` (your API key to access this endpoint)"
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:106
msgid "**tmdb-api**"
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:108
msgid "Tool Name: TMDB API"
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:109
msgid "Tool Description: Useful for when you want to get information from The Movie Database. The input should be a question in natural language that this API can answer."
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:110
msgid "Notes: A natural language connection to the TMDB API (`https://api.themoviedb.org/3`), specifically the `/search/movie` endpoint."
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:112
msgid "Extra Parameters: `tmdb_bearer_token` (your Bearer Token to access this endpoint - note that this is different from the API key)"
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:114
msgid "**google-search**"
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:117
msgid "Tool Description: A wrapper around Google Search. Useful for when you need to answer questions about current events. Input should be a search query."
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:118
msgid "Notes: Uses the Google Custom Search API"
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:120
msgid "Extra Parameters: `google_api_key`, `google_cse_id`"
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:121
msgid "For more information on this, see [this page](../../../ecosystem/google_search.md)"
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:123
msgid "**searx-search**"
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:126
msgid "Tool Description: A wrapper around SearxNG meta search engine. Input should be a search query."
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:127
msgid "Notes: SearxNG is easy to deploy self-hosted. It is a good privacy friendly alternative to Google Search. Uses the SearxNG API."
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:129
msgid "Extra Parameters: `searx_host`"
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:131
msgid "**google-serper**"
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:134
msgid "Tool Description: A low-cost Google Search API. Useful for when you need to answer questions about current events. Input should be a search query."
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:135
msgid "Notes: Calls the [serper.dev](https://serper.dev) Google Search API and then parses results."
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:137
msgid "Extra Parameters: `serper_api_key`"
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:138
msgid "For more information on this, see [this page](../../../ecosystem/google_serper.md)"
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:140
msgid "**wikipedia**"
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:142
msgid "Tool Name: Wikipedia"
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:143
msgid "Tool Description: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, historical events, or other subjects. Input should be a search query."
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:144
msgid "Notes: Uses the [wikipedia](https://pypi.org/project/wikipedia/) Python package to call the MediaWiki API and then parses results."
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:146
msgid "Extra Parameters: `top_k_results`"
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:148
msgid "**podcast-api**"
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:150
msgid "Tool Name: Podcast API"
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:151
msgid "Tool Description: Use the Listen Notes Podcast API to search all podcasts or episodes. The input should be a question in natural language that this API can answer."
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:152
msgid "Notes: A natural language connection to the Listen Notes Podcast API (`https://www.PodcastAPI.com`), specifically the `/search/` endpoint."
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:154
msgid "Extra Parameters: `listen_api_key` (your api key to access this endpoint)"
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:156
msgid "**openweathermap-api**"
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:158
msgid "Tool Name: OpenWeatherMap"
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:159
msgid "Tool Description: A wrapper around OpenWeatherMap API. Useful for fetching current weather information for a specified location. Input should be a location string (e.g. 'London,GB')."
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:160
msgid "Notes: A connection to the OpenWeatherMap API (https://api.openweathermap.org), specifically the `/data/2.5/weather` endpoint."
msgstr ""

#: ../docs/modules/agents/tools/getting_started.md:162
msgid "Extra Parameters: `openweathermap_api_key` (your API key to access this endpoint)"
msgstr ""

#: ../docs/modules/agents/tools/multi_input_tool.ipynb:10002
msgid "Multi-Input Tools"
msgstr ""

#: ../docs/modules/agents/tools/multi_input_tool.ipynb:10004
msgid "This notebook shows how to use a tool that requires multiple inputs with an agent."
msgstr ""

#: ../docs/modules/agents/tools/multi_input_tool.ipynb:10006
msgid "The difficulty in doing so comes from the fact that an agent decides its next step from a language model, which outputs a string. So if that step requires multiple inputs, they need to be parsed from that. Therefore, the currently supported way to do this is to write a smaller wrapper function that parses a string into multiple inputs."
msgstr ""

#: ../docs/modules/agents/tools/multi_input_tool.ipynb:10008
msgid "For a concrete example, let's work on giving an agent access to a multiplication function, which takes as input two integers. In order to use this, we will tell the agent to generate the \"Action Input\" as a comma-separated list of length two. We will then write a thin wrapper that takes a string, splits it into two around a comma, and passes both parsed sides as integers to the multiplication function."
msgstr ""

#: ../docs/modules/agents/tools/multi_input_tool.ipynb:30002
msgid "Here is the multiplication function, as well as a wrapper to parse a string as input."
msgstr ""

#: ../docs/modules/agents/tools/tool_input_validation.ipynb:10002
msgid "Tool Input Schema"
msgstr ""

#: ../docs/modules/agents/tools/tool_input_validation.ipynb:10004
msgid "By default, tools infer the argument schema by inspecting the function signature. For more strict requirements, custom input schema can be specified, along with custom validation logic."
msgstr ""

#: ../docs/modules/callbacks/getting_started.ipynb:10002
msgid "Callbacks"
msgstr ""

#: ../docs/modules/callbacks/getting_started.ipynb:20002
msgid "LangChain provides a callback system that allows you to hook into the various stages of your LLM application. This is useful for logging, [monitoring](https://python.langchain.com/en/latest/tracing.html), [streaming](https://python.langchain.com/en/latest/modules/models/llms/examples/streaming_llm.html), and other tasks."
msgstr ""

#: ../docs/modules/callbacks/getting_started.ipynb:20004
msgid "You can subscribe to these events by using the `callback_manager` argument available throughout the API. A `CallbackManager` is an object that manages a list of `CallbackHandlers`. The `CallbackManager` will call the appropriate method on each handler when the event is triggered."
msgstr ""

#: ../docs/modules/callbacks/getting_started.ipynb:40002
msgid "`CallbackHandlers` are objects that implement the `CallbackHandler` interface, which has a method for each event that can be subscribed to. The `CallbackManager` will call the appropriate method on each handler when the event is triggered."
msgstr ""

#: ../docs/modules/callbacks/getting_started.ipynb:60002
msgid "Creating and Using a Custom `CallbackHandler`"
msgstr ""

#: ../docs/modules/callbacks/getting_started.ipynb:60004
msgid "By default, a shared CallbackManager with the StdOutCallbackHandler will be used by models, chains, agents, and tools. However, you can pass in your own CallbackManager with a custom CallbackHandler:"
msgstr ""

#: ../docs/modules/callbacks/getting_started.ipynb:80002
msgid "Async Support"
msgstr ""

#: ../docs/modules/callbacks/getting_started.ipynb:80004
msgid "If you are planning to use the async API, it is recommended to use `AsyncCallbackHandler` and `AsyncCallbackManager` to avoid blocking the runloop."
msgstr ""

#: ../docs/modules/chains.rst:22
#: ../docs/modules/models/llms.rst:23
#: ../docs/modules/prompts/prompt_templates.rst:22
msgid "Reference"
msgstr ""

#: ../docs/modules/chains.rst:22
#: ../docs/modules/chains.rst:2
msgid "Chains"
msgstr ""

#: ../docs/modules/chains.rst:5
msgid "`Conceptual Guide <https://docs.langchain.com/docs/components/chains>`_"
msgstr ""

#: ../docs/modules/chains.rst:8
msgid "Using an LLM in isolation is fine for some simple applications, but many more complex ones require chaining LLMs - either with each other or with other experts. LangChain provides a standard interface for Chains, as well as some common implementations of chains for ease of use."
msgstr ""

#: ../docs/modules/chains.rst:12
#: ../docs/modules/memory.rst:19
#: ../docs/modules/models/chat.rst:14
#: ../docs/modules/models/llms.rst:12
#: ../docs/modules/prompts/prompt_templates.rst:12
msgid "The following sections of documentation are provided:"
msgstr ""

#: ../docs/modules/chains.rst:14
msgid "`Getting Started <./chains/getting_started.html>`_: A getting started guide for chains, to get you up and running quickly."
msgstr ""

#: ../docs/modules/chains.rst:16
msgid "`How-To Guides <./chains/how_to_guides.html>`_: A collection of how-to guides. These highlight how to use various types of chains."
msgstr ""

#: ../docs/modules/chains.rst:18
msgid "`Reference <../reference/modules/chains.html>`_: API reference documentation for all Chain classes."
msgstr ""

#: ../docs/modules/chains/examples/api.ipynb:10002
msgid "API Chains"
msgstr ""

#: ../docs/modules/chains/examples/api.ipynb:10003
msgid "This notebook showcases using LLMs to interact with APIs to retrieve relevant information."
msgstr ""

#: ../docs/modules/chains/examples/api.ipynb:40002
msgid "OpenMeteo Example"
msgstr ""

#: ../docs/modules/chains/examples/api.ipynb:70002
msgid "TMDB Example"
msgstr ""

#: ../docs/modules/chains/examples/api.ipynb:110002
msgid "Listen API Example"
msgstr ""

#: ../docs/modules/chains/examples/constitutional_chain.ipynb:10002
msgid "Self-Critique Chain with Constitutional AI"
msgstr ""

#: ../docs/modules/chains/examples/constitutional_chain.ipynb:10003
msgid "This notebook showcases how to use the ConstitutionalChain."
msgstr ""

#: ../docs/modules/chains/examples/constitutional_chain.ipynb:20002
msgid "Sometimes LLMs can produce harmful, toxic, or otherwise undesirable outputs. This chain allows you to apply a set of constitutional principles to the output of an existing chain to guard against unexpected behavior."
msgstr ""

#: ../docs/modules/chains/examples/constitutional_chain.ipynb:40002
msgid "Let's try adding a constitutional principle against outputs that are illegal or unethical."
msgstr ""

#: ../docs/modules/chains/examples/constitutional_chain.ipynb:60002
msgid "We can also run multiple principles sequentially. Let's make the model talk like Master Yoda."
msgstr ""

#: ../docs/modules/chains/examples/llm_bash.ipynb:10002
msgid "BashChain"
msgstr ""

#: ../docs/modules/chains/examples/llm_bash.ipynb:10003
msgid "This notebook showcases using LLMs and a bash process to perform simple filesystem commands."
msgstr ""

#: ../docs/modules/chains/examples/llm_bash.ipynb:30002
#: ../docs/modules/chains/examples/llm_math.ipynb:30002
#: ../docs/modules/chains/examples/sqlite.ipynb:80002
msgid "Customize Prompt"
msgstr ""

#: ../docs/modules/chains/examples/llm_bash.ipynb:30003
msgid "You can also customize the prompt that is used. Here is an example prompting to avoid using the 'echo' utility"
msgstr ""

#: ../docs/modules/chains/examples/llm_bash.ipynb:60002
msgid "Persistent Terminal"
msgstr ""

#: ../docs/modules/chains/examples/llm_bash.ipynb:60004
msgid "By default, the chain will run in a separate subprocess each time it is called. This behavior can be changed by instantiating with a persistent bash process."
msgstr ""

#: ../docs/modules/chains/examples/llm_checker.ipynb:10002
msgid "LLMCheckerChain"
msgstr ""

#: ../docs/modules/chains/examples/llm_checker.ipynb:10003
msgid "This notebook showcases how to use LLMCheckerChain."
msgstr ""

#: ../docs/modules/chains/examples/llm_math.ipynb:10002
msgid "LLM Math"
msgstr ""

#: ../docs/modules/chains/examples/llm_math.ipynb:10004
msgid "This notebook showcases using LLMs and Python REPLs to do complex word math problems."
msgstr ""

#: ../docs/modules/chains/examples/llm_math.ipynb:30003
msgid "You can also customize the prompt that is used. Here is an example prompting it to use numpy"
msgstr ""

#: ../docs/modules/chains/examples/llm_requests.ipynb:10002
msgid "LLMRequestsChain"
msgstr ""

#: ../docs/modules/chains/examples/llm_requests.ipynb:10004
msgid "Using the request library to get HTML results from a URL and then an LLM to parse results"
msgstr ""

#: ../docs/modules/chains/examples/llm_summarization_checker.ipynb:10002
msgid "LLMSummarizationCheckerChain"
msgstr ""

#: ../docs/modules/chains/examples/llm_summarization_checker.ipynb:10003
msgid "This notebook shows some examples of LLMSummarizationCheckerChain in use with different types of texts.  It has a few distinct differences from the `LLMCheckerChain`, in that it doesn't have any assumtions to the format of the input text (or summary). Additionally, as the LLMs like to hallucinate when fact checking or get confused by context, it is sometimes beneficial to run the checker multiple times.  It does this by feeding the rewritten \"True\" result back on itself, and checking the \"facts\" for truth.  As you can see from the examples below, this can be very effective in arriving at a generally true body of text."
msgstr ""

#: ../docs/modules/chains/examples/llm_summarization_checker.ipynb:10006
msgid "You can control the number of times the checker runs by setting the `max_checks` parameter.  The default is 2, but you can set it to 1 if you don't want any double-checking."
msgstr ""

#: ../docs/modules/chains/examples/moderation.ipynb:10002
msgid "Moderation"
msgstr ""

#: ../docs/modules/chains/examples/moderation.ipynb:10003
msgid "This notebook walks through examples of how to use a moderation chain, and several common ways for doing so. Moderation chains are useful for detecting text that could be hateful, violent, etc. This can be useful to apply on both user input, but also on the output of a Language Model. Some API providers, like OpenAI, [specifically prohibit](https://beta.openai.com/docs/usage-policies/use-case-policy) you, or your end users, from generating some types of harmful content. To comply with this (and to just generally prevent your application from being harmful) you may often want to append a moderation chain to any LLMChains, in order to make sure any output the LLM generates is not harmful."
msgstr ""

#: ../docs/modules/chains/examples/moderation.ipynb:10005
msgid "If the content passed into the moderation chain is harmful, there is not one best way to handle it, it probably depends on your application. Sometimes you may want to throw an error in the Chain (and have your application handle that). Other times, you may want to return something to the user explaining that the text was harmful. There could even be other ways to handle it! We will cover all these ways in this notebook."
msgstr ""

#: ../docs/modules/chains/examples/moderation.ipynb:10007
msgid "In this notebook, we will show:"
msgstr ""

#: ../docs/modules/chains/examples/moderation.ipynb:10009
msgid "How to run any piece of text through a moderation chain."
msgstr ""

#: ../docs/modules/chains/examples/moderation.ipynb:10010
msgid "How to append a Moderation chain to an LLMChain."
msgstr ""

#: ../docs/modules/chains/examples/moderation.ipynb:30002
msgid "How to use the moderation chain"
msgstr ""

#: ../docs/modules/chains/examples/moderation.ipynb:30004
msgid "Here's an example of using the moderation chain with default settings (will return a string explaining stuff was flagged)."
msgstr ""

#: ../docs/modules/chains/examples/moderation.ipynb:70002
msgid "Here's an example of using the moderation chain to throw an error."
msgstr ""

#: ../docs/modules/chains/examples/moderation.ipynb:110002
msgid "Here's an example of creating a custom moderation chain with a custom error message. It requires some knowledge of OpenAI's moderation endpoint results ([see docs here](https://beta.openai.com/docs/api-reference/moderations))."
msgstr ""

#: ../docs/modules/chains/examples/moderation.ipynb:150002
msgid "How to append a Moderation chain to an LLMChain"
msgstr ""

#: ../docs/modules/chains/examples/moderation.ipynb:150004
msgid "To easily combine a moderation chain with an LLMChain, you can use the SequentialChain abstraction."
msgstr ""

#: ../docs/modules/chains/examples/moderation.ipynb:150006
msgid "Let's start with a simple example of where the LLMChain only has a single input. For this purpose, we will prompt the model so it says something harmful."
msgstr ""

#: ../docs/modules/chains/examples/moderation.ipynb:200002
msgid "Now let's walk through an example of using it with an LLMChain which has multiple inputs (a bit more tricky because we can't use the SimpleSequentialChain)"
msgstr ""

#: ../docs/modules/chains/examples/openapi.ipynb:10002
msgid "OpenAPI Chain"
msgstr ""

#: ../docs/modules/chains/examples/openapi.ipynb:10004
msgid "This notebook shows an example of using an OpenAPI chain to call an endpoint in natural language, and get back a response in natural language"
msgstr ""

#: ../docs/modules/chains/examples/openapi.ipynb:30002
msgid "Load the spec"
msgstr ""

#: ../docs/modules/chains/examples/openapi.ipynb:30004
msgid "Load a wrapper of the spec (so we can work with it more easily). You can load from a url or from a local file."
msgstr ""

#: ../docs/modules/chains/examples/openapi.ipynb:60002
msgid "Select the Operation"
msgstr ""

#: ../docs/modules/chains/examples/openapi.ipynb:60004
msgid "In order to provide a focused on modular chain, we create a chain specifically only for one of the endpoints. Here we get an API operation from a specified endpoint and method."
msgstr ""

#: ../docs/modules/chains/examples/openapi.ipynb:80002
msgid "Construct the chain"
msgstr ""

#: ../docs/modules/chains/examples/openapi.ipynb:80004
msgid "We can now construct a chain to interact with it. In order to construct such a chain, we will pass in:"
msgstr ""

#: ../docs/modules/chains/examples/openapi.ipynb:80006
msgid "The operation endpoint"
msgstr ""

#: ../docs/modules/chains/examples/openapi.ipynb:80007
msgid "A requests wrapper (can be used to handle authentication, etc)"
msgstr ""

#: ../docs/modules/chains/examples/openapi.ipynb:80008
msgid "The LLM to use to interact with it"
msgstr ""

#: ../docs/modules/chains/examples/openapi.ipynb:130002
msgid "Return raw response"
msgstr ""

#: ../docs/modules/chains/examples/openapi.ipynb:130004
msgid "We can also run this chain without synthesizing the response. This will have the effect of just returning the raw API output."
msgstr ""

#: ../docs/modules/chains/examples/openapi.ipynb:170002
msgid "Example POST message"
msgstr ""

#: ../docs/modules/chains/examples/openapi.ipynb:170004
msgid "For this demo, we will interact with the speak API."
msgstr ""

#: ../docs/modules/chains/examples/pal.ipynb:10002
msgid "PAL"
msgstr ""

#: ../docs/modules/chains/examples/pal.ipynb:10004
msgid "Implements Program-Aided Language Models, as in https://arxiv.org/pdf/2211.10435.pdf."
msgstr ""

#: ../docs/modules/chains/examples/pal.ipynb:40002
msgid "Math Prompt"
msgstr ""

#: ../docs/modules/chains/examples/pal.ipynb:80002
msgid "Colored Objects"
msgstr ""

#: ../docs/modules/chains/examples/pal.ipynb:120002
msgid "Intermediate Steps"
msgstr ""

#: ../docs/modules/chains/examples/pal.ipynb:120003
msgid "You can also use the intermediate steps flag to return the code executed that generates the answer."
msgstr ""

#: ../docs/modules/chains/examples/sqlite.ipynb:10002
msgid "SQL Chain example"
msgstr ""

#: ../docs/modules/chains/examples/sqlite.ipynb:10004
msgid "This example demonstrates the use of the `SQLDatabaseChain` for answering questions over a database."
msgstr ""

#: ../docs/modules/chains/examples/sqlite.ipynb:20002
msgid "Under the hood, LangChain uses SQLAlchemy to connect to SQL databases. The `SQLDatabaseChain` can therefore be used with any SQL dialect supported by SQLAlchemy, such as MS SQL, MySQL, MariaDB, PostgreSQL, Oracle SQL, and SQLite. Please refer to the SQLAlchemy documentation for more information about requirements for connecting to your database. For example, a connection to MySQL requires an appropriate connector such as PyMySQL. A URI for a MySQL connection might look like: `mysql+pymysql://user:pass@some_mysql_db_address/db_name`"
msgstr ""

#: ../docs/modules/chains/examples/sqlite.ipynb:20004
msgid "This demonstration uses SQLite and the example Chinook database. To set it up, follow the instructions on https://database.guide/2-sample-databases-sqlite/, placing the `.db` file in a notebooks folder at the root of this repository."
msgstr ""

#: ../docs/modules/chains/examples/sqlite.ipynb:50002
msgid "**NOTE:** For data-sensitive projects, you can specify `return_direct=True` in the `SQLDatabaseChain` initialization to directly return the output of the SQL query without any additional formatting. This prevents the LLM from seeing any contents within the database. Note, however, the LLM still has access to the database scheme (i.e. dialect, table and key names) by default."
msgstr ""

#: ../docs/modules/chains/examples/sqlite.ipynb:80003
msgid "You can also customize the prompt that is used. Here is an example prompting it to understand that foobar is the same as the Employee table"
msgstr ""

#: ../docs/modules/chains/examples/sqlite.ipynb:120002
msgid "Return Intermediate Steps"
msgstr ""

#: ../docs/modules/chains/examples/sqlite.ipynb:120004
msgid "You can also return the intermediate steps of the SQLDatabaseChain. This allows you to access the SQL statement that was generated, as well as the result of running that against the SQL Database."
msgstr ""

#: ../docs/modules/chains/examples/sqlite.ipynb:150002
msgid "Choosing how to limit the number of rows returned"
msgstr ""

#: ../docs/modules/chains/examples/sqlite.ipynb:150003
msgid "If you are querying for several rows of a table you can select the maximum number of results you want to get by using the 'top_k' parameter (default is 10). This is useful for avoiding query results that exceed the prompt max length or consume tokens unnecessarily."
msgstr ""

#: ../docs/modules/chains/examples/sqlite.ipynb:180002
msgid "Adding example rows from each table"
msgstr ""

#: ../docs/modules/chains/examples/sqlite.ipynb:180003
msgid "Sometimes, the format of the data is not obvious and it is optimal to include a sample of rows from the tables in the prompt to allow the LLM to understand the data before providing a final query. Here we will use this feature to let the LLM know that artists are saved with their full names by providing two rows from the `Track` table."
msgstr ""

#: ../docs/modules/chains/examples/sqlite.ipynb:200002
msgid "The sample rows are added to the prompt after each corresponding table's column information:"
msgstr ""

#: ../docs/modules/chains/examples/sqlite.ipynb:240002
msgid "Custom Table Info"
msgstr ""

#: ../docs/modules/chains/examples/sqlite.ipynb:240003
msgid "In some cases, it can be useful to provide custom table information instead of using the automatically generated table definitions and the first `sample_rows_in_table_info` sample rows. For example, if you know that the first few rows of a table are uninformative, it could help to manually provide example rows that are more diverse or provide more information to the model. It is also possible to limit the columns that will be visible to the model if there are unnecessary columns."
msgstr ""

#: ../docs/modules/chains/examples/sqlite.ipynb:240005
msgid "This information can be provided as a dictionary with table names as the keys and table information as the values. For example, let's provide a custom definition and sample rows for the Track table with only a few columns:"
msgstr ""

#: ../docs/modules/chains/examples/sqlite.ipynb:270002
msgid "Note how our custom table definition and sample rows for `Track` overrides the `sample_rows_in_table_info` parameter. Tables that are not overridden by `custom_table_info`, in this example `Playlist`, will have their table info gathered automatically as usual."
msgstr ""

#: ../docs/modules/chains/examples/sqlite.ipynb:290002
msgid "SQLDatabaseSequentialChain"
msgstr ""

#: ../docs/modules/chains/examples/sqlite.ipynb:290004
msgid "Chain for querying SQL database that is a sequential chain."
msgstr ""

#: ../docs/modules/chains/examples/sqlite.ipynb:290006
msgid "The chain is as follows:"
msgstr ""

#: ../docs/modules/chains/examples/sqlite.ipynb:290011
msgid "This is useful in cases where the number of tables in the database is large."
msgstr ""

#: ../docs/modules/chains/generic/async_chain.ipynb:10002
msgid "Async API for Chain"
msgstr ""

#: ../docs/modules/chains/generic/async_chain.ipynb:10004
msgid "LangChain provides async support for Chains by leveraging the [asyncio](https://docs.python.org/3/library/asyncio.html) library."
msgstr ""

#: ../docs/modules/chains/generic/async_chain.ipynb:10006
msgid "Async methods are currently supported in `LLMChain` (through `arun`, `apredict`, `acall`) and `LLMMathChain` (through `arun` and `acall`), `ChatVectorDBChain`, and [QA chains](../indexes/chain_examples/question_answering.html). Async support for other chains is on the roadmap."
msgstr ""

#: ../docs/modules/chains/generic/from_hub.ipynb:10002
msgid "Loading from LangChainHub"
msgstr ""

#: ../docs/modules/chains/generic/from_hub.ipynb:10004
msgid "This notebook covers how to load chains from [LangChainHub](https://github.com/hwchase17/langchain-hub)."
msgstr ""

#: ../docs/modules/chains/generic/from_hub.ipynb:40002
msgid "Sometimes chains will require extra arguments that were not serialized with the chain. For example, a chain that does question answering over a vector database will require a vector database."
msgstr ""

#: ../docs/modules/chains/generic/llm_chain.ipynb:10002
msgid "LLM Chain"
msgstr ""

#: ../docs/modules/chains/generic/llm_chain.ipynb:20002
msgid "`LLMChain` is perhaps one of the most popular ways of querying an LLM object. It formats the prompt template using the input key values provided (and also memory key values, if available), passes the formatted string to LLM and returns the LLM output. Below we show additional functionalities of `LLMChain` class."
msgstr ""

#: ../docs/modules/chains/generic/llm_chain.ipynb:40002
msgid "Additional ways of running LLM Chain"
msgstr ""

#: ../docs/modules/chains/generic/llm_chain.ipynb:50002
msgid "Aside from `__call__` and `run` methods shared by all `Chain` object (see [Getting Started](../getting_started.ipynb) to learn more), `LLMChain` offers a few more ways of calling the chain logic:"
msgstr ""

#: ../docs/modules/chains/generic/llm_chain.ipynb:60002
msgid "`apply` allows you run the chain against a list of inputs:"
msgstr ""

#: ../docs/modules/chains/generic/llm_chain.ipynb:80002
msgid "`generate` is similar to `apply`, except it return an `LLMResult` instead of string. `LLMResult` often contains useful generation such as token usages and finish reason."
msgstr ""

#: ../docs/modules/chains/generic/llm_chain.ipynb:100002
msgid "`predict` is similar to `run` method except in 2 ways:"
msgstr ""

#: ../docs/modules/chains/generic/llm_chain.ipynb:100003
msgid "Input key is specified as keyword argument instead of a Python dict"
msgstr ""

#: ../docs/modules/chains/generic/llm_chain.ipynb:100004
msgid "It supports multiple input keys."
msgstr ""

#: ../docs/modules/chains/generic/llm_chain.ipynb:130002
msgid "Parsing the outputs"
msgstr ""

#: ../docs/modules/chains/generic/llm_chain.ipynb:140002
msgid "By default, `LLMChain` does not parse the output even if the underlying `prompt` object has an output parser. If you would like to apply that output parser on the LLM output, use `predict_and_parse` instead of `predict` and `apply_and_parse` instead of `apply`."
msgstr ""

#: ../docs/modules/chains/generic/llm_chain.ipynb:150002
msgid "With `predict`:"
msgstr ""

#: ../docs/modules/chains/generic/llm_chain.ipynb:170002
msgid "With `predict_and_parser`:"
msgstr ""

#: ../docs/modules/chains/generic/llm_chain.ipynb:190002
msgid "Initialize from string"
msgstr ""

#: ../docs/modules/chains/generic/llm_chain.ipynb:200002
msgid "You can also construct an LLMChain from a string template directly."
msgstr ""

#: ../docs/modules/chains/generic/sequential_chains.ipynb:10002
msgid "Sequential Chains"
msgstr ""

#: ../docs/modules/chains/generic/sequential_chains.ipynb:20002
msgid "The next step after calling a language model is make a series of calls to a language model. This is particularly useful when you want to take the output from one call and use it as the input to another."
msgstr ""

#: ../docs/modules/chains/generic/sequential_chains.ipynb:20004
msgid "In this notebook we will walk through some examples for how to do this, using sequential chains. Sequential chains are defined as a series of chains, called in deterministic order. There are two types of sequential chains:"
msgstr ""

#: ../docs/modules/chains/generic/sequential_chains.ipynb:20006
msgid "`SimpleSequentialChain`: The simplest form of sequential chains, where each step has a singular input/output, and the output of one step is the input to the next."
msgstr ""

#: ../docs/modules/chains/generic/sequential_chains.ipynb:20007
msgid "`SequentialChain`: A more general form of sequential chains, allowing for multiple inputs/outputs."
msgstr ""

#: ../docs/modules/chains/generic/sequential_chains.ipynb:30002
msgid "SimpleSequentialChain"
msgstr ""

#: ../docs/modules/chains/generic/sequential_chains.ipynb:30004
msgid "In this series of chains, each individual chain has a single input and a single output, and the output of one step is used as input to the next."
msgstr ""

#: ../docs/modules/chains/generic/sequential_chains.ipynb:30006
msgid "Let's walk through a toy example of doing this, where the first chain takes in the title of an imaginary play and then generates a synopsis for that title, and the second chain takes in the synopsis of that play and generates an imaginary review for that play."
msgstr ""

#: ../docs/modules/chains/generic/sequential_chains.ipynb:100002
msgid "Sequential Chain"
msgstr ""

#: ../docs/modules/chains/generic/sequential_chains.ipynb:100003
msgid "Of course, not all sequential chains will be as simple as passing a single string as an argument and getting a single string as output for all steps in the chain. In this next example, we will experiment with more complex chains that involve multiple inputs, and where there also multiple final outputs."
msgstr ""

#: ../docs/modules/chains/generic/sequential_chains.ipynb:100005
msgid "Of particular importance is how we name the input/output variable names. In the above example we didn't have to think about that because we were just passing the output of one chain directly as input to the next, but here we do have worry about that because we have multiple inputs."
msgstr ""

#: ../docs/modules/chains/generic/sequential_chains.ipynb:150002
msgid "Memory in Sequential Chains"
msgstr ""

#: ../docs/modules/chains/generic/sequential_chains.ipynb:150003
msgid "Sometimes you may want to pass along some context to use in each step of the chain or in a later part of the chain, but maintaining and chaining together the input/output variables can quickly get messy.  Using `SimpleMemory` is a convenient way to do manage this and clean up your chains."
msgstr ""

#: ../docs/modules/chains/generic/sequential_chains.ipynb:150005
msgid "For example, using the previous playwright SequentialChain, lets say you wanted to include some context about date, time and location of the play, and using the generated synopsis and review, create some social media post text.  You could add these new context variables as `input_variables`, or we can add a `SimpleMemory` to the chain to manage this context:"
msgstr ""

#: ../docs/modules/chains/generic/serialization.ipynb:10002
msgid "Serialization"
msgstr ""

#: ../docs/modules/chains/generic/serialization.ipynb:10003
msgid "This notebook covers how to serialize chains to and from disk. The serialization format we use is json or yaml. Currently, only some chains support this type of serialization. We will grow the number of supported chains over time."
msgstr ""

#: ../docs/modules/chains/generic/serialization.ipynb:20002
msgid "Saving a chain to disk"
msgstr ""

#: ../docs/modules/chains/generic/serialization.ipynb:20003
msgid "First, let's go over how to save a chain to disk. This can be done with the `.save` method, and specifying a file path with a json or yaml extension."
msgstr ""

#: ../docs/modules/chains/generic/serialization.ipynb:50002
msgid "Let's now take a look at what's inside this saved file"
msgstr ""

#: ../docs/modules/chains/generic/serialization.ipynb:70002
msgid "Loading a chain from disk"
msgstr ""

#: ../docs/modules/chains/generic/serialization.ipynb:70003
msgid "We can load a chain from disk by using the `load_chain` method."
msgstr ""

#: ../docs/modules/chains/generic/serialization.ipynb:110002
msgid "Saving components separately"
msgstr ""

#: ../docs/modules/chains/generic/serialization.ipynb:110003
msgid "In the above example, we can see that the prompt and llm configuration information is saved in the same json as the overall chain. Alternatively, we can split them up and save them separately. This is often useful to make the saved components more modular. In order to do this, we just need to specify `llm_path` instead of the `llm` component, and `prompt_path` instead of the `prompt` component."
msgstr ""

#: ../docs/modules/chains/generic/serialization.ipynb:180002
msgid "We can then load it in the same way"
msgstr ""

#: ../docs/modules/chains/generic/transformation.ipynb:10002
msgid "Transformation Chain"
msgstr ""

#: ../docs/modules/chains/generic/transformation.ipynb:10004
msgid "This notebook showcases using a generic transformation chain."
msgstr ""

#: ../docs/modules/chains/generic/transformation.ipynb:10006
msgid "As an example, we will create a dummy transformation that takes in a super long text, filters the text to only the first 3 paragraphs, and then passes that into an LLMChain to summarize those."
msgstr ""

#: ../docs/modules/chains/getting_started.ipynb:10004
msgid "In this tutorial, we will learn about creating simple chains in LangChain. We will learn how to create a chain, add components to it, and run it."
msgstr ""

#: ../docs/modules/chains/getting_started.ipynb:10006
msgid "In this tutorial, we will cover:"
msgstr ""

#: ../docs/modules/chains/getting_started.ipynb:10007
msgid "Using a simple LLM chain"
msgstr ""

#: ../docs/modules/chains/getting_started.ipynb:10008
msgid "Creating sequential chains"
msgstr ""

#: ../docs/modules/chains/getting_started.ipynb:10009
msgid "Creating a custom chain"
msgstr ""

#: ../docs/modules/chains/getting_started.ipynb:10011
msgid "Why do we need chains?"
msgstr ""

#: ../docs/modules/chains/getting_started.ipynb:10013
msgid "Chains allow us to combine multiple components together to create a single, coherent application. For example, we can create a chain that takes user input, formats it with a PromptTemplate, and then passes the formatted response to an LLM. We can build more complex chains by combining multiple chains together, or by combining chains with other components."
msgstr ""

#: ../docs/modules/chains/getting_started.ipynb:20002
msgid "Quick start: Using `LLMChain`"
msgstr ""

#: ../docs/modules/chains/getting_started.ipynb:20004
msgid "The `LLMChain` is a simple chain that takes in a prompt template, formats it with the user input and returns the response from an LLM."
msgstr ""

#: ../docs/modules/chains/getting_started.ipynb:20007
msgid "To use the `LLMChain`, first create a prompt template."
msgstr ""

#: ../docs/modules/chains/getting_started.ipynb:40002
msgid "We can now create a very simple chain that will take user input, format the prompt with it, and then send it to the LLM."
msgstr ""

#: ../docs/modules/chains/getting_started.ipynb:60002
msgid "You can use a chat model in an `LLMChain` as well:"
msgstr ""

#: ../docs/modules/chains/getting_started.ipynb:80002
msgid "Different ways of calling chains"
msgstr ""

#: ../docs/modules/chains/getting_started.ipynb:80004
msgid "All classes inherited from `Chain` offer a few ways of running chain logic. The most direct one is by using `__call__`:"
msgstr ""

#: ../docs/modules/chains/getting_started.ipynb:100002
msgid "By default, `__call__` returns both the input and output key values. You can configure it to only return output key values by setting `return_only_outputs` to `True`."
msgstr ""

#: ../docs/modules/chains/getting_started.ipynb:120002
msgid "If the `Chain` only outputs one output key (i.e. only has one element in its `output_keys`), you can  use `run` method. Note that `run` outputs a string instead of a dictionary."
msgstr ""

#: ../docs/modules/chains/getting_started.ipynb:150002
msgid "In the case of one input key, you can input the string directly without specifying the input mapping."
msgstr ""

#: ../docs/modules/chains/getting_started.ipynb:170002
msgid "Tips: You can easily integrate a `Chain` object as a `Tool` in your `Agent` via its `run` method. See an example [here](../agents/tools/custom_tools.ipynb)."
msgstr ""

#: ../docs/modules/chains/getting_started.ipynb:180002
msgid "Add memory to chains"
msgstr ""

#: ../docs/modules/chains/getting_started.ipynb:180004
msgid "`Chain` supports taking a `BaseMemory` object as its `memory` argument, allowing `Chain` object to persist data across multiple calls. In other words, it makes `Chain` a stateful object."
msgstr ""

#: ../docs/modules/chains/getting_started.ipynb:200002
msgid "Essentially, `BaseMemory` defines an interface of how `langchain` stores memory. It allows reading of stored data through `load_memory_variables` method and storing new data through `save_context` method. You can learn more about it in [Memory](../memory/getting_started.ipynb) section."
msgstr ""

#: ../docs/modules/chains/getting_started.ipynb:210002
msgid "Debug Chain"
msgstr ""

#: ../docs/modules/chains/getting_started.ipynb:210004
msgid "It can be hard to debug `Chain` object solely from its output as most `Chain` objects involve a fair amount of input prompt preprocessing and LLM output post-processing. Setting `verbose` to `True` will print out some internal states of the `Chain` object while it is being ran."
msgstr ""

#: ../docs/modules/chains/getting_started.ipynb:230002
msgid "Combine chains with the `SequentialChain`"
msgstr ""

#: ../docs/modules/chains/getting_started.ipynb:230004
msgid "The next step after calling a language model is to make a series of calls to a language model. We can do this using sequential chains, which are chains that execute their links in a predefined order. Specifically, we will use the `SimpleSequentialChain`. This is the simplest type of a sequential chain, where each step has a single input/output, and the output of one step is the input to the next."
msgstr ""

#: ../docs/modules/chains/getting_started.ipynb:230006
msgid "In this tutorial, our sequential chain will:"
msgstr ""

#: ../docs/modules/chains/getting_started.ipynb:230007
msgid "First, create a company name for a product. We will reuse the `LLMChain` we'd previously initialized to create this company name."
msgstr ""

#: ../docs/modules/chains/getting_started.ipynb:230008
msgid "Then, create a catchphrase for the product. We will initialize a new `LLMChain` to create this catchphrase, as shown below."
msgstr ""

#: ../docs/modules/chains/getting_started.ipynb:250002
msgid "Now we can combine the two LLMChains, so that we can create a company name and a catchphrase in a single step."
msgstr ""

#: ../docs/modules/chains/getting_started.ipynb:270002
msgid "Create a custom chain with the `Chain` class"
msgstr ""

#: ../docs/modules/chains/getting_started.ipynb:270004
msgid "LangChain provides many chains out of the box, but sometimes you may want to create a custom chain for your specific use case. For this example, we will create a custom chain that concatenates the outputs of 2 `LLMChain`s."
msgstr ""

#: ../docs/modules/chains/getting_started.ipynb:270006
msgid "In order to create a custom chain:"
msgstr ""

#: ../docs/modules/chains/getting_started.ipynb:270007
msgid "Start by subclassing the `Chain` class,"
msgstr ""

#: ../docs/modules/chains/getting_started.ipynb:270008
msgid "Fill out the `input_keys` and `output_keys` properties,"
msgstr ""

#: ../docs/modules/chains/getting_started.ipynb:270009
msgid "Add the `_call` method that shows how to execute the chain."
msgstr ""

#: ../docs/modules/chains/getting_started.ipynb:270011
msgid "These steps are demonstrated in the example below:"
msgstr ""

#: ../docs/modules/chains/getting_started.ipynb:290002
msgid "Now, we can try running the chain that we called."
msgstr ""

#: ../docs/modules/chains/getting_started.ipynb:310002
msgid "That's it! For more details about how to do cool things with Chains, check out the [how-to guide](how_to_guides.rst) for chains."
msgstr ""

#: ../docs/modules/chains/how_to_guides.rst:4
msgid "A chain is made up of links, which can be either primitives or other chains. Primitives can be either `prompts <../prompts.html>`_, `models <../models.html>`_, arbitrary functions, or other chains. The examples here are broken up into three sections:"
msgstr ""

#: ../docs/modules/chains/how_to_guides.rst:8
msgid "**Generic Functionality**"
msgstr ""

#: ../docs/modules/chains/how_to_guides.rst:10
msgid "Covers both generic chains (that are useful in a wide variety of applications) as well as generic functionality related to those chains."
msgstr ""

#: ../docs/modules/chains/how_to_guides.rst:18
msgid "**Index-related Chains**"
msgstr ""

#: ../docs/modules/chains/how_to_guides.rst:20
msgid "Chains related to working with indexes."
msgstr ""

#: ../docs/modules/chains/how_to_guides.rst:29
msgid "**All other chains**"
msgstr ""

#: ../docs/modules/chains/how_to_guides.rst:31
msgid "All other types of chains!"
msgstr ""

#: ../docs/modules/chains/index_examples/analyze_document.ipynb:10002
msgid "Analyze Document"
msgstr ""

#: ../docs/modules/chains/index_examples/analyze_document.ipynb:10004
msgid "The AnalyzeDocumentChain is more of an end to chain. This chain takes in a single document, splits it up, and then runs it through a CombineDocumentsChain. This can be used as more of an end-to-end chain."
msgstr ""

#: ../docs/modules/chains/index_examples/analyze_document.ipynb:30002
msgid "Summarize"
msgstr ""

#: ../docs/modules/chains/index_examples/analyze_document.ipynb:30003
msgid "Let's take a look at it in action below, using it summarize a long document."
msgstr ""

#: ../docs/modules/chains/index_examples/analyze_document.ipynb:80002
#: ../docs/modules/chains/index_examples/question_answering.ipynb:10002
msgid "Question Answering"
msgstr ""

#: ../docs/modules/chains/index_examples/analyze_document.ipynb:80003
msgid "Let's take a look at this using a question answering chain."
msgstr ""

#: ../docs/modules/chains/index_examples/chat_vector_db.ipynb:10002
msgid "Chat Over Documents with Chat History"
msgstr ""

#: ../docs/modules/chains/index_examples/chat_vector_db.ipynb:10004
msgid "This notebook goes over how to set up a chain to chat over documents with chat history using a `ConversationalRetrievalChain`. The only difference between this chain and the [RetrievalQAChain](./vector_db_qa.ipynb) is that this allows for passing in of a chat history which can be used to allow for follow up questions."
msgstr ""

#: ../docs/modules/chains/index_examples/chat_vector_db.ipynb:30002
msgid "Load in documents. You can replace this with a loader for whatever type of data you want"
msgstr ""

#: ../docs/modules/chains/index_examples/chat_vector_db.ipynb:50002
msgid "If you had multiple loaders that you wanted to combine, you do something like:"
msgstr ""

#: ../docs/modules/chains/index_examples/chat_vector_db.ipynb:70002
msgid "We now split the documents, create embeddings for them, and put them in a vectorstore. This allows us to do semantic search over them."
msgstr ""

#: ../docs/modules/chains/index_examples/chat_vector_db.ipynb:90002
msgid "We can now create a memory object, which is neccessary to track the inputs/outputs and hold a conversation."
msgstr ""

#: ../docs/modules/chains/index_examples/chat_vector_db.ipynb:110002
msgid "We now initialize the `ConversationalRetrievalChain`"
msgstr ""

#: ../docs/modules/chains/index_examples/chat_vector_db.ipynb:170002
msgid "Pass in chat history"
msgstr ""

#: ../docs/modules/chains/index_examples/chat_vector_db.ipynb:170004
msgid "In the above example, we used a Memory object to track chat history. We can also just pass it in explicitly. In order to do this, we need to initialize a chain without any memory object."
msgstr ""

#: ../docs/modules/chains/index_examples/chat_vector_db.ipynb:190002
msgid "Here's an example of asking a question with no chat history"
msgstr ""

#: ../docs/modules/chains/index_examples/chat_vector_db.ipynb:220002
msgid "Here's an example of asking a question with some chat history"
msgstr ""

#: ../docs/modules/chains/index_examples/chat_vector_db.ipynb:250002
#: ../docs/modules/chains/index_examples/vector_db_qa.ipynb:160002
msgid "Return Source Documents"
msgstr ""

#: ../docs/modules/chains/index_examples/chat_vector_db.ipynb:250003
msgid "You can also easily return source documents from the ConversationalRetrievalChain. This is useful for when you want to inspect what documents were returned."
msgstr ""

#: ../docs/modules/chains/index_examples/chat_vector_db.ipynb:290002
msgid "ConversationalRetrievalChain with `search_distance`"
msgstr ""

#: ../docs/modules/chains/index_examples/chat_vector_db.ipynb:290003
msgid "If you are using a vector store that supports filtering by search distance, you can add a threshold value parameter."
msgstr ""

#: ../docs/modules/chains/index_examples/chat_vector_db.ipynb:320002
msgid "ConversationalRetrievalChain with `map_reduce`"
msgstr ""

#: ../docs/modules/chains/index_examples/chat_vector_db.ipynb:320003
msgid "We can also use different types of combine document chains with the ConversationalRetrievalChain chain."
msgstr ""

#: ../docs/modules/chains/index_examples/chat_vector_db.ipynb:370002
msgid "ConversationalRetrievalChain with Question Answering with sources"
msgstr ""

#: ../docs/modules/chains/index_examples/chat_vector_db.ipynb:370004
msgid "You can also use this chain with the question answering with sources chain."
msgstr ""

#: ../docs/modules/chains/index_examples/chat_vector_db.ipynb:420002
msgid "ConversationalRetrievalChain with streaming to `stdout`"
msgstr ""

#: ../docs/modules/chains/index_examples/chat_vector_db.ipynb:420004
msgid "Output from the chain will be streamed to `stdout` token by token in this example."
msgstr ""

#: ../docs/modules/chains/index_examples/chat_vector_db.ipynb:460002
msgid "get_chat_history Function"
msgstr ""

#: ../docs/modules/chains/index_examples/chat_vector_db.ipynb:460003
msgid "You can also specify a `get_chat_history` function, which can be used to format the chat_history string."
msgstr ""

#: ../docs/modules/chains/index_examples/graph_qa.ipynb:10002
msgid "Graph QA"
msgstr ""

#: ../docs/modules/chains/index_examples/graph_qa.ipynb:10004
msgid "This notebook goes over how to do question answering over a graph data structure."
msgstr ""

#: ../docs/modules/chains/index_examples/graph_qa.ipynb:20002
msgid "Create the graph"
msgstr ""

#: ../docs/modules/chains/index_examples/graph_qa.ipynb:20004
msgid "In this section, we construct an example graph. At the moment, this works best for small pieces of text."
msgstr ""

#: ../docs/modules/chains/index_examples/graph_qa.ipynb:60002
msgid "We will use just a small snippet, because extracting the knowledge triplets is a bit intensive at the moment."
msgstr ""

#: ../docs/modules/chains/index_examples/graph_qa.ipynb:100002
msgid "We can inspect the created graph."
msgstr ""

#: ../docs/modules/chains/index_examples/graph_qa.ipynb:120002
msgid "Querying the graph"
msgstr ""

#: ../docs/modules/chains/index_examples/graph_qa.ipynb:120003
msgid "We can now use the graph QA chain to ask question of the graph"
msgstr ""

#: ../docs/modules/chains/index_examples/graph_qa.ipynb:160002
msgid "Save the graph"
msgstr ""

#: ../docs/modules/chains/index_examples/graph_qa.ipynb:160003
msgid "We can also save and load the graph."
msgstr ""

#: ../docs/modules/chains/index_examples/hyde.ipynb:10002
msgid "Hypothetical Document Embeddings"
msgstr ""

#: ../docs/modules/chains/index_examples/hyde.ipynb:10003
msgid "This notebook goes over how to use Hypothetical Document Embeddings (HyDE), as described in [this paper](https://arxiv.org/abs/2212.10496)."
msgstr ""

#: ../docs/modules/chains/index_examples/hyde.ipynb:10005
msgid "At a high level, HyDE is an embedding technique that takes queries, generates a hypothetical answer, and then embeds that generated document and uses that as the final example."
msgstr ""

#: ../docs/modules/chains/index_examples/hyde.ipynb:10007
msgid "In order to use HyDE, we therefore need to provide a base embedding model, as well as an LLMChain that can be used to generate those documents. By default, the HyDE class comes with some default prompts to use (see the paper for more details on them), but we can also create our own."
msgstr ""

#: ../docs/modules/chains/index_examples/hyde.ipynb:70002
msgid "Multiple generations"
msgstr ""

#: ../docs/modules/chains/index_examples/hyde.ipynb:70003
msgid "We can also generate multiple documents and then combine the embeddings for those. By default, we combine those by taking the average. We can do this by changing the LLM we use to generate documents to return multiple things."
msgstr ""

#: ../docs/modules/chains/index_examples/hyde.ipynb:110002
msgid "Using our own prompts"
msgstr ""

#: ../docs/modules/chains/index_examples/hyde.ipynb:110003
msgid "Besides using preconfigured prompts, we can also easily construct our own prompts and use those in the LLMChain that is generating the documents. This can be useful if we know the domain our queries will be in, as we can condition the prompt to generate text more similar to that."
msgstr ""

#: ../docs/modules/chains/index_examples/hyde.ipynb:110005
msgid "In the example below, let's condition it to generate text about a state of the union address (because we will use that in the next example)."
msgstr ""

#: ../docs/modules/chains/index_examples/hyde.ipynb:150002
msgid "Using HyDE"
msgstr ""

#: ../docs/modules/chains/index_examples/hyde.ipynb:150003
msgid "Now that we have HyDE, we can use it as we would any other embedding class! Here is using it to find similar passages in the state of the union example."
msgstr ""

#: ../docs/modules/chains/index_examples/qa_with_sources.ipynb:10002
msgid "Question Answering with Sources"
msgstr ""

#: ../docs/modules/chains/index_examples/qa_with_sources.ipynb:10004
msgid "This notebook walks through how to use LangChain for question answering with sources over a list of documents. It covers four different chain types: `stuff`, `map_reduce`, `refine`,`map-rerank`. For a more in depth explanation of what these chain types are, see [here](../combine_docs.md)."
msgstr ""

#: ../docs/modules/chains/index_examples/qa_with_sources.ipynb:20002
#: ../docs/modules/chains/index_examples/question_answering.ipynb:20002
#: ../docs/modules/chains/index_examples/summarize.ipynb:20002
#: ../docs/modules/chains/index_examples/vector_db_text_generation.ipynb:20002
msgid "Prepare Data"
msgstr ""

#: ../docs/modules/chains/index_examples/qa_with_sources.ipynb:20003
#: ../docs/modules/chains/index_examples/question_answering.ipynb:20003
msgid "First we prepare the data. For this example we do similarity search over a vector database, but these documents could be fetched in any manner (the point of this notebook to highlight what to do AFTER you fetch the documents)."
msgstr ""

#: ../docs/modules/chains/index_examples/qa_with_sources.ipynb:80002
#: ../docs/modules/chains/index_examples/question_answering.ipynb:80002
#: ../docs/modules/chains/index_examples/summarize.ipynb:70002
msgid "Quickstart"
msgstr ""

#: ../docs/modules/chains/index_examples/qa_with_sources.ipynb:80003
#: ../docs/modules/chains/index_examples/question_answering.ipynb:80003
#: ../docs/modules/chains/index_examples/summarize.ipynb:70003
msgid "If you just want to get started as quickly as possible, this is the recommended way to do it:"
msgstr ""

#: ../docs/modules/chains/index_examples/qa_with_sources.ipynb:100002
#: ../docs/modules/chains/index_examples/question_answering.ipynb:100002
#: ../docs/modules/chains/index_examples/summarize.ipynb:90002
msgid "If you want more control and understanding over what is happening, please see the information below."
msgstr ""

#: ../docs/modules/chains/index_examples/qa_with_sources.ipynb:110002
#: ../docs/modules/chains/index_examples/question_answering.ipynb:110002
#: ../docs/modules/chains/index_examples/summarize.ipynb:100002
msgid "The `stuff` Chain"
msgstr ""

#: ../docs/modules/chains/index_examples/qa_with_sources.ipynb:110004
msgid "This sections shows results of using the `stuff` Chain to do question answering with sources."
msgstr ""

#: ../docs/modules/chains/index_examples/qa_with_sources.ipynb:140002
#: ../docs/modules/chains/index_examples/qa_with_sources.ipynb:220002
#: ../docs/modules/chains/index_examples/qa_with_sources.ipynb:310002
#: ../docs/modules/chains/index_examples/qa_with_sources.ipynb:390002
#: ../docs/modules/chains/index_examples/question_answering.ipynb:140002
#: ../docs/modules/chains/index_examples/question_answering.ipynb:220002
#: ../docs/modules/chains/index_examples/question_answering.ipynb:310002
#: ../docs/modules/chains/index_examples/question_answering.ipynb:380002
#: ../docs/modules/chains/index_examples/summarize.ipynb:130002
#: ../docs/modules/chains/index_examples/summarize.ipynb:210002
#: ../docs/modules/chains/index_examples/summarize.ipynb:270002
msgid "**Custom Prompts**"
msgstr ""

#: ../docs/modules/chains/index_examples/qa_with_sources.ipynb:140004
#: ../docs/modules/chains/index_examples/qa_with_sources.ipynb:220004
#: ../docs/modules/chains/index_examples/qa_with_sources.ipynb:310004
#: ../docs/modules/chains/index_examples/qa_with_sources.ipynb:390004
#: ../docs/modules/chains/index_examples/question_answering.ipynb:140004
#: ../docs/modules/chains/index_examples/question_answering.ipynb:220004
#: ../docs/modules/chains/index_examples/question_answering.ipynb:310004
#: ../docs/modules/chains/index_examples/question_answering.ipynb:380004
#: ../docs/modules/chains/index_examples/summarize.ipynb:130004
#: ../docs/modules/chains/index_examples/summarize.ipynb:210004
#: ../docs/modules/chains/index_examples/summarize.ipynb:270004
msgid "You can also use your own prompts with this chain. In this example, we will respond in Italian."
msgstr ""

#: ../docs/modules/chains/index_examples/qa_with_sources.ipynb:160002
#: ../docs/modules/chains/index_examples/question_answering.ipynb:160002
#: ../docs/modules/chains/index_examples/summarize.ipynb:150002
msgid "The `map_reduce` Chain"
msgstr ""

#: ../docs/modules/chains/index_examples/qa_with_sources.ipynb:160004
msgid "This sections shows results of using the `map_reduce` Chain to do question answering with sources."
msgstr ""

#: ../docs/modules/chains/index_examples/qa_with_sources.ipynb:190002
#: ../docs/modules/chains/index_examples/qa_with_sources.ipynb:280002
#: ../docs/modules/chains/index_examples/question_answering.ipynb:190002
#: ../docs/modules/chains/index_examples/question_answering.ipynb:280002
#: ../docs/modules/chains/index_examples/summarize.ipynb:180002
#: ../docs/modules/chains/index_examples/summarize.ipynb:250002
msgid "**Intermediate Steps**"
msgstr ""

#: ../docs/modules/chains/index_examples/qa_with_sources.ipynb:190004
msgid "We can also return the intermediate steps for `map_reduce` chains, should we want to inspect them. This is done with the `return_intermediate_steps` variable."
msgstr ""

#: ../docs/modules/chains/index_examples/qa_with_sources.ipynb:240002
#: ../docs/modules/chains/index_examples/question_answering.ipynb:240002
msgid "**Batch Size**"
msgstr ""

#: ../docs/modules/chains/index_examples/qa_with_sources.ipynb:240004
#: ../docs/modules/chains/index_examples/question_answering.ipynb:240004
msgid "When using the `map_reduce` chain, one thing to keep in mind is the batch size you are using during the map step. If this is too high, it could cause rate limiting errors. You can control this by setting the batch size on the LLM used. Note that this only applies for LLMs with this parameter. Below is an example of doing so:"
msgstr ""

#: ../docs/modules/chains/index_examples/qa_with_sources.ipynb:250002
#: ../docs/modules/chains/index_examples/question_answering.ipynb:250002
#: ../docs/modules/chains/index_examples/summarize.ipynb:230002
msgid "The `refine` Chain"
msgstr ""

#: ../docs/modules/chains/index_examples/qa_with_sources.ipynb:250004
msgid "This sections shows results of using the `refine` Chain to do question answering with sources."
msgstr ""

#: ../docs/modules/chains/index_examples/qa_with_sources.ipynb:280004
msgid "We can also return the intermediate steps for `refine` chains, should we want to inspect them. This is done with the `return_intermediate_steps` variable."
msgstr ""

#: ../docs/modules/chains/index_examples/qa_with_sources.ipynb:340002
#: ../docs/modules/chains/index_examples/question_answering.ipynb:330002
msgid "The `map-rerank` Chain"
msgstr ""

#: ../docs/modules/chains/index_examples/qa_with_sources.ipynb:340004
#: ../docs/modules/chains/index_examples/question_answering.ipynb:330004
msgid "This sections shows results of using the `map-rerank` Chain to do question answering with sources."
msgstr ""

#: ../docs/modules/chains/index_examples/question_answering.ipynb:10004
msgid "This notebook walks through how to use LangChain for question answering over a list of documents. It covers four different types of chains: `stuff`, `map_reduce`, `refine`, `map_rerank`. For a more in depth explanation of what these chain types are, see [here](../combine_docs.md)."
msgstr ""

#: ../docs/modules/chains/index_examples/question_answering.ipynb:110004
msgid "This sections shows results of using the `stuff` Chain to do question answering."
msgstr ""

#: ../docs/modules/chains/index_examples/question_answering.ipynb:160004
msgid "This sections shows results of using the `map_reduce` Chain to do question answering."
msgstr ""

#: ../docs/modules/chains/index_examples/question_answering.ipynb:190004
#: ../docs/modules/chains/index_examples/summarize.ipynb:180004
msgid "We can also return the intermediate steps for `map_reduce` chains, should we want to inspect them. This is done with the `return_map_steps` variable."
msgstr ""

#: ../docs/modules/chains/index_examples/question_answering.ipynb:250004
msgid "This sections shows results of using the `refine` Chain to do question answering."
msgstr ""

#: ../docs/modules/chains/index_examples/question_answering.ipynb:280004
#: ../docs/modules/chains/index_examples/summarize.ipynb:250004
msgid "We can also return the intermediate steps for `refine` chains, should we want to inspect them. This is done with the `return_refine_steps` variable."
msgstr ""

#: ../docs/modules/chains/index_examples/summarize.ipynb:10002
msgid "Summarization"
msgstr ""

#: ../docs/modules/chains/index_examples/summarize.ipynb:10004
msgid "This notebook walks through how to use LangChain for summarization over a list of documents. It covers three different chain types: `stuff`, `map_reduce`, and `refine`. For a more in depth explanation of what these chain types are, see [here](https://docs.langchain.com/docs/components/chains/index_related_chains)."
msgstr ""

#: ../docs/modules/chains/index_examples/summarize.ipynb:20003
msgid "First we prepare the data. For this example we create multiple documents from one long one, but these documents could be fetched in any manner (the point of this notebook to highlight what to do AFTER you fetch the documents)."
msgstr ""

#: ../docs/modules/chains/index_examples/summarize.ipynb:100004
msgid "This sections shows results of using the `stuff` Chain to do summarization."
msgstr ""

#: ../docs/modules/chains/index_examples/summarize.ipynb:150004
msgid "This sections shows results of using the `map_reduce` Chain to do summarization."
msgstr ""

#: ../docs/modules/chains/index_examples/summarize.ipynb:230004
msgid "This sections shows results of using the `refine` Chain to do summarization."
msgstr ""

#: ../docs/modules/chains/index_examples/vector_db_qa.ipynb:10002
#: ../docs/modules/indexes/vectorstores/examples/deeplake.ipynb:120002
msgid "Retrieval Question/Answering"
msgstr ""

#: ../docs/modules/chains/index_examples/vector_db_qa.ipynb:10004
msgid "This example showcases question answering over an index."
msgstr ""

#: ../docs/modules/chains/index_examples/vector_db_qa.ipynb:60002
#: ../docs/modules/chains/index_examples/vector_db_qa_with_sources.ipynb:80002
msgid "Chain Type"
msgstr ""

#: ../docs/modules/chains/index_examples/vector_db_qa.ipynb:60003
msgid "You can easily specify different chain types to load and use in the RetrievalQA chain. For a more detailed walkthrough of these types, please see [this notebook](question_answering.ipynb)."
msgstr ""

#: ../docs/modules/chains/index_examples/vector_db_qa.ipynb:60005
#: ../docs/modules/chains/index_examples/vector_db_qa_with_sources.ipynb:80005
msgid "There are two ways to load different chain types. First, you can specify the chain type argument in the `from_chain_type` method. This allows you to pass in the name of the chain type you want to use. For example, in the below we change the chain type to `map_reduce`."
msgstr ""

#: ../docs/modules/chains/index_examples/vector_db_qa.ipynb:90002
msgid "The above way allows you to really simply change the chain_type, but it does provide a ton of flexibility over parameters to that chain type. If you want to control those parameters, you can load the chain directly (as you did in [this notebook](question_answering.ipynb)) and then pass that directly to the the RetrievalQA chain with the `combine_documents_chain` parameter. For example:"
msgstr ""

#: ../docs/modules/chains/index_examples/vector_db_qa.ipynb:120002
msgid "Custom Prompts"
msgstr ""

#: ../docs/modules/chains/index_examples/vector_db_qa.ipynb:120003
msgid "You can pass in custom prompts to do question answering. These prompts are the same prompts as you can pass into the [base question answering chain](./question_answering.ipynb)"
msgstr ""

#: ../docs/modules/chains/index_examples/vector_db_qa.ipynb:160003
msgid "Additionally, we can return the source documents used to answer the question by specifying an optional parameter when constructing the chain."
msgstr ""

#: ../docs/modules/chains/index_examples/vector_db_qa_with_sources.ipynb:10002
msgid "Retrieval Question Answering with Sources"
msgstr ""

#: ../docs/modules/chains/index_examples/vector_db_qa_with_sources.ipynb:10004
msgid "This notebook goes over how to do question-answering with sources over an Index. It does this by using the `RetrievalQAWithSourcesChain`, which does the lookup of the documents from an Index."
msgstr ""

#: ../docs/modules/chains/index_examples/vector_db_qa_with_sources.ipynb:80003
msgid "You can easily specify different chain types to load and use in the RetrievalQAWithSourcesChain chain. For a more detailed walkthrough of these types, please see [this notebook](qa_with_sources.ipynb)."
msgstr ""

#: ../docs/modules/chains/index_examples/vector_db_qa_with_sources.ipynb:110002
msgid "The above way allows you to really simply change the chain_type, but it does provide a ton of flexibility over parameters to that chain type. If you want to control those parameters, you can load the chain directly (as you did in [this notebook](qa_with_sources.ipynb)) and then pass that directly to the the RetrievalQAWithSourcesChain chain with the `combine_documents_chain` parameter. For example:"
msgstr ""

#: ../docs/modules/chains/index_examples/vector_db_text_generation.ipynb:10002
msgid "Vector DB Text Generation"
msgstr ""

#: ../docs/modules/chains/index_examples/vector_db_text_generation.ipynb:10004
msgid "This notebook walks through how to use LangChain for text generation over a vector index. This is useful if we want to generate text that is able to draw from a large body of custom text, for example, generating blog posts that have an understanding of previous blog posts written, or product tutorials that can refer to product documentation."
msgstr ""

#: ../docs/modules/chains/index_examples/vector_db_text_generation.ipynb:20004
msgid "First, we prepare the data. For this example, we fetch a documentation site that consists of markdown files hosted on Github and split them into small enough Documents."
msgstr ""

#: ../docs/modules/chains/index_examples/vector_db_text_generation.ipynb:50002
msgid "Set Up Vector DB"
msgstr ""

#: ../docs/modules/chains/index_examples/vector_db_text_generation.ipynb:50004
msgid "Now that we have the documentation content in chunks, let's put all this information in a vector index for easy retrieval."
msgstr ""

#: ../docs/modules/chains/index_examples/vector_db_text_generation.ipynb:70002
msgid "Set Up LLM Chain with Custom Prompt"
msgstr ""

#: ../docs/modules/chains/index_examples/vector_db_text_generation.ipynb:70004
msgid "Next, let's set up a simple LLM chain but give it a custom prompt for blog post generation. Note that the custom prompt is parameterized and takes two inputs: `context`, which will be the documents fetched from the vector search, and `topic`, which is given by the user."
msgstr ""

#: ../docs/modules/chains/index_examples/vector_db_text_generation.ipynb:90002
msgid "Generate Text"
msgstr ""

#: ../docs/modules/chains/index_examples/vector_db_text_generation.ipynb:90004
msgid "Finally, we write a function to apply our inputs to the chain. The function takes an input parameter `topic`. We find the documents in the vector index that correspond to that `topic`, and use them as additional context in our simple LLM chain."
msgstr ""

#: ../docs/modules/indexes.rst:2
msgid "Indexes"
msgstr ""

#: ../docs/modules/indexes.rst:5
msgid "`Conceptual Guide <https://docs.langchain.com/docs/components/indexing>`_"
msgstr ""

#: ../docs/modules/indexes.rst:8
msgid "Indexes refer to ways to structure documents so that LLMs can best interact with them. This module contains utility functions for working with documents, different types of indexes, and then examples for using those indexes in chains."
msgstr ""

#: ../docs/modules/indexes.rst:11
msgid "The most common way that indexes are used in chains is in a \"retrieval\" step. This step refers to taking a user's query and returning the most relevant documents. We draw this distinction because (1) an index can be used for other things besides retrieval, and (2) retrieval can use other logic besides an index to find relevant documents. We therefore have a concept of a \"Retriever\" interface - this is the interface that most chains work with."
msgstr ""

#: ../docs/modules/indexes.rst:16
msgid "Most of the time when we talk about indexes and retrieval we are talking about indexing and retrieving unstructured data (like text documents). For interacting with structured data (SQL tables, etc) or APIs, please see the corresponding use case sections for links to relevant functionality. The primary index and retrieval types supported by LangChain are currently centered around vector databases, and therefore a lot of the functionality we dive deep on those topics."
msgstr ""

#: ../docs/modules/indexes.rst:21
msgid "For an overview of everything related to this, please see the below notebook for getting started:"
msgstr ""

#: ../docs/modules/indexes.rst:28
msgid "We then provide a deep dive on the four main components."
msgstr ""

#: ../docs/modules/indexes.rst:30
msgid "**Document Loaders**"
msgstr ""

#: ../docs/modules/indexes.rst:32
msgid "How to load documents from a variety of sources."
msgstr ""

#: ../docs/modules/indexes.rst:34
msgid "**Text Splitters**"
msgstr ""

#: ../docs/modules/indexes.rst:36
msgid "An overview of the abstractions and implementions around splitting text."
msgstr ""

#: ../docs/modules/indexes.rst:39
msgid "**VectorStores**"
msgstr ""

#: ../docs/modules/indexes.rst:41
msgid "An overview of VectorStores and the many integrations LangChain provides."
msgstr ""

#: ../docs/modules/indexes.rst:44
msgid "**Retrievers**"
msgstr ""

#: ../docs/modules/indexes.rst:46
msgid "An overview of Retrievers and the implementations LangChain provides."
msgstr ""

#: ../docs/modules/indexes/document_loaders.rst:2
msgid "Document Loaders"
msgstr ""

#: ../docs/modules/indexes/document_loaders.rst:5
msgid "`Conceptual Guide <https://docs.langchain.com/docs/components/indexing/document-loaders>`_"
msgstr ""

#: ../docs/modules/indexes/document_loaders.rst:8
msgid "Combining language models with your own text data is a powerful way to differentiate them. The first step in doing this is to load the data into \"documents\" - a fancy way of say some pieces of text. This module is aimed at making this easy."
msgstr ""

#: ../docs/modules/indexes/document_loaders.rst:12
msgid "A primary driver of a lot of this is the `Unstructured <https://github.com/Unstructured-IO/unstructured>`_ python package. This package is a great way to transform all types of files - text, powerpoint, images, html, pdf, etc - into text data."
msgstr ""

#: ../docs/modules/indexes/document_loaders.rst:15
msgid "For detailed instructions on how to get set up with Unstructured, see installation guidelines `here <https://github.com/Unstructured-IO/unstructured#coffee-getting-started>`_."
msgstr ""

#: ../docs/modules/indexes/document_loaders.rst:17
msgid "The following document loaders are provided:"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/CoNLL-U.ipynb:10002
msgid "CoNLL-U"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/CoNLL-U.ipynb:10003
msgid "This is an example of how to load a file in [CoNLL-U](https://universaldependencies.org/format.html) format. The whole file is treated as one document. The example data (`conllu.conllu`) is based on one of the standard UD/CoNLL-U examples."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/airbyte_json.ipynb:10002
msgid "Airbyte JSON"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/airbyte_json.ipynb:10003
msgid "This covers how to load any source from Airbyte into a local JSON file that can be read in as a document"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/airbyte_json.ipynb:10005
msgid "Prereqs: Have docker desktop installed"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/airbyte_json.ipynb:10008
msgid "Steps:"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/airbyte_json.ipynb:10010
msgid "Clone Airbyte from GitHub - `git clone https://github.com/airbytehq/airbyte.git`"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/airbyte_json.ipynb:10012
msgid "Switch into Airbyte directory - `cd airbyte`"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/airbyte_json.ipynb:10014
msgid "Start Airbyte - `docker compose up`"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/airbyte_json.ipynb:10016
msgid "In your browser, just visit¬†http://localhost:8000. You will be asked for a username and password. By default, that's username¬†`airbyte`¬†and password¬†`password`."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/airbyte_json.ipynb:10018
msgid "Setup any source you wish."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/airbyte_json.ipynb:10020
msgid "Set destination as Local JSON, with specified destination path - lets say `/json_data`. Set up manual sync."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/airbyte_json.ipynb:10022
msgid "Run the connection!"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/airbyte_json.ipynb:10024
msgid "To see what files are create, you can navigate to: `file:///tmp/airbyte_local`"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/airbyte_json.ipynb:10026
msgid "Find your data and copy path. That path should be saved in the file variable below. It should start with `/tmp/airbyte_local`"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/apify_dataset.ipynb:10002
msgid "Apify Dataset"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/apify_dataset.ipynb:10004
msgid "This notebook shows how to load Apify datasets to LangChain."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/apify_dataset.ipynb:10006
msgid "[Apify Dataset](https://docs.apify.com/platform/storage/dataset) is a scaleable append-only storage with sequential access built for storing structured web scraping results, such as a list of products or Google SERPs, and then export them to various formats like JSON, CSV, or Excel. Datasets are mainly used to save results of [Apify Actors](https://apify.com/store)‚Äîserverless cloud programs for varius web scraping, crawling, and data extraction use cases."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/apify_dataset.ipynb:10008
#: ../docs/modules/indexes/document_loaders/examples/googledrive.ipynb:10005
#: ../docs/modules/indexes/document_loaders/examples/youtube.ipynb:100004
#: ../docs/modules/prompts/prompt_templates/examples/connecting_to_a_feature_store.ipynb:170002
msgid "Prerequisites"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/apify_dataset.ipynb:10010
msgid "You need to have an existing dataset on the Apify platform. If you don't have one, please first check out [this notebook](../../../agents/tools/examples/apify.ipynb) on how to use Apify to extract content from documentation, knowledge bases, help centers, or blogs."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/apify_dataset.ipynb:20002
msgid "First, import `ApifyDatasetLoader` into your source code:"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/apify_dataset.ipynb:40002
msgid "Then provide a function that maps Apify dataset record fields to LangChain `Document` format."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/apify_dataset.ipynb:40004
msgid "For example, if your dataset items are structured like this:"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/apify_dataset.ipynb:40013
msgid "The mapping function in the code below will convert them to LangChain `Document` format, so that you can use them further with any LLM model (e.g. for question answering)."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/apify_dataset.ipynb:70002
msgid "An example with question answering"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/apify_dataset.ipynb:70004
msgid "In this example, we use data from a dataset to answer a question."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/arxiv.ipynb:10002
msgid "Arxiv"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/arxiv.ipynb:10004
msgid "[arXiv](https://arxiv.org/) is an open-access archive for 2 million scholarly articles in the fields of physics, mathematics, computer science, quantitative biology, quantitative finance, statistics, electrical engineering and systems science, and economics."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/arxiv.ipynb:10006
msgid "This notebook shows how to load scientific articles from `Arxiv.org` into a document format that we can use downstream."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/arxiv.ipynb:20002
msgid "Installation"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/arxiv.ipynb:50002
msgid "Second, you need to install `PyMuPDF` python package which transform PDF files from the `arxiv.org` site into the text fromat."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/arxiv.ipynb:80002
msgid "`ArxivLoader` has these arguments:"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/arxiv.ipynb:80003
msgid "`query`: free text which used to find documents in the Arxiv"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/arxiv.ipynb:80004
msgid "optional `load_max_docs`: default=100. Use it to limit number of downloaded documents. It takes time to download all 100 documents, so use a small number for experiments."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/arxiv.ipynb:80005
msgid "optional `load_all_available_meta`: default=False. By defaul only the most important fields downloaded: `Published` (date when document was published/last updated), `Title`, `Authors`, `Summary`. If True, other fields also downloaded."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/azlyrics.ipynb:10002
msgid "AZLyrics"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/azlyrics.ipynb:10003
msgid "This covers how to load AZLyrics webpages into a document format that we can use downstream."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/azure_blob_storage_container.ipynb:10002
msgid "Azure Blob Storage Container"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/azure_blob_storage_container.ipynb:10004
msgid "This covers how to load document objects from a container on Azure Blob Storage."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/azure_blob_storage_container.ipynb:60002
#: ../docs/modules/indexes/document_loaders/examples/gcs_directory.ipynb:60002
#: ../docs/modules/indexes/document_loaders/examples/s3_directory.ipynb:60002
msgid "Specifying a prefix"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/azure_blob_storage_container.ipynb:60003
#: ../docs/modules/indexes/document_loaders/examples/gcs_directory.ipynb:60003
#: ../docs/modules/indexes/document_loaders/examples/s3_directory.ipynb:60003
msgid "You can also specify a prefix for more finegrained control over what files to load."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/azure_blob_storage_file.ipynb:10002
msgid "Azure Blob Storage File"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/azure_blob_storage_file.ipynb:10004
msgid "This covers how to load document objects from a Azure Blob Storage file."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/bigquery.ipynb:10002
msgid "BigQuery Loader"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/bigquery.ipynb:10004
msgid "Load a BigQuery query with one document per row."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/bigquery.ipynb:40002
msgid "Basic Usage"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/bigquery.ipynb:70002
#: ../docs/modules/indexes/document_loaders/examples/duckdb.ipynb:60002
msgid "Specifying Which Columns are Content vs Metadata"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/bigquery.ipynb:100002
#: ../docs/modules/indexes/document_loaders/examples/duckdb.ipynb:90002
msgid "Adding Source to Metadata"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/bilibili.ipynb:10002
msgid "Bilibili"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/bilibili.ipynb:10004
msgid "This loader utilizes the `bilibili-api` to fetch the text transcript from Bilibili, one of the most beloved long-form video sites in China."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/bilibili.ipynb:10006
msgid "With this BiliBiliLoader, users can easily obtain the transcript of their desired video content on the platform."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/blackboard.ipynb:10002
msgid "Blackboard"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/blackboard.ipynb:10004
msgid "This covers how to load data from a Blackboard Learn instance."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/blockchain.ipynb:10002
msgid "Blockchain Document Loader"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/blockchain.ipynb:20002
msgid "Overview"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/blockchain.ipynb:30002
msgid "The intention of this notebook is to provide a means of testing functionality in the Langchain Document Loader for Blockchain."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/blockchain.ipynb:30004
msgid "Initially this Loader supports:"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/blockchain.ipynb:30007
msgid "Ethereum Maninnet, Ethereum Testnet, Polgyon Mainnet, Polygon Testnet (default is eth-mainnet)"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/blockchain.ipynb:30008
msgid "Alchemy's getNFTsForCollection API"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/blockchain.ipynb:30010
msgid "It can be extended if the community finds value in this loader.  Specifically:"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/blockchain.ipynb:30012
msgid "Additional APIs can be added (e.g. Tranction-related APIs)"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/blockchain.ipynb:30014
msgid "To run this notebook, the user will need:"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/blockchain.ipynb:30017
msgid "An OpenAI key (for OpenAI models)"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/blockchain.ipynb:30018
msgid "A free [Alchemy API Key](https://www.alchemy.com/)"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/blockchain.ipynb:40002
#: ../docs/modules/indexes/document_loaders/examples/notiondb.ipynb:10011
#: ../docs/modules/indexes/document_loaders/examples/url.ipynb:60008
#: ../docs/modules/indexes/document_loaders/examples/url.ipynb:110008
#: ../docs/modules/memory/examples/motorhead_memory.ipynb:10005
#: ../docs/modules/models/llms/integrations/replicate.ipynb:20002
msgid "Setup"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/blockchain.ipynb:80002
msgid "Create a Blockchain Document Loader"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/blockchain.ipynb:90002
msgid "Option 1: Ethereum Mainnet (default BlockchainType)"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/blockchain.ipynb:110002
msgid "Option 2: Polygon Mainnet"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/blockchain.ipynb:130002
msgid "(Optional) Using the Blockchain Document Loader"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/blockchain.ipynb:140002
msgid "Setup Splitter and Index"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/blockchain.ipynb:190002
msgid "Setup Models and Chains"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/blockchain.ipynb:220002
msgid "Retrieval Chain"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/chatgpt_loader.ipynb:10002
msgid "ChatGPT Data Loader"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/chatgpt_loader.ipynb:10004
msgid "This notebook covers how to load `conversations.json` from your ChatGPT data export folder."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/chatgpt_loader.ipynb:10006
msgid "You can get your data export by email by going to: https://chat.openai.com/ -> (Profile) - Settings -> Export data -> Confirm export."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/college_confidential.ipynb:10002
msgid "College Confidential"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/college_confidential.ipynb:10003
msgid "This covers how to load College Confidential webpages into a document format that we can use downstream."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/confluence.ipynb:10002
msgid "Confluence"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/confluence.ipynb:10004
msgid "A loader for Confluence pages."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/confluence.ipynb:10007
msgid "This currently supports both username/api_key and Oauth2 login."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/confluence.ipynb:10010
msgid "Specify a list page_ids and/or space_key to load in the corresponding pages into Document objects, if both are specified the union of both sets will be returned."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/confluence.ipynb:10013
msgid "You can also specify a boolean `include_attachments` to include attachments, this is set to False by default, if set to True all attachments will be downloaded and ConfluenceReader will extract the text from the attachments and add it to the Document object. Currently supported attachment types are: PDF, PNG, JPEG/JPG, SVG, Word and Excel."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/confluence.ipynb:10015
msgid "Hint: space_key and page_id can both be found in the URL of a page in Confluence - https://yoursite.atlassian.com/wiki/spaces/<space_key>/pages/<page_id>"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/copypaste.ipynb:10002
msgid "Copy Paste"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/copypaste.ipynb:10004
msgid "This notebook covers how to load a document object from something you just want to copy and paste. In this case, you don't even need to use a DocumentLoader, but rather can just construct the Document directly."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/copypaste.ipynb:50002
msgid "Metadata"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/copypaste.ipynb:50003
msgid "If you want to add metadata about the where you got this piece of text, you easily can with the metadata key."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/csv.ipynb:10002
msgid "CSV Loader"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/csv.ipynb:10004
msgid "Load csv files with a single row per document."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/csv.ipynb:50002
msgid "Customizing the csv parsing and loading"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/csv.ipynb:50004
msgid "See the [csv module](https://docs.python.org/3/library/csv.html) documentation for more information of what csv args are supported."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/csv.ipynb:80002
msgid "Specify a column to be used identify the document source"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/csv.ipynb:80004
msgid "Use the `source_column` argument to specify a column to be set as the source for the document created from each row. Otherwise `file_path` will be used as the source for all documents created from the csv file."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/csv.ipynb:80006
msgid "This is useful when using documents loaded from CSV files for chains that answer questions using sources."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/dataframe.ipynb:10002
msgid "DataFrame Loader"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/dataframe.ipynb:10004
msgid "This notebook goes over how to load data from a pandas dataframe"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/diffbot.ipynb:10002
msgid "Diffbot"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/diffbot.ipynb:10004
msgid "This covers how to extract HTML documents from a list of URLs using the [Diffbot extract API](https://www.diffbot.com/products/extract/), into a document format that we can use downstream."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/diffbot.ipynb:30002
msgid "The Diffbot Extract API Requires an API token. Once you have it, you can extract the data from the previous URLs"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/diffbot.ipynb:50002
msgid "With the `.load()` method, you can see the documents loaded"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/directory_loader.ipynb:10002
msgid "Directory Loader"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/directory_loader.ipynb:10003
msgid "This covers how to use the DirectoryLoader to load all documents in a directory. Under the hood, by default this uses the [UnstructuredLoader](./unstructured_file.ipynb)"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/directory_loader.ipynb:30002
msgid "We can use the `glob` parameter to control which files to load. Note that here it doesn't load the `.rst` file or the `.ipynb` files."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/directory_loader.ipynb:70002
msgid "Show a progress bar"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/directory_loader.ipynb:80002
msgid "By default a progress bar will not be shown. To show a progress bar, install the `tqdm` library (e.g. `pip install tqdm`), and set the `show_progress` parameter to `True`."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/directory_loader.ipynb:100002
msgid "Change loader class"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/directory_loader.ipynb:100003
msgid "By default this uses the UnstructuredLoader class. However, you can change up the type of loader pretty easily."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/directory_loader.ipynb:150002
msgid "If you need to load Python source code files, use the `PythonLoader`."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/discord_loader.ipynb:10002
msgid "Discord"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/discord_loader.ipynb:10004
msgid "You can follow the below steps to download your Discord data:"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/discord_loader.ipynb:10006
msgid "Go to your **User Settings**"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/discord_loader.ipynb:10007
msgid "Then go to **Privacy and Safety**"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/discord_loader.ipynb:10008
msgid "Head over to the **Request all of my Data** and click on **Request Data** button"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/discord_loader.ipynb:10010
msgid "It might take 30 days for you to receive your data. You'll receive an email at the address which is registered with Discord. That email will have a download button using which you would be able to download your personal Discord data."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/duckdb.ipynb:10002
msgid "DuckDB Loader"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/duckdb.ipynb:10004
msgid "Load a DuckDB query with one document per row."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/email.ipynb:10002
msgid "Email"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/email.ipynb:10004
msgid "This notebook shows how to load email (`.eml`) and Microsoft Outlook (`.msg`) files."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/email.ipynb:20002
#: ../docs/modules/indexes/document_loaders/examples/image.ipynb:20002
#: ../docs/modules/indexes/document_loaders/examples/pdf.ipynb:70002
msgid "Using Unstructured"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/email.ipynb:70002
#: ../docs/modules/indexes/document_loaders/examples/epub.ipynb:50002
#: ../docs/modules/indexes/document_loaders/examples/image.ipynb:70002
#: ../docs/modules/indexes/document_loaders/examples/markdown.ipynb:60002
#: ../docs/modules/indexes/document_loaders/examples/pdf.ipynb:110002
#: ../docs/modules/indexes/document_loaders/examples/powerpoint.ipynb:60002
#: ../docs/modules/indexes/document_loaders/examples/unstructured_file.ipynb:90002
#: ../docs/modules/indexes/document_loaders/examples/word_document.ipynb:60002
msgid "Retain Elements"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/email.ipynb:70004
#: ../docs/modules/indexes/document_loaders/examples/epub.ipynb:50004
#: ../docs/modules/indexes/document_loaders/examples/image.ipynb:70004
#: ../docs/modules/indexes/document_loaders/examples/markdown.ipynb:60004
#: ../docs/modules/indexes/document_loaders/examples/pdf.ipynb:110004
#: ../docs/modules/indexes/document_loaders/examples/powerpoint.ipynb:60004
#: ../docs/modules/indexes/document_loaders/examples/unstructured_file.ipynb:90004
#: ../docs/modules/indexes/document_loaders/examples/word_document.ipynb:60004
msgid "Under the hood, Unstructured creates different \"elements\" for different chunks of text. By default we combine those together, but you can easily keep that separation by specifying `mode=\"elements\"`."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/email.ipynb:110002
msgid "Using OutlookMessageLoader"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/epub.ipynb:10002
msgid "EPubs"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/epub.ipynb:10004
msgid "This covers how to load `.epub` documents into a document format that we can use downstream. You'll need to install the [`pandocs`](https://pandoc.org/installing.html) package for this loader to work."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/evernote.ipynb:10002
msgid "EverNote"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/evernote.ipynb:10004
msgid "How to load EverNote file from disk."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/example_data/fake-content.html:1
msgid "<!DOCTYPE html> <html> <head>"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/example_data/fake-content.html:4
msgid "<title>Test Title</title>"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/example_data/fake-content.html:5
msgid "</head> <body>"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/example_data/fake-content.html:8
msgid "<h1>My First Heading</h1> <p>My first paragraph.</p>"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/example_data/fake-content.html:11
msgid "</body> </html>"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/example_data/notebook.ipynb:10002
#: ../docs/modules/indexes/document_loaders/examples/notebook.ipynb:10002
msgid "Notebook"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/example_data/notebook.ipynb:10004
#: ../docs/modules/indexes/document_loaders/examples/notebook.ipynb:10004
msgid "This notebook covers how to load data from an .ipynb notebook into a format suitable by LangChain."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/example_data/notebook.ipynb:40002
#: ../docs/modules/indexes/document_loaders/examples/notebook.ipynb:40002
msgid "`NotebookLoader.load()` loads the `.ipynb` notebook file into a `Document` object."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/example_data/notebook.ipynb:40004
#: ../docs/modules/indexes/document_loaders/examples/notebook.ipynb:40004
msgid "**Parameters**:"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/example_data/notebook.ipynb:40006
#: ../docs/modules/indexes/document_loaders/examples/notebook.ipynb:40006
msgid "`include_outputs` (bool): whether to include cell outputs in the resulting document (default is False)."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/example_data/notebook.ipynb:40007
#: ../docs/modules/indexes/document_loaders/examples/notebook.ipynb:40007
msgid "`max_output_length` (int): the maximum number of characters to include from each cell output (default is 10)."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/example_data/notebook.ipynb:40008
#: ../docs/modules/indexes/document_loaders/examples/notebook.ipynb:40008
msgid "`remove_newline` (bool): whether to remove newline characters from the cell sources and outputs (default is False)."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/example_data/notebook.ipynb:40009
#: ../docs/modules/indexes/document_loaders/examples/notebook.ipynb:40009
msgid "`traceback` (bool): whether to include full traceback (default is False)."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/facebook_chat.ipynb:10002
msgid "Facebook Chat"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/facebook_chat.ipynb:10004
msgid "This notebook covers how to load data from the Facebook Chats into a format that can be ingested into LangChain."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/figma.ipynb:10002
msgid "Figma"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/figma.ipynb:10004
msgid "This notebook covers how to load data from the Figma REST API into a format that can be ingested into LangChain, along with example usage for code generation."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/figma.ipynb:30002
msgid "The Figma API Requires an access token, node_ids, and a file key."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/figma.ipynb:30004
msgid "The file key can be pulled from the URL.  https://www.figma.com/file/{filekey}/sampleFilename"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/figma.ipynb:30006
msgid "Node IDs are also available in the URL. Click on anything and look for the '?node-id={node_id}' param."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/figma.ipynb:30008
msgid "Access token instructions are in the Figma help center article: https://help.figma.com/hc/en-us/articles/8085703771159-Manage-personal-access-tokens"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/figma.ipynb:80002
msgid "Returns the following in `response.content`:"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/gcs_directory.ipynb:10002
msgid "GCS Directory"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/gcs_directory.ipynb:10004
msgid "This covers how to load document objects from an Google Cloud Storage (GCS) directory."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/gcs_file.ipynb:10002
msgid "GCS File Storage"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/gcs_file.ipynb:10004
msgid "This covers how to load document objects from an Google Cloud Storage (GCS) file object."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/git.ipynb:10002
msgid "Git"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/git.ipynb:10004
msgid "This notebook shows how to load text files from Git repository."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/git.ipynb:20002
msgid "Load existing repository from disk"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/git.ipynb:90002
msgid "Clone repository from url"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/git.ipynb:140002
msgid "Filtering files to load"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/gitbook.ipynb:10002
msgid "GitBook"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/gitbook.ipynb:10003
msgid "How to pull page data from any GitBook."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/gitbook.ipynb:40002
msgid "Load from single GitBook page"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/gitbook.ipynb:70002
msgid "Load from all paths in a given GitBook"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/gitbook.ipynb:70003
msgid "For this to work, the GitbookLoader needs to be initialized with the root path (`https://docs.gitbook.com` in this example) and have `load_all_paths` set to `True`."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/googledrive.ipynb:10002
msgid "Google Drive"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/googledrive.ipynb:10003
msgid "This notebook covers how to load documents from Google Drive. Currently, only Google Docs are supported."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/googledrive.ipynb:10007
#: ../docs/modules/indexes/document_loaders/examples/youtube.ipynb:100006
msgid "Create a Google Cloud project or use an existing project"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/googledrive.ipynb:10008
msgid "Enable the [Google Drive API](https://console.cloud.google.com/flows/enableapi?apiid=drive.googleapis.com)"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/googledrive.ipynb:10009
#: ../docs/modules/indexes/document_loaders/examples/youtube.ipynb:100008
msgid "[Authorize credentials for desktop app](https://developers.google.com/drive/api/quickstart/python#authorize_credentials_for_a_desktop_application)"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/googledrive.ipynb:10010
msgid "`pip install --upgrade google-api-python-client google-auth-httplib2 google-auth-oauthlib`"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/googledrive.ipynb:10012
#: ../docs/modules/indexes/document_loaders/examples/youtube.ipynb:100011
msgid "üßë Instructions for ingesting your Google Docs data"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/googledrive.ipynb:10013
msgid "By default, the `GoogleDriveLoader` expects the `credentials.json` file to be `~/.credentials/credentials.json`, but this is configurable using the `credentials_path` keyword argument. Same thing with `token.json` - `token_path`. Note that `token.json` will be created automatically the first time you use the loader."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/googledrive.ipynb:10015
msgid "`GoogleDriveLoader` can load from a list of Google Docs document ids or a folder id. You can obtain your folder and document id from the URL:"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/googledrive.ipynb:10016
msgid "Folder: https://drive.google.com/drive/u/0/folders/1yucgL9WGgWZdM1TOuKkeghlPizuzMYb5 -> folder id is `\"1yucgL9WGgWZdM1TOuKkeghlPizuzMYb5\"`"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/googledrive.ipynb:10017
msgid "Document: https://docs.google.com/document/d/1bfaMQ18_i56204VaQDVeAFpqEijJTgvurupdEDiaUQw/edit -> document id is `\"1bfaMQ18_i56204VaQDVeAFpqEijJTgvurupdEDiaUQw\"`"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/gutenberg.ipynb:10002
msgid "Gutenberg"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/gutenberg.ipynb:10004
msgid "This covers how to load links to Gutenberg e-books into a document format that we can use downstream."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/hn.ipynb:10002
msgid "Hacker News"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/hn.ipynb:10003
msgid "How to pull page data and comments from Hacker News"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/html.ipynb:10002
msgid "HTML"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/html.ipynb:10004
msgid "This covers how to load HTML documents into a document format that we can use downstream."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/html.ipynb:60002
msgid "Loading HTML with BeautifulSoup4"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/html.ipynb:60004
msgid "We can also use BeautifulSoup4 to load HTML documents using the `BSHTMLLoader`.  This will extract the text from the html into `page_content`, and the page title as `title` into `metadata`."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/hugging_face_dataset.ipynb:10002
msgid "HuggingFace dataset loader"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/hugging_face_dataset.ipynb:10004
msgid "This notebook shows how to load Hugging Face Hub datasets to LangChain."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/hugging_face_dataset.ipynb:10006
msgid "The Hugging Face Hub hosts a large number of community-curated datasets for a diverse range of tasks such as translation, automatic speech recognition, and image classification."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/hugging_face_dataset.ipynb:60002
#: ../docs/modules/models/llms/integrations/sagemaker.ipynb:50002
msgid "Example"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/hugging_face_dataset.ipynb:60003
msgid "In this example, we use data from a dataset to answer a question"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/ifixit.ipynb:10002
msgid "iFixit"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/ifixit.ipynb:10004
msgid "[iFixit](https://www.ifixit.com) is the largest, open repair community on the web. The site contains nearly 100k repair manuals, 200k Questions & Answers on 42k devices, and all the data is licensed under CC-BY-NC-SA 3.0."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/ifixit.ipynb:10006
msgid "This loader will allow you to download the text of a repair guide, text of Q&A's and wikis from devices on iFixit using their open APIs.  It's incredibly useful for context related to technical documents and answers to questions about devices in the corpus of data on iFixit."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/ifixit.ipynb:100002
msgid "Searching iFixit using /suggest"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/ifixit.ipynb:100004
msgid "If you're looking for a more general way to search iFixit based on a keyword or phrase, the /suggest endpoint will return content related to the search term, then the loader will load the content from each of the suggested items and prep and return the documents."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/image.ipynb:10002
msgid "Images"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/image.ipynb:10004
msgid "This covers how to load images such as JPGs PNGs into a document format that we can use downstream."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/image_captions.ipynb:10002
msgid "Image captions"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/image_captions.ipynb:10003
msgid "This notebook shows how to use the ImageCaptionLoader tutorial to generate a query-able index of image captions"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/image_captions.ipynb:30002
msgid "Prepare a list of image urls from Wikimedia"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/image_captions.ipynb:50002
msgid "Create the loader"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/image_captions.ipynb:80002
msgid "Create the index"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/image_captions.ipynb:100002
#: ../docs/modules/indexes/retrievers/examples/databerry.ipynb:20002
#: ../docs/modules/indexes/retrievers/examples/metal.ipynb:60002
msgid "Query"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/imsdb.ipynb:10002
msgid "IMSDb"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/imsdb.ipynb:10004
msgid "This covers how to load IMSDb webpages into a document format that we can use downstream."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/markdown.ipynb:10002
msgid "Markdown"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/markdown.ipynb:10004
msgid "This covers how to load markdown documents into a document format that we can use downstream."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/notion.ipynb:10002
msgid "Notion"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/notion.ipynb:10003
msgid "This notebook covers how to load documents from a Notion database dump."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/notion.ipynb:10005
msgid "In order to get this notion dump, follow these instructions:"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/notion.ipynb:10007
#: ../docs/modules/indexes/document_loaders/examples/roam.ipynb:10005
#: ../docs/modules/indexes/document_loaders/examples/slack_directory.ipynb:10008
msgid "üßë Instructions for ingesting your own dataset"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/notion.ipynb:10009
msgid "Export your dataset from Notion. You can do this by clicking on the three dots in the upper right hand corner and then clicking `Export`."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/notion.ipynb:10011
#: ../docs/modules/indexes/document_loaders/examples/roam.ipynb:10009
msgid "When exporting, make sure to select the `Markdown & CSV` format option."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/notion.ipynb:10013
#: ../docs/modules/indexes/document_loaders/examples/roam.ipynb:10011
msgid "This will produce a `.zip` file in your Downloads folder. Move the `.zip` file into this repository."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/notion.ipynb:10015
#: ../docs/modules/indexes/document_loaders/examples/roam.ipynb:10013
msgid "Run the following command to unzip the zip file (replace the `Export...` with your own file name as needed)."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/notion.ipynb:10021
msgid "Run the following command to ingest the data."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/notiondb.ipynb:10002
msgid "Notion DB Loader"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/notiondb.ipynb:10004
msgid "NotionDBLoader is a Python class for loading content from a Notion database. It retrieves pages from the database, reads their content, and returns a list of Document objects."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/notiondb.ipynb:10006
msgid "Requirements"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/notiondb.ipynb:10008
msgid "A Notion Database"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/notiondb.ipynb:10009
msgid "Notion Integration Token"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/notiondb.ipynb:10013
msgid "1. Create a Notion Table Database"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/notiondb.ipynb:10014
msgid "Create a new table database in Notion. You can add any column to the database and they will be treated as metadata. For example you can add the following columns:"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/notiondb.ipynb:10016
msgid "Title: set Title as the default property."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/notiondb.ipynb:10017
msgid "Categories: A Multi-select property to store categories associated with the page."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/notiondb.ipynb:10018
msgid "Keywords: A Multi-select property to store keywords associated with the page."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/notiondb.ipynb:10020
msgid "Add your content to the body of each page in the database. The NotionDBLoader will extract the content and metadata from these pages."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/notiondb.ipynb:10022
msgid "2. Create a Notion Integration"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/notiondb.ipynb:10023
msgid "To create a Notion Integration, follow these steps:"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/notiondb.ipynb:10025
msgid "Visit the (Notion Developers)[https://www.notion.com/my-integrations] page and log in with your Notion account."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/notiondb.ipynb:10026
#: ../docs/modules/indexes/document_loaders/examples/notiondb.ipynb:10037
msgid "Click on the \"+ New integration\" button."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/notiondb.ipynb:10027
msgid "Give your integration a name and choose the workspace where your database is located."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/notiondb.ipynb:10028
msgid "Select the require capabilities, this extension only need the Read content capability"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/notiondb.ipynb:10029
msgid "Click the \"Submit\" button to create the integration. Once the integration is created, you'll be provided with an Integration Token (API key). Copy this token and keep it safe, as you'll need it to use the NotionDBLoader."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/notiondb.ipynb:10032
msgid "3. Connect the Integration to the Database"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/notiondb.ipynb:10033
msgid "To connect your integration to the database, follow these steps:"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/notiondb.ipynb:10035
#: ../docs/modules/indexes/document_loaders/examples/notiondb.ipynb:10045
msgid "Open your database in Notion."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/notiondb.ipynb:10036
#: ../docs/modules/indexes/document_loaders/examples/notiondb.ipynb:10046
msgid "Click on the three-dot menu icon in the top right corner of the database view."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/notiondb.ipynb:10038
msgid "Find your integration, you may need to start typing its name in the search box."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/notiondb.ipynb:10039
msgid "Click on the \"Connect\" button to connect the integration to the database."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/notiondb.ipynb:10042
msgid "4. Get the Database ID"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/notiondb.ipynb:10043
msgid "To get the database ID, follow these steps:"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/notiondb.ipynb:10047
msgid "Select \"Copy link\" from the menu to copy the database URL to your clipboard."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/notiondb.ipynb:10048
msgid "The database ID is the long string of alphanumeric characters found in the URL. It typically looks like this: https://www.notion.so/username/8935f9d140a04f95a872520c4f123456?v=.... In this example, the database ID is 8935f9d140a04f95a872520c4f123456."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/notiondb.ipynb:10050
msgid "With the database properly set up and the integration token and database ID in hand, you can now use the NotionDBLoader code to load content and metadata from your Notion database."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/notiondb.ipynb:10052
#: ../docs/modules/memory/how_to_guides.rst:18
msgid "Usage"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/notiondb.ipynb:10053
msgid "NotionDBLoader is part of the langchain package's document loaders. You can use it as follows:"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/obsidian.ipynb:10002
msgid "Obsidian"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/obsidian.ipynb:10003
msgid "This notebook covers how to load documents from an Obsidian database."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/obsidian.ipynb:10005
msgid "Since Obsidian is just stored on disk as a folder of Markdown files, the loader just takes a path to this directory."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/obsidian.ipynb:10007
msgid "Obsidian files also sometimes contain [metadata](https://help.obsidian.md/Editing+and+formatting/Metadata) which is a YAML block at the top of the file. These values will be added to the document's metadata. (`ObsidianLoader` can also be passed a `collect_metadata=False` argument to disable this behavior.)"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/pdf.ipynb:10002
msgid "PDF"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/pdf.ipynb:10004
msgid "This covers how to load pdfs into a document format that we can use downstream."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/pdf.ipynb:20002
msgid "Using PyPDF"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/pdf.ipynb:20004
msgid "Load PDF using `pypdf` into array of documents, where each document contains the page content and metadata with `page` number."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/pdf.ipynb:50002
msgid "An advantage of this approach is that documents can be retrieved with page numbers."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/pdf.ipynb:150002
msgid "Fetching remote PDFs using Unstructured"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/pdf.ipynb:150004
msgid "This covers how to load online pdfs into a document format that we can use downstream. This can be used for various online pdf sites such as https://open.umn.edu/opentextbooks/textbooks/ and https://arxiv.org/archive/"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/pdf.ipynb:150006
msgid "Note: all other pdf loaders can also be used to fetch remote PDFs, but `OnlinePDFLoader` is a legacy function, and works specifically with `UnstructuredPDFLoader`."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/pdf.ipynb:210002
msgid "Using PDFMiner"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/pdf.ipynb:250002
msgid "Using PDFMiner to generate HTML text"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/pdf.ipynb:260002
msgid "This can be helpful for chunking texts semantically into sections as the output html content can be parsed via `BeautifulSoup` to get more structured and rich information about font size, page numbers, pdf headers/footers, etc."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/pdf.ipynb:340002
msgid "Using PyMuPDF"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/pdf.ipynb:340004
msgid "This is the fastest of the PDF parsing options, and contains detailed metadata about the PDF and its pages, as well as returns one document per page."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/pdf.ipynb:390002
msgid "Additionally, you can pass along any of the options from the [PyMuPDF documentation](https://pymupdf.readthedocs.io/en/latest/app1.html#plain-text/) as keyword arguments in the `load` call, and it will be pass along to the `get_text()` call."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/powerpoint.ipynb:10002
msgid "PowerPoint"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/powerpoint.ipynb:10004
msgid "This covers how to load PowerPoint documents into a document format that we can use downstream."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/readthedocs_documentation.ipynb:10002
msgid "ReadTheDocs Documentation"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/readthedocs_documentation.ipynb:10003
msgid "This notebook covers how to load content from html that was generated as part of a Read-The-Docs build."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/readthedocs_documentation.ipynb:10005
msgid "For an example of this in the wild, see [here](https://github.com/hwchase17/chat-langchain)."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/readthedocs_documentation.ipynb:10007
msgid "This assumes that the html has already been scraped into a folder. This can be done by uncommenting and running the following command"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/roam.ipynb:10002
msgid "Roam"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/roam.ipynb:10003
msgid "This notebook covers how to load documents from a Roam database. This takes a lot of inspiration from the example repo [here](https://github.com/JimmyLv/roam-qa)."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/roam.ipynb:10007
msgid "Export your dataset from Roam Research. You can do this by clicking on the three dots in the upper right hand corner and then clicking `Export`."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/s3_directory.ipynb:10002
msgid "s3 Directory"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/s3_directory.ipynb:10004
msgid "This covers how to load document objects from an s3 directory object."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/s3_file.ipynb:10002
msgid "s3 File"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/s3_file.ipynb:10004
msgid "This covers how to load document objects from an s3 file object."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/sitemap.ipynb:10002
msgid "Sitemap Loader"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/sitemap.ipynb:10004
msgid "Extends from the [WebBaseLoader](), this will load a sitemap from a given URL, and then scrape and load all the pages in the sitemap, returning each page as a document."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/sitemap.ipynb:10006
msgid "The scraping is done concurrently, using `WebBaseLoader`.  There are reasonable limits to concurrent requests, defaulting to 2 per second.  If you aren't concerned about being a good citizen, or you control the server you are scraping and don't care about load, you can change the `requests_per_second` parameter to increase the max concurrent requests.  Note, while this will speed up the scraping process, but may cause the server to block you.  Be careful!"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/sitemap.ipynb:70002
msgid "Filtering sitemap URLs"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/sitemap.ipynb:70004
msgid "Sitemaps can be massive files, with thousands of urls.  Often you don't need every single one of them.  You can filter the urls by passing a list of strings or regex patterns to the `url_filter` parameter.  Only urls that match one of the patterns will be loaded."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/slack_directory.ipynb:10002
msgid "Slack (Local Exported Zipfile)"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/slack_directory.ipynb:10004
msgid "This notebook covers how to load documents from a Zipfile generated from a Slack export."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/slack_directory.ipynb:10006
msgid "In order to get this Slack export, follow these instructions:"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/slack_directory.ipynb:10010
msgid "Export your Slack data. You can do this by going to your Workspace Management page and clicking the Import/Export option ({your_slack_domain}.slack.com/services/export). Then, choose the right date range and click `Start export`. Slack will send you an email and a DM when the export is ready."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/slack_directory.ipynb:10012
msgid "The download will produce a `.zip` file in your Downloads folder (or wherever your downloads can be found, depending on your OS configuration)."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/slack_directory.ipynb:10014
msgid "Copy the path to the `.zip` file, and assign it as `LOCAL_ZIPFILE` below."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/srt.ipynb:10002
msgid "Subtitle Files"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/srt.ipynb:10003
msgid "How to load data from subtitle (`.srt`) files"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/telegram.ipynb:10002
msgid "Telegram"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/telegram.ipynb:10004
msgid "This notebook covers how to load data from Telegram into a format that can be ingested into LangChain."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/twitter.ipynb:10002
msgid "Twitter"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/twitter.ipynb:10004
msgid "This loader fetches the text from the Tweets of a list of Twitter users, using the `tweepy` Python package. You must initialize the loader with your Twitter API token, and you need to pass in the Twitter username you want to extract."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/unstructured_file.ipynb:10002
msgid "Unstructured File Loader"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/unstructured_file.ipynb:10003
msgid "This notebook covers how to use Unstructured to load files of many types. Unstructured currently supports loading of text files, powerpoints, html, pdfs, images, and more."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/unstructured_file.ipynb:130002
msgid "Define a Partitioning Strategy"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/unstructured_file.ipynb:130004
msgid "Unstructured document loader allow users to pass in a `strategy` parameter that lets `unstructured` know how to partition the document. Currently supported strategies are `\"hi_res\"` (the default) and `\"fast\"`. Hi res partitioning strategies are more accurate, but take longer to process. Fast strategies partition the document more quickly, but trade-off accuracy. Not all document types have separate hi res and fast partitioning strategies. For those document types, the `strategy` kwarg is ignored. In some cases, the high res strategy will fallback to fast if there is a dependency missing (i.e. a model for document partitioning). You can see how to apply a strategy to an `UnstructuredFileLoader` below."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/unstructured_file.ipynb:180002
msgid "PDF Example"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/unstructured_file.ipynb:180004
msgid "Processing PDF documents works exactly the same way. Unstructured detects the file type and extracts the same types of `elements`."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/url.ipynb:10002
msgid "URL"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/url.ipynb:10004
msgid "This covers how to load HTML documents from a list of URLs into a document format that we can use downstream."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/url.ipynb:60002
msgid "Selenium URL Loader"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/url.ipynb:60004
msgid "This covers how to load HTML documents from a list of URLs using the `SeleniumURLLoader`."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/url.ipynb:60006
msgid "Using selenium allows us to load pages that require JavaScript to render."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/url.ipynb:60010
msgid "To use the `SeleniumURLLoader`, you will need to install `selenium` and `unstructured`."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/url.ipynb:110002
msgid "Playwright URL Loader"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/url.ipynb:110004
msgid "This covers how to load HTML documents from a list of URLs using the `PlaywrightURLLoader`."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/url.ipynb:110006
msgid "As in the Selenium case, Playwright allows us to load pages that need JavaScript to render."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/url.ipynb:110010
msgid "To use the `PlaywrightURLLoader`, you will need to install `playwright` and `unstructured`. Additionally, you will need to install the Playwright Chromium browser:"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/web_base.ipynb:10002
msgid "Web Base"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/web_base.ipynb:10004
msgid "This covers how to load all text from webpages into a document format that we can use downstream. For more custom logic for loading webpages look at some child class examples such as IMSDbLoader, AZLyricsLoader, and CollegeConfidentialLoader"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/web_base.ipynb:70002
msgid "Loading multiple webpages"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/web_base.ipynb:70004
msgid "You can also load multiple webpages at once by passing in a list of urls to the loader. This will return a list of documents in the same order as the urls passed in."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/web_base.ipynb:90002
msgid "Load multiple urls concurrently"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/web_base.ipynb:90004
msgid "You can speed up the scraping process by scraping and parsing multiple urls concurrently."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/web_base.ipynb:90006
msgid "There are reasonable limits to concurrent requests, defaulting to 2 per second.  If you aren't concerned about being a good citizen, or you control the server you are scraping and don't care about load, you can change the `requests_per_second` parameter to increase the max concurrent requests.  Note, while this will speed up the scraping process, but may cause the server to block you.  Be careful!"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/web_base.ipynb:120002
msgid "Loading a xml file, or using a different BeautifulSoup parser"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/web_base.ipynb:120004
msgid "You can also look at `SitemapLoader` for an example of how to load a sitemap file, which is an example of using this feature."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/whatsapp_chat.ipynb:10002
msgid "WhatsApp Chat"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/whatsapp_chat.ipynb:10004
msgid "This notebook covers how to load data from the WhatsApp Chats into a format that can be ingested into LangChain."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/word_document.ipynb:10002
msgid "Word Documents"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/word_document.ipynb:10004
msgid "This covers how to load Word documents into a document format that we can use downstream."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/youtube.ipynb:10002
msgid "YouTube"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/youtube.ipynb:10004
msgid "How to load documents from YouTube transcripts."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/youtube.ipynb:60002
msgid "Add video info"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/youtube.ipynb:100002
msgid "YouTube loader from Google Cloud"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/youtube.ipynb:100007
msgid "Enable the [Youtube Api](https://console.cloud.google.com/apis/enableflow?apiid=youtube.googleapis.com&project=sixth-grammar-344520)"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/youtube.ipynb:100009
msgid "`pip install --upgrade google-api-python-client google-auth-httplib2 google-auth-oauthlib youtube-transcript-api`"
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/youtube.ipynb:100012
msgid "By default, the `GoogleDriveLoader` expects the `credentials.json` file to be `~/.credentials/credentials.json`, but this is configurable using the `credentials_file` keyword argument. Same thing with `token.json`. Note that `token.json` will be created automatically the first time you use the loader."
msgstr ""

#: ../docs/modules/indexes/document_loaders/examples/youtube.ipynb:100014
msgid "`GoogleApiYoutubeLoader` can load from a list of Google Docs document ids or a folder id. You can obtain your folder and document id from the URL: Note depending on your set up, the `service_account_path` needs to be set up. See [here](https://developers.google.com/drive/api/v3/quickstart/python) for more details."
msgstr ""

#: ../docs/modules/indexes/getting_started.ipynb:10004
msgid "LangChain primary focuses on constructing indexes with the goal of using them as a Retriever. In order to best understand what this means, it's worth highlighting what the base Retriever interface is. The `BaseRetriever` class in LangChain is as follows:"
msgstr ""

#: ../docs/modules/indexes/getting_started.ipynb:30002
msgid "It's that simple! The `get_relevant_documents` method can be implemented however you see fit."
msgstr ""

#: ../docs/modules/indexes/getting_started.ipynb:30004
msgid "Of course, we also help construct what we think useful Retrievers are. The main type of Retriever that we focus on is a Vectorstore retriever. We will focus on that for the rest of this guide."
msgstr ""

#: ../docs/modules/indexes/getting_started.ipynb:30006
msgid "In order to understand what a vectorstore retriever is, it's important to understand what a Vectorstore is. So let's look at that."
msgstr ""

#: ../docs/modules/indexes/getting_started.ipynb:40002
msgid "By default, LangChain uses [Chroma](../../ecosystem/chroma.md) as the vectorstore to index and search embeddings. To walk through this tutorial, we'll first need to install `chromadb`."
msgstr ""

#: ../docs/modules/indexes/getting_started.ipynb:40008
msgid "This example showcases question answering over documents. We have chosen this as the example for getting started because it nicely combines a lot of different elements (Text splitters, embeddings, vectorstores) and then also shows how to use them in a chain."
msgstr ""

#: ../docs/modules/indexes/getting_started.ipynb:40011
msgid "Question answering over documents consists of four steps:"
msgstr ""

#: ../docs/modules/indexes/getting_started.ipynb:40013
msgid "Create an index"
msgstr ""

#: ../docs/modules/indexes/getting_started.ipynb:40014
msgid "Create a Retriever from that index"
msgstr ""

#: ../docs/modules/indexes/getting_started.ipynb:40015
msgid "Create a question answering chain"
msgstr ""

#: ../docs/modules/indexes/getting_started.ipynb:40016
msgid "Ask questions!"
msgstr ""

#: ../docs/modules/indexes/getting_started.ipynb:40018
msgid "Each of the steps has multiple sub steps and potential configurations. In this notebook we will primarily focus on (1). We will start by showing the one-liner for doing so, but then break down what is actually going on."
msgstr ""

#: ../docs/modules/indexes/getting_started.ipynb:40020
msgid "First, let's import some common classes we'll use no matter what."
msgstr ""

#: ../docs/modules/indexes/getting_started.ipynb:60002
msgid "Next in the generic setup, let's specify the document loader we want to use. You can download the `state_of_the_union.txt` file [here](https://github.com/hwchase17/langchain/blob/master/docs/modules/state_of_the_union.txt)"
msgstr ""

#: ../docs/modules/indexes/getting_started.ipynb:80002
msgid "One Line Index Creation"
msgstr ""

#: ../docs/modules/indexes/getting_started.ipynb:80004
msgid "To get started as quickly as possible, we can use the `VectorstoreIndexCreator`."
msgstr ""

#: ../docs/modules/indexes/getting_started.ipynb:110002
msgid "Now that the index is created, we can use it to ask questions of the data! Note that under the hood this is actually doing a few steps as well, which we will cover later in this guide."
msgstr ""

#: ../docs/modules/indexes/getting_started.ipynb:140002
msgid "What is returned from the `VectorstoreIndexCreator` is `VectorStoreIndexWrapper`, which provides these nice `query` and `query_with_sources` functionality. If we just wanted to access the vectorstore directly, we can also do that."
msgstr ""

#: ../docs/modules/indexes/getting_started.ipynb:160002
msgid "If we then want to access the VectorstoreRetriever, we can do that with:"
msgstr ""

#: ../docs/modules/indexes/getting_started.ipynb:180002
msgid "Walkthrough"
msgstr ""

#: ../docs/modules/indexes/getting_started.ipynb:180004
msgid "Okay, so what's actually going on? How is this index getting created?"
msgstr ""

#: ../docs/modules/indexes/getting_started.ipynb:180006
msgid "A lot of the magic is being hid in this `VectorstoreIndexCreator`. What is this doing?"
msgstr ""

#: ../docs/modules/indexes/getting_started.ipynb:180008
msgid "There are three main steps going on after the documents are loaded:"
msgstr ""

#: ../docs/modules/indexes/getting_started.ipynb:180010
msgid "Splitting documents into chunks"
msgstr ""

#: ../docs/modules/indexes/getting_started.ipynb:180011
msgid "Creating embeddings for each document"
msgstr ""

#: ../docs/modules/indexes/getting_started.ipynb:180012
msgid "Storing documents and embeddings in a vectorstore"
msgstr ""

#: ../docs/modules/indexes/getting_started.ipynb:180014
msgid "Let's walk through this in code"
msgstr ""

#: ../docs/modules/indexes/getting_started.ipynb:200002
msgid "Next, we will split the documents into chunks."
msgstr ""

#: ../docs/modules/indexes/getting_started.ipynb:220002
msgid "We will then select which embeddings we want to use."
msgstr ""

#: ../docs/modules/indexes/getting_started.ipynb:240002
msgid "We now create the vectorstore to use as the index."
msgstr ""

#: ../docs/modules/indexes/getting_started.ipynb:260002
msgid "So that's creating the index. Then, we expose this index in a retriever interface."
msgstr ""

#: ../docs/modules/indexes/getting_started.ipynb:280002
msgid "Then, as before, we create a chain and use it to answer questions!"
msgstr ""

#: ../docs/modules/indexes/getting_started.ipynb:310002
msgid "`VectorstoreIndexCreator` is just a wrapper around all this logic. It is configurable in the text splitter it uses, the embeddings it uses, and the vectorstore it uses. For example, you can configure it as below:"
msgstr ""

#: ../docs/modules/indexes/getting_started.ipynb:330002
msgid "Hopefully this highlights what is going on under the hood of `VectorstoreIndexCreator`. While we think it's important to have a simple way to create indexes, we also think it's important to understand what's going on under the hood."
msgstr ""

#: ../docs/modules/indexes/retrievers.rst:2
msgid "Retrievers"
msgstr ""

#: ../docs/modules/indexes/retrievers.rst:5
msgid "`Conceptual Guide <https://docs.langchain.com/docs/components/indexing/retriever>`_"
msgstr ""

#: ../docs/modules/indexes/retrievers.rst:8
msgid "The retriever interface is a generic interface that makes it easy to combine documents with language models. This interface exposes a `get_relevant_documents` method which takes in a query (a string) and returns a list of documents."
msgstr ""

#: ../docs/modules/indexes/retrievers.rst:12
msgid "Please see below for a list of all the retrievers supported."
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/chatgpt-plugin-retriever.ipynb:10002
msgid "ChatGPT Plugin Retriever"
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/chatgpt-plugin-retriever.ipynb:10004
msgid "This notebook shows how to use the ChatGPT Retriever Plugin within LangChain."
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/chatgpt-plugin-retriever.ipynb:20002
msgid "Create"
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/chatgpt-plugin-retriever.ipynb:20004
msgid "First, let's go over how to create the ChatGPT Retriever Plugin."
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/chatgpt-plugin-retriever.ipynb:20006
msgid "To set up the ChatGPT Retriever Plugin, please follow instructions [here](https://github.com/openai/chatgpt-retrieval-plugin)."
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/chatgpt-plugin-retriever.ipynb:20008
msgid "You can also create the ChatGPT Retriever Plugin from LangChain document loaders. The below code walks through how to do that."
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/chatgpt-plugin-retriever.ipynb:40002
msgid "Using the ChatGPT Retriever Plugin"
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/chatgpt-plugin-retriever.ipynb:40004
msgid "Okay, so we've created the ChatGPT Retriever Plugin, but how do we actually use it?"
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/chatgpt-plugin-retriever.ipynb:40006
msgid "The below code walks through how to do that."
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/contextual-compression.ipynb:10002
msgid "Contextual Compression Retriever"
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/contextual-compression.ipynb:10004
msgid "This notebook introduces the concept of DocumentCompressors and the ContextualCompressionRetriever. The core idea is simple: given a specific query, we should be able to return only the documents relevant to that query, and only the parts of those documents that are relevant. The ContextualCompressionsRetriever is a wrapper for another retriever that iterates over the initial output of the base retriever and filters and compresses those initial documents, so that only the most relevant information is returned."
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/contextual-compression.ipynb:30002
msgid "Using a vanilla vector store retriever"
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/contextual-compression.ipynb:30003
msgid "Let's start by initializing a simple vector store retriever and storing the 2023 State of the Union speech (in chunks). We can see that given an example question our retriever returns one or two relevant docs and a few irrelevant docs. And even the relevant docs have a lot of irrelevant information in them."
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/contextual-compression.ipynb:50002
msgid "Adding contextual compression with an `LLMChainExtractor`"
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/contextual-compression.ipynb:50003
msgid "Now let's wrap our base retriever with a `ContextualCompressionRetriever`. We'll add an `LLMChainExtractor`, which will iterate over the initially returned documents and extract from each only the content that is relevant to the query."
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/contextual-compression.ipynb:70002
msgid "More built-in compressors: filters"
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/contextual-compression.ipynb:70003
msgid "`LLMChainFilter`"
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/contextual-compression.ipynb:70004
msgid "The `LLMChainFilter` is slightly simpler but more robust compressor that uses an LLM chain to decide which of the initially retrieved documents to filter out and which ones to return, without manipulating the document contents."
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/contextual-compression.ipynb:90002
msgid "`EmbeddingsFilter`"
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/contextual-compression.ipynb:90004
msgid "Making an extra LLM call over each retrieved document is expensive and slow. The `EmbeddingsFilter` provides a cheaper and faster option by embedding the documents and query and only returning those documents which have sufficiently similar embeddings to the query."
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/contextual-compression.ipynb:110002
msgid "Stringing compressors and document transformers together"
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/contextual-compression.ipynb:110003
msgid "Using the `DocumentCompressorPipeline` we can also easily combine multiple compressors in sequence. Along with compressors we can add `BaseDocumentTransformer`s to our pipeline, which don't perform any contextual compression but simply perform some transformation on a set of documents. For example `TextSplitter`s can be used as document transformers to split documents into smaller pieces, and the `EmbeddingsRedundantFilter` can be used to filter out redundant documents based on embedding similarity between documents."
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/contextual-compression.ipynb:110005
msgid "Below we create a compressor pipeline by first splitting our docs into smaller chunks, then removing redundant documents, and then filtering based on relevance to the query."
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/databerry.ipynb:10002
msgid "Databerry"
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/databerry.ipynb:10004
msgid "This notebook shows how to use [Databerry's](https://www.databerry.ai/) retriever."
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/databerry.ipynb:10006
msgid "First, you will need to sign up for Databerry, create a datastore, add some data and get your datastore api endpoint url"
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/databerry.ipynb:20004
#: ../docs/modules/indexes/retrievers/examples/metal.ipynb:60004
msgid "Now that our index is set up, we can set up a retriever and start querying it."
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/elastic_search_bm25.ipynb:10002
msgid "ElasticSearch BM25"
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/elastic_search_bm25.ipynb:10004
msgid "This notebook goes over how to use a retriever that under the hood uses ElasticSearcha and BM25."
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/elastic_search_bm25.ipynb:10006
msgid "For more information on the details of BM25 see [this blog post](https://www.elastic.co/blog/practical-bm25-part-2-the-bm25-algorithm-and-its-variables)."
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/elastic_search_bm25.ipynb:30002
msgid "Create New Retriever"
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/elastic_search_bm25.ipynb:60002
#: ../docs/modules/indexes/retrievers/examples/pinecone_hybrid_search.ipynb:160002
msgid "Add texts (if necessary)"
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/elastic_search_bm25.ipynb:60004
#: ../docs/modules/indexes/retrievers/examples/pinecone_hybrid_search.ipynb:160004
msgid "We can optionally add texts to the retriever (if they aren't already in there)"
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/elastic_search_bm25.ipynb:80002
#: ../docs/modules/indexes/retrievers/examples/pinecone_hybrid_search.ipynb:180002
#: ../docs/modules/indexes/retrievers/examples/svm_retriever.ipynb:60002
#: ../docs/modules/indexes/retrievers/examples/tf_idf_retriever.ipynb:60002
msgid "Use Retriever"
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/elastic_search_bm25.ipynb:80004
#: ../docs/modules/indexes/retrievers/examples/pinecone_hybrid_search.ipynb:180004
#: ../docs/modules/indexes/retrievers/examples/svm_retriever.ipynb:60004
#: ../docs/modules/indexes/retrievers/examples/tf_idf_retriever.ipynb:60004
msgid "We can now use the retriever!"
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/metal.ipynb:10002
msgid "Metal"
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/metal.ipynb:10004
msgid "This notebook shows how to use [Metal's](https://docs.getmetal.io/introduction) retriever."
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/metal.ipynb:10006
msgid "First, you will need to sign up for Metal and get an API key. You can do so [here](https://docs.getmetal.io/misc-create-app)"
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/metal.ipynb:40002
msgid "Ingest Documents"
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/metal.ipynb:40004
msgid "You only need to do this if you haven't already set up an index"
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/pinecone_hybrid_search.ipynb:10002
msgid "Pinecone Hybrid Search"
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/pinecone_hybrid_search.ipynb:10004
msgid "This notebook goes over how to use a retriever that under the hood uses Pinecone and Hybrid Search."
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/pinecone_hybrid_search.ipynb:10006
msgid "The logic of this retriever is taken from [this documentaion](https://docs.pinecone.io/docs/hybrid-search)"
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/pinecone_hybrid_search.ipynb:30002
msgid "Setup Pinecone"
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/pinecone_hybrid_search.ipynb:40002
msgid "You should only have to do this part once."
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/pinecone_hybrid_search.ipynb:40004
msgid "Note: it's important to make sure that the \"context\" field that holds the document text in the metadata is not indexed. Currently you need to specify explicitly the fields you do want to index. For more information checkout Pinecone's [docs](https://docs.pinecone.io/docs/manage-indexes#selective-metadata-indexing)."
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/pinecone_hybrid_search.ipynb:70002
msgid "Now that its created, we can use it"
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/pinecone_hybrid_search.ipynb:90002
msgid "Get embeddings and sparse encoders"
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/pinecone_hybrid_search.ipynb:90004
msgid "Embeddings are used for the dense vectors, tokenizer is used for the sparse vector"
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/pinecone_hybrid_search.ipynb:110002
msgid "To encode the text to sparse values you can either choose SPLADE or BM25. For out of domain tasks we recommend using BM25."
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/pinecone_hybrid_search.ipynb:110004
msgid "For more information about the sparse encoders you can checkout pinecone-text library [docs](https://pinecone-io.github.io/pinecone-text/pinecone_text.html)."
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/pinecone_hybrid_search.ipynb:130002
msgid "The above code is using default tfids values. It's highly recommended to fit the tf-idf values to your own corpus. You can do it as follow:"
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/pinecone_hybrid_search.ipynb:140002
msgid "Load Retriever"
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/pinecone_hybrid_search.ipynb:140004
msgid "We can now construct the retriever!"
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/svm_retriever.ipynb:10002
msgid "SVM Retriever"
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/svm_retriever.ipynb:10004
msgid "This notebook goes over how to use a retriever that under the hood uses an SVM using scikit-learn."
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/svm_retriever.ipynb:10006
msgid "Largely based on https://github.com/karpathy/randomfun/blob/master/knn_vs_svm.ipynb"
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/svm_retriever.ipynb:40002
#: ../docs/modules/indexes/retrievers/examples/tf_idf_retriever.ipynb:40002
msgid "Create New Retriever with Texts"
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/tf_idf_retriever.ipynb:10002
msgid "TF-IDF Retriever"
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/tf_idf_retriever.ipynb:10004
msgid "This notebook goes over how to use a retriever that under the hood uses TF-IDF using scikit-learn."
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/tf_idf_retriever.ipynb:10006
msgid "For more information on the details of TF-IDF see [this blog post](https://medium.com/data-science-bootcamp/tf-idf-basics-of-information-retrieval-48de122b2a4c)."
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/time_weighted_vectorstore.ipynb:10002
msgid "Time Weighted VectorStore Retriever"
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/time_weighted_vectorstore.ipynb:10004
msgid "This retriever uses a combination of semantic similarity and recency."
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/time_weighted_vectorstore.ipynb:10006
msgid "The algorithm for scoring them is:"
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/time_weighted_vectorstore.ipynb:10012
msgid "Notably, hours_passed refers to the hours passed since the object in the retriever **was last accessed**, not since it was created. This means that frequently accessed objects remain \"fresh.\""
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/time_weighted_vectorstore.ipynb:30002
msgid "Low Decay Rate"
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/time_weighted_vectorstore.ipynb:30004
msgid "A low decay rate (in this, to be extreme, we will set close to 0) means memories will be \"remembered\" for longer. A decay rate of 0 means memories never be forgotten, making this retriever equivalent to the vector lookup."
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/time_weighted_vectorstore.ipynb:70002
msgid "High Decay Rate"
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/time_weighted_vectorstore.ipynb:70004
msgid "With a high decay factor (e.g., several 9's), the recency score quickly goes to 0! If you set this all the way to 1, recency is 0 for all objects, once again making this equivalent to a vector lookup."
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/vectorstore-retriever.ipynb:10002
msgid "VectorStore Retriever"
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/vectorstore-retriever.ipynb:10004
msgid "The index - and therefore the retriever - that LangChain has the most support for is a VectorStoreRetriever. As the name suggests, this retriever is backed heavily by a VectorStore."
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/vectorstore-retriever.ipynb:10006
msgid "Once you construct a VectorStore, its very easy to construct a retriever. Let's walk through an example."
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/vectorstore-retriever.ipynb:60002
msgid "By default, the vectorstore retriever uses similarity search. If the underlying vectorstore support maximum marginal relevance search, you can specify that as the search type."
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/vectorstore-retriever.ipynb:90002
msgid "You can also specify search kwargs like `k` to use when doing retrieval."
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/weaviate-hybrid.ipynb:10002
msgid "Weaviate Hybrid Search"
msgstr ""

#: ../docs/modules/indexes/retrievers/examples/weaviate-hybrid.ipynb:10004
msgid "This notebook shows how to use [Weaviate hybrid search](https://weaviate.io/blog/hybrid-search-explained) as a LangChain retriever."
msgstr ""

#: ../docs/modules/indexes/text_splitters.rst:2
msgid "Text Splitters"
msgstr ""

#: ../docs/modules/indexes/text_splitters.rst:5
msgid "`Conceptual Guide <https://docs.langchain.com/docs/components/indexing/text-splitter>`_"
msgstr ""

#: ../docs/modules/indexes/text_splitters.rst:8
msgid "When you want to deal with long pieces of text, it is necessary to split up that text into chunks. As simple as this sounds, there is a lot of potential complexity here. Ideally, you want to keep the semantically related pieces of text together. What \"semantically related\" means could depend on the type of text. This notebook showcases several ways to do that."
msgstr ""

#: ../docs/modules/indexes/text_splitters.rst:12
msgid "At a high level, text splitters work as following:"
msgstr ""

#: ../docs/modules/indexes/text_splitters.rst:14
msgid "Split the text up into small, semantically meaningful chunks (often sentences)."
msgstr ""

#: ../docs/modules/indexes/text_splitters.rst:15
msgid "Start combining these small chunks into a larger chunk until you reach a certain size (as measured by some function)."
msgstr ""

#: ../docs/modules/indexes/text_splitters.rst:16
msgid "Once you reach that size, make that chunk its own piece of text and then start creating a new chunk of text with some overlap (to keep context between chunks)."
msgstr ""

#: ../docs/modules/indexes/text_splitters.rst:18
msgid "That means there two different axes along which you can customize your text splitter:"
msgstr ""

#: ../docs/modules/indexes/text_splitters.rst:20
msgid "How the text is split"
msgstr ""

#: ../docs/modules/indexes/text_splitters.rst:21
msgid "How the chunk size is measured"
msgstr ""

#: ../docs/modules/indexes/text_splitters.rst:23
msgid "For an introduction to the default text splitter and generic functionality see:"
msgstr ""

#: ../docs/modules/indexes/text_splitters.rst:33
msgid "We also have documentation for all the types of text splitters that are supported. Please see below for that list."
msgstr ""

#: ../docs/modules/indexes/text_splitters/examples/character_text_splitter.ipynb:10002
msgid "Character Text Splitter"
msgstr ""

#: ../docs/modules/indexes/text_splitters/examples/character_text_splitter.ipynb:10004
msgid "This is a more simple method. This splits based on characters (by default \"\\n\\n\") and measure chunk length by number of characters."
msgstr ""

#: ../docs/modules/indexes/text_splitters/examples/character_text_splitter.ipynb:10006
msgid "How the text is split: by single character"
msgstr ""

#: ../docs/modules/indexes/text_splitters/examples/character_text_splitter.ipynb:10007
#: ../docs/modules/indexes/text_splitters/examples/latex.ipynb:10007
#: ../docs/modules/indexes/text_splitters/examples/markdown.ipynb:10007
#: ../docs/modules/indexes/text_splitters/examples/nltk.ipynb:10006
#: ../docs/modules/indexes/text_splitters/examples/python.ipynb:10007
#: ../docs/modules/indexes/text_splitters/examples/recursive_text_splitter.ipynb:10007
#: ../docs/modules/indexes/text_splitters/examples/spacy.ipynb:10006
msgid "How the chunk size is measured: by length function passed in (defaults to number of characters)"
msgstr ""

#: ../docs/modules/indexes/text_splitters/examples/character_text_splitter.ipynb:50002
msgid "Here's an example of passing metadata along with the documents, notice that it is split along with the documents."
msgstr ""

#: ../docs/modules/indexes/text_splitters/examples/huggingface_length_function.ipynb:10002
msgid "Hugging Face Length Function"
msgstr ""

#: ../docs/modules/indexes/text_splitters/examples/huggingface_length_function.ipynb:10003
msgid "Most LLMs are constrained by the number of tokens that you can pass in, which is not the same as the number of characters. In order to get a more accurate estimate, we can use Hugging Face tokenizers to count the text length."
msgstr ""

#: ../docs/modules/indexes/text_splitters/examples/huggingface_length_function.ipynb:10005
#: ../docs/modules/indexes/text_splitters/examples/tiktoken.ipynb:10005
msgid "How the text is split: by character passed in"
msgstr ""

#: ../docs/modules/indexes/text_splitters/examples/huggingface_length_function.ipynb:10006
msgid "How the chunk size is measured: by Hugging Face tokenizer"
msgstr ""

#: ../docs/modules/indexes/text_splitters/examples/latex.ipynb:10002
msgid "Latex Text Splitter"
msgstr ""

#: ../docs/modules/indexes/text_splitters/examples/latex.ipynb:10004
msgid "LatexTextSplitter splits text along Latex headings, headlines, enumerations and more. It's implemented as a simple subclass of RecursiveCharacterSplitter with Latex-specific separators. See the source code to see the Latex syntax expected by default."
msgstr ""

#: ../docs/modules/indexes/text_splitters/examples/latex.ipynb:10006
msgid "How the text is split: by list of latex specific tags"
msgstr ""

#: ../docs/modules/indexes/text_splitters/examples/markdown.ipynb:10002
msgid "Markdown Text Splitter"
msgstr ""

#: ../docs/modules/indexes/text_splitters/examples/markdown.ipynb:10004
msgid "MarkdownTextSplitter splits text along Markdown headings, code blocks, or horizontal rules. It's implemented as a simple subclass of RecursiveCharacterSplitter with Markdown-specific separators. See the source code to see the Markdown syntax expected by default."
msgstr ""

#: ../docs/modules/indexes/text_splitters/examples/markdown.ipynb:10006
msgid "How the text is split: by list of markdown specific characters"
msgstr ""

#: ../docs/modules/indexes/text_splitters/examples/nltk.ipynb:10002
msgid "NLTK Text Splitter"
msgstr ""

#: ../docs/modules/indexes/text_splitters/examples/nltk.ipynb:10003
msgid "Rather than just splitting on \"\\n\\n\", we can use NLTK to split based on tokenizers."
msgstr ""

#: ../docs/modules/indexes/text_splitters/examples/nltk.ipynb:10005
msgid "How the text is split: by NLTK"
msgstr ""

#: ../docs/modules/indexes/text_splitters/examples/python.ipynb:10002
msgid "Python Code Text Splitter"
msgstr ""

#: ../docs/modules/indexes/text_splitters/examples/python.ipynb:10004
msgid "PythonCodeTextSplitter splits text along python class and method definitions. It's implemented as a simple subclass of RecursiveCharacterSplitter with Python-specific separators. See the source code to see the Python syntax expected by default."
msgstr ""

#: ../docs/modules/indexes/text_splitters/examples/python.ipynb:10006
msgid "How the text is split: by list of python specific characters"
msgstr ""

#: ../docs/modules/indexes/text_splitters/examples/recursive_text_splitter.ipynb:10002
msgid "RecursiveCharacterTextSplitter"
msgstr ""

#: ../docs/modules/indexes/text_splitters/examples/recursive_text_splitter.ipynb:10003
msgid "This text splitter is the recommended one for generic text. It is parameterized by a list of characters. It tries to split on them in order until the chunks are small enough. The default list is `[\"\\n\\n\", \"\\n\", \" \", \"\"]`. This has the effect of trying to keep all paragraphs (and then sentences, and then words) together as long as possible, as those would generically seem to be the strongest semantically related pieces of text."
msgstr ""

#: ../docs/modules/indexes/text_splitters/examples/recursive_text_splitter.ipynb:10006
msgid "How the text is split: by list of characters"
msgstr ""

#: ../docs/modules/indexes/text_splitters/examples/spacy.ipynb:10002
msgid "Spacy Text Splitter"
msgstr ""

#: ../docs/modules/indexes/text_splitters/examples/spacy.ipynb:10003
msgid "Another alternative to NLTK is to use Spacy."
msgstr ""

#: ../docs/modules/indexes/text_splitters/examples/spacy.ipynb:10005
msgid "How the text is split: by Spacy"
msgstr ""

#: ../docs/modules/indexes/text_splitters/examples/tiktoken.ipynb:10002
msgid "tiktoken (OpenAI) Length Function"
msgstr ""

#: ../docs/modules/indexes/text_splitters/examples/tiktoken.ipynb:10003
msgid "You can also use tiktoken, a open source tokenizer package from OpenAI to estimate tokens used. Will probably be more accurate for their models."
msgstr ""

#: ../docs/modules/indexes/text_splitters/examples/tiktoken.ipynb:10006
msgid "How the chunk size is measured: by `tiktoken` tokenizer"
msgstr ""

#: ../docs/modules/indexes/text_splitters/examples/tiktoken_splitter.ipynb:10002
msgid "TiktokenText Splitter"
msgstr ""

#: ../docs/modules/indexes/text_splitters/examples/tiktoken_splitter.ipynb:10004
msgid "How the text is split: by `tiktoken` tokens"
msgstr ""

#: ../docs/modules/indexes/text_splitters/examples/tiktoken_splitter.ipynb:10005
msgid "How the chunk size is measured: by `tiktoken` tokens"
msgstr ""

#: ../docs/modules/indexes/text_splitters/getting_started.ipynb:10003
msgid "The default recommended text splitter is the RecursiveCharacterTextSplitter. This text splitter takes a list of characters. It tries to create chunks based on splitting on the first character, but if any chunks are too large it then moves onto the next character, and so forth. By default the characters it tries to split on are `[\"\\n\\n\", \"\\n\", \" \", \"\"]`"
msgstr ""

#: ../docs/modules/indexes/text_splitters/getting_started.ipynb:10005
msgid "In addition to controlling which characters you can split on, you can also control a few other things:"
msgstr ""

#: ../docs/modules/indexes/text_splitters/getting_started.ipynb:10007
msgid "`length_function`: how the length of chunks is calculated. Defaults to just counting number of characters, but it's pretty common to pass a token counter here."
msgstr ""

#: ../docs/modules/indexes/text_splitters/getting_started.ipynb:10008
msgid "`chunk_size`: the maximum size of your chunks (as measured by the length function)."
msgstr ""

#: ../docs/modules/indexes/text_splitters/getting_started.ipynb:10009
msgid "`chunk_overlap`: the maximum overlap between chunks. It can be nice to have some overlap to maintain some continuity between chunks (eg do a sliding window)."
msgstr ""

#: ../docs/modules/indexes/vectorstores.rst:2
msgid "Vectorstores"
msgstr ""

#: ../docs/modules/indexes/vectorstores.rst:5
msgid "`Conceptual Guide <https://docs.langchain.com/docs/components/indexing/vectorstore>`_"
msgstr ""

#: ../docs/modules/indexes/vectorstores.rst:8
msgid "Vectorstores are one of the most important components of building indexes."
msgstr ""

#: ../docs/modules/indexes/vectorstores.rst:10
msgid "For an introduction to vectorstores and generic functionality see:"
msgstr ""

#: ../docs/modules/indexes/vectorstores.rst:19
msgid "We also have documentation for all the types of vectorstores that are supported. Please see below for that list."
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/analyticdb.ipynb:10002
msgid "AnalyticDB"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/analyticdb.ipynb:10004
msgid "This notebook shows how to use functionality related to the AnalyticDB vector database. To run, you should have an [AnalyticDB](https://www.alibabacloud.com/help/en/analyticdb-for-postgresql/latest/product-introduction-overview) instance up and running:"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/analyticdb.ipynb:10006
msgid "Using [AnalyticDB Cloud Vector Database](https://www.alibabacloud.com/product/hybriddb-postgresql). Click here to fast deploy it."
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/analyticdb.ipynb:30002
msgid "Split documents and get embeddings by call OpenAI API"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/analyticdb.ipynb:50002
msgid "Connect to AnalyticDB by setting related ENVIRONMENTS."
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/analyticdb.ipynb:50011
msgid "Then store your embeddings and documents into AnalyticDB"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/analyticdb.ipynb:70002
msgid "Query and retrieve data"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/annoy.ipynb:10002
msgid "Annoy"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/annoy.ipynb:10004
msgid "This notebook shows how to use functionality related to the Annoy vector database."
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/annoy.ipynb:10006
msgid "\"Annoy (Approximate Nearest Neighbors Oh Yeah) is a C++ library with Python bindings to search for points in space that are close to a given query point. It also creates large read-only file-based data structures that are mmapped into memory so that many processes may share the same data.\""
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/annoy.ipynb:10008
msgid "via [Annoy](https://github.com/spotify/annoy)"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/annoy.ipynb:20003
msgid "Annoy is read-only - once the index is built you cannot add any more emebddings! If you want to progressively add to your VectorStore then better choose an alternative!"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/annoy.ipynb:30002
msgid "Create VectorStore from texts"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/annoy.ipynb:90002
msgid "Create VectorStore from docs"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/annoy.ipynb:150002
msgid "Create VectorStore via existing embeddings"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/annoy.ipynb:190002
msgid "Search via embeddings"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/annoy.ipynb:230002
msgid "Search via docstore id"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/annoy.ipynb:270002
msgid "Save and load"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/annoy.ipynb:310002
msgid "Construct from scratch"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/atlas.ipynb:10002
msgid "AtlasDB"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/atlas.ipynb:10004
msgid "This notebook shows you how to use functionality related to the AtlasDB"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/chroma.ipynb:10002
msgid "Chroma"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/chroma.ipynb:10004
msgid "This notebook shows how to use functionality related to the Chroma vector database."
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/chroma.ipynb:60002
#: ../docs/modules/indexes/vectorstores/examples/pgvector.ipynb:60002
#: ../docs/modules/indexes/vectorstores/examples/qdrant.ipynb:180002
#: ../docs/modules/indexes/vectorstores/examples/supabase.ipynb:100002
msgid "Similarity search with score"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/chroma.ipynb:90002
msgid "Persistance"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/chroma.ipynb:90004
msgid "The below steps cover how to persist a ChromaDB instance"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/chroma.ipynb:100002
msgid "Initialize PeristedChromaDB"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/chroma.ipynb:100003
msgid "Create embeddings for each chunk and insert into the Chroma vector database. The persist_directory argument tells ChromaDB where to store the database when it's persisted."
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/chroma.ipynb:120002
msgid "Persist the Database"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/chroma.ipynb:120003
msgid "We should call persist() to ensure the embeddings are written to disk."
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/chroma.ipynb:140002
msgid "Load the Database from disk, and create the chain"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/chroma.ipynb:140003
msgid "Be sure to pass the same persist_directory and embedding_function as you did when you instantiated the database. Initialize the chain we will use for question answering."
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/chroma.ipynb:160002
#: ../docs/modules/indexes/vectorstores/examples/supabase.ipynb:130002
msgid "Retriever options"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/chroma.ipynb:160004
msgid "This section goes over different options for how to use Chroma as a retriever."
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/chroma.ipynb:160006
msgid "MMR"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/chroma.ipynb:160008
#: ../docs/modules/indexes/vectorstores/examples/supabase.ipynb:130008
msgid "In addition to using similarity search in the retriever object, you can also use `mmr`."
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/deeplake.ipynb:10002
msgid "Deep Lake"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/deeplake.ipynb:10004
msgid "This notebook showcases basic functionality related to Deep Lake. While Deep Lake can store embeddings, it is capable of storing any type of data. It is a fully fledged serverless data lake with version control, query engine and streaming dataloader to deep learning frameworks."
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/deeplake.ipynb:10006
msgid "For more information, please see the Deep Lake [documentation](docs.activeloop.ai) or [api reference](docs.deeplake.ai)"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/deeplake.ipynb:60002
msgid "Creates a dataset locally at `./deeplake/`, then runs similiarity search"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/deeplake.ipynb:90002
msgid "Later, you can reload the dataset without recomputing embeddings"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/deeplake.ipynb:110002
msgid "Deep Lake, for now, is single writer and multiple reader. Setting `read_only=True` helps to avoid acquring the writer lock."
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/deeplake.ipynb:150002
msgid "Attribute based filtering in metadata"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/deeplake.ipynb:180002
msgid "Choosing distance function"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/deeplake.ipynb:180003
msgid "Distance function `L2` for Euclidean, `L1` for Nuclear, `Max` l-infinity distnace, `cos` for cosine similarity, `dot` for dot product"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/deeplake.ipynb:200002
msgid "Maximal Marginal relevance"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/deeplake.ipynb:200003
msgid "Using maximal marginal relevance"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/deeplake.ipynb:220002
msgid "Delete dataset"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/deeplake.ipynb:240002
msgid "and if delete fails you can also force delete"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/deeplake.ipynb:260002
msgid "Deep Lake datasets on cloud (Activeloop, AWS, GCS, etc.) or local"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/deeplake.ipynb:260003
msgid "By default deep lake datasets are stored in memory, in case you want to persist locally or to any object storage you can simply provide path to the dataset. You can retrieve token from [app.activeloop.ai](https://app.activeloop.ai/)"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/deeplake.ipynb:300002
msgid "Creating dataset on AWS S3"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/deeplake.ipynb:320002
msgid "Deep Lake API"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/deeplake.ipynb:320003
msgid "you can access the Deep Lake  dataset at `db.ds`"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/deeplake.ipynb:350002
msgid "Transfer local dataset to cloud"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/deeplake.ipynb:350003
msgid "Copy already created dataset to the cloud. You can also transfer from cloud to local."
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/elasticsearch.ipynb:10002
msgid "ElasticSearch"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/elasticsearch.ipynb:10004
msgid "This notebook shows how to use functionality related to the ElasticSearch database."
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/faiss.ipynb:10002
msgid "FAISS"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/faiss.ipynb:10004
msgid "This notebook shows how to use functionality related to the FAISS vector database."
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/faiss.ipynb:60002
msgid "Similarity Search with score"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/faiss.ipynb:60003
msgid "There are some FAISS specific methods. One of them is `similarity_search_with_score`, which allows you to return not only the documents but also the similarity score of the query to them."
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/faiss.ipynb:90002
msgid "It is also possible to do a search for documents similar to a given embedding vector using `similarity_search_by_vector` which accepts an embedding vector as a parameter instead of a string."
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/faiss.ipynb:110002
msgid "Saving and loading"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/faiss.ipynb:110003
msgid "You can also save and load a FAISS index. This is useful so you don't have to recreate it everytime you use it."
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/faiss.ipynb:160002
msgid "Merging"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/faiss.ipynb:160003
msgid "You can also merge two FAISS vectorstores"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/milvus.ipynb:10002
msgid "Milvus"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/milvus.ipynb:10004
msgid "This notebook shows how to use functionality related to the Milvus vector database."
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/milvus.ipynb:10006
msgid "To run, you should have a Milvus instance up and running: https://milvus.io/docs/install_standalone-docker.md"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/myscale.ipynb:10002
msgid "MyScale"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/myscale.ipynb:10004
msgid "This notebook shows how to use functionality related to the MyScale vector database."
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/myscale.ipynb:30002
msgid "Setting up envrionments"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/myscale.ipynb:30004
msgid "There are two ways to set up parameters for myscale index."
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/myscale.ipynb:30006
msgid "Environment Variables"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/myscale.ipynb:30008
msgid "Before you run the app, please set the environment variable with `export`:  `export MYSCALE_URL='<your-endpoints-url>' MYSCALE_PORT=<your-endpoints-port> MYSCALE_USERNAME=<your-username> MYSCALE_PASSWORD=<your-password> ...`"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/myscale.ipynb:30011
msgid "You can easily find your account, password and other info on our SaaS. For details please refer to [this document](https://docs.myscale.com/en/cluster-management/)"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/myscale.ipynb:30013
msgid "Every attributes under `MyScaleSettings` can be set with prefix `MYSCALE_` and is case insensitive."
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/myscale.ipynb:30015
msgid "Create `MyScaleSettings` object with parameters"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/myscale.ipynb:70002
msgid "Get connection info and data schema"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/myscale.ipynb:90002
msgid "Filtering"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/myscale.ipynb:90004
msgid "You can have direct access to myscale SQL where statement. You can write `WHERE` clause following standard SQL."
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/myscale.ipynb:90006
msgid "**NOTE**: Please be aware of SQL injection, this interface must not be directly called by end-user."
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/myscale.ipynb:90008
msgid "If you custimized your `column_map` under your setting, you search with filter like this:"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/myscale.ipynb:120002
msgid "Deleting your data"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/opensearch.ipynb:10002
msgid "OpenSearch"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/opensearch.ipynb:10004
msgid "This notebook shows how to use functionality related to the OpenSearch database."
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/opensearch.ipynb:10006
msgid "To run, you should have the opensearch instance up and running: [here](https://opensearch.org/docs/latest/install-and-configure/install-opensearch/index/) `similarity_search` by default performs the Approximate k-NN Search which uses one of the several algorithms like lucene, nmslib, faiss recommended for large datasets. To perform brute force search we have other search methods known as Script Scoring and Painless Scripting. Check [this](https://opensearch.org/docs/latest/search-plugins/knn/index/) for more details."
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/opensearch.ipynb:60002
msgid "similarity_search using Approximate k-NN Search with Custom Parameters"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/opensearch.ipynb:90002
msgid "similarity_search using Script Scoring with Custom Parameters"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/opensearch.ipynb:120002
msgid "similarity_search using Painless Scripting with Custom Parameters"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/opensearch.ipynb:150002
msgid "Using a preexisting OpenSearch instance"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/opensearch.ipynb:150004
msgid "It's also possible to use a preexisting OpenSearch instance with documents that already have vectors present."
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/pgvector.ipynb:10002
msgid "PGVector"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/pgvector.ipynb:10004
msgid "This notebook shows how to use functionality related to the Postgres vector database (PGVector)."
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/pgvector.ipynb:70002
msgid "Similarity Search with Euclidean Distance (Default)"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/pinecone.ipynb:10002
msgid "Pinecone"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/pinecone.ipynb:10004
msgid "This notebook shows how to use functionality related to the Pinecone vector database."
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/qdrant.ipynb:10002
msgid "Qdrant"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/qdrant.ipynb:10004
msgid "This notebook shows how to use functionality related to the Qdrant vector database. There are various modes of how to run Qdrant, and depending on the chosen one, there will be some subtle differences. The options include:"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/qdrant.ipynb:10006
msgid "Local mode, no server required"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/qdrant.ipynb:10007
#: ../docs/modules/indexes/vectorstores/examples/qdrant.ipynb:80002
msgid "On-premise server deployment"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/qdrant.ipynb:10008
#: ../docs/modules/indexes/vectorstores/examples/qdrant.ipynb:100002
msgid "Qdrant Cloud"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/qdrant.ipynb:40002
msgid "Connecting to Qdrant from LangChain"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/qdrant.ipynb:40004
msgid "Local mode"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/qdrant.ipynb:40006
msgid "Python client allows you to run the same code in local mode without running the Qdrant server. That's great for testing things out and debugging or if you plan to store just a small amount of vectors. The embeddings might be fully kepy in memory or persisted on disk."
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/qdrant.ipynb:40008
msgid "In-memory"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/qdrant.ipynb:40010
msgid "For some testing scenarios and quick experiments, you may prefer to keep all the data in memory only, so it gets lost when the client is destroyed - usually at the end of your script/notebook."
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/qdrant.ipynb:60002
msgid "On-disk storage"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/qdrant.ipynb:60004
msgid "Local mode, without using the Qdrant server, may also store your vectors on disk so they're persisted between runs."
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/qdrant.ipynb:80004
msgid "No matter if you choose to launch Qdrant locally with [a Docker container](https://qdrant.tech/documentation/install/), or select a Kubernetes deployment with [the official Helm chart](https://github.com/qdrant/qdrant-helm), the way you're going to connect to such an instance will be identical. You'll need to provide a URL pointing to the service."
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/qdrant.ipynb:100004
msgid "If you prefer not to keep yourself busy with managing the infrastructure, you can choose to set up a fully-managed Qdrant cluster on [Qdrant Cloud](https://cloud.qdrant.io/). There is a free forever 1GB cluster included for trying out. The main difference with using a managed version of Qdrant is that you'll need to provide an API key to secure your deployment from being accessed publicly."
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/qdrant.ipynb:120002
msgid "Reusing the same collection"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/qdrant.ipynb:120004
msgid "Both `Qdrant.from_texts` and `Qdrant.from_documents` methods are great to start using Qdrant with LangChain, but **they are going to destroy the collection and create it from scratch**! If you want to reuse the existing collection, you can always create an instance of `Qdrant` on your own and pass the `QdrantClient` instance with the connection details."
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/qdrant.ipynb:150002
msgid "Similarity search"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/qdrant.ipynb:150004
msgid "The simplest scenario for using Qdrant vector store is to perform a similarity search. Under the hood, our query will be encoded with the `embedding_function` and used to find similar documents in Qdrant collection."
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/qdrant.ipynb:180004
msgid "Sometimes we might want to perform the search, but also obtain a relevancy score to know how good is a particular result."
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/qdrant.ipynb:210002
msgid "Maximum marginal relevance search (MMR)"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/qdrant.ipynb:210004
msgid "If you'd like to look up for some similar documents, but you'd also like to receive diverse results, MMR is method you should consider. Maximal marginal relevance optimizes for similarity to query AND diversity among selected documents."
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/qdrant.ipynb:240002
msgid "Qdrant as a Retriever"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/qdrant.ipynb:240004
msgid "Qdrant, as all the other vector stores, is a LangChain Retriever, by using cosine similarity."
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/qdrant.ipynb:260002
msgid "It might be also specified to use MMR as a search strategy, instead of similarity."
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/qdrant.ipynb:290002
msgid "Customizing Qdrant"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/qdrant.ipynb:290004
msgid "Qdrant stores your vector embeddings along with the optional JSON-like payload. Payloads are optional, but since LangChain assumes the embeddings are generated from the documents, we keep the context data, so you can extract the original texts as well."
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/qdrant.ipynb:290006
msgid "By default, your document is going to be stored in the following payload structure:"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/qdrant.ipynb:290017
msgid "You can, however, decide to use different keys for the page content and metadata. That's useful if you already have a collection that you'd like to reuse. You can always change the"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/redis.ipynb:10002
msgid "Redis"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/redis.ipynb:10004
msgid "This notebook shows how to use functionality related to the [Redis vector database](https://redis.com/solutions/use-cases/vector-database/)."
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/redis.ipynb:100002
msgid "RedisVectorStoreRetriever"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/redis.ipynb:100004
msgid "Here we go over different options for using the vector store as a retriever."
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/redis.ipynb:100006
msgid "There are three different search methods we can use to do retrieval. By default, it will use semantic similarity."
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/redis.ipynb:130002
msgid "We can also use similarity_limit as a search method. This is only return documents if they are similar enough"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/supabase.ipynb:10002
msgid "SupabaseVectorStore"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/supabase.ipynb:10004
msgid "This notebook shows how to use Supabase and `pgvector` as your VectorStore."
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/supabase.ipynb:10006
msgid "To run this notebook, please ensure:"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/supabase.ipynb:10008
msgid "the `pgvector` extension is enabled"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/supabase.ipynb:10009
msgid "you have installed the `supabase-py` package"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/supabase.ipynb:10010
msgid "that you have created a `match_documents` function in your database"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/supabase.ipynb:10011
msgid "that you have a `documents` table in your `public` schema similar to the one below."
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/supabase.ipynb:10013
msgid "The following function determines cosine similarity, but you can adjust to your needs."
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/supabase.ipynb:130004
msgid "This section goes over different options for how to use SupabaseVectorStore as a retriever."
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/supabase.ipynb:130006
msgid "Maximal Marginal Relevance Searches"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/weaviate.ipynb:10002
msgid "Weaviate"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/weaviate.ipynb:10004
msgid "This notebook shows how to use functionality related to the Weaviate vector database."
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/zilliz.ipynb:10002
msgid "Zilliz"
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/zilliz.ipynb:10004
msgid "This notebook shows how to use functionality related to the Zilliz Cloud managed vector database."
msgstr ""

#: ../docs/modules/indexes/vectorstores/examples/zilliz.ipynb:10006
msgid "To run, you should have a Zilliz Cloud instance up and running: https://zilliz.com/cloud"
msgstr ""

#: ../docs/modules/indexes/vectorstores/getting_started.ipynb:10004
msgid "This notebook showcases basic functionality related to VectorStores. A key part of working with vectorstores is creating the vector to put in them, which is usually created via embeddings. Therefore, it is recommended that you familiarize yourself with the [embedding notebook](embeddings.ipynb) before diving into this."
msgstr ""

#: ../docs/modules/indexes/vectorstores/getting_started.ipynb:10006
msgid "This covers generic high level functionality related to all vector stores. For guides on specific vectorstores, please see the how-to guides [here](../how_to_guides.rst)"
msgstr ""

#: ../docs/modules/indexes/vectorstores/getting_started.ipynb:60002
msgid "Add texts"
msgstr ""

#: ../docs/modules/indexes/vectorstores/getting_started.ipynb:60003
msgid "You can easily add text to a vectorstore with the `add_texts` method. It will return a list of document IDs (in case you need to use them downstream)."
msgstr ""

#: ../docs/modules/indexes/vectorstores/getting_started.ipynb:100002
msgid "From Documents"
msgstr ""

#: ../docs/modules/indexes/vectorstores/getting_started.ipynb:100003
msgid "We can also initialize a vectorstore from documents directly. This is useful when we use the method on the text splitter to get documents directly (handy when the original documents have associated metadata)."
msgstr ""

#: ../docs/modules/memory.rst:27
#: ../docs/modules/memory.rst:2
#: ../docs/modules/memory.rst:27
msgid "Memory"
msgstr ""

#: ../docs/modules/memory.rst:5
msgid "`Conceptual Guide <https://docs.langchain.com/docs/components/memory>`_"
msgstr ""

#: ../docs/modules/memory.rst:8
msgid "By default, Chains and Agents are stateless, meaning that they treat each incoming query independently (as are the underlying LLMs and chat models). In some applications (chatbots being a GREAT example) it is highly important to remember previous interactions, both at a short term but also at a long term level. The concept of ‚ÄúMemory‚Äù exists to do exactly that."
msgstr ""

#: ../docs/modules/memory.rst:14
msgid "LangChain provides memory components in two forms. First, LangChain provides helper utilities for managing and manipulating previous chat messages. These are designed to be modular and useful regardless of how they are used. Secondly, LangChain provides easy ways to incorporate these utilities into chains."
msgstr ""

#: ../docs/modules/memory.rst:21
msgid "`Getting Started <./memory/getting_started.html>`_: An overview of how to get started with different types of memory."
msgstr ""

#: ../docs/modules/memory.rst:23
msgid "`How-To Guides <./memory/how_to_guides.html>`_: A collection of how-to guides. These highlight different types of memory, as well as how to use memory in chains."
msgstr ""

#: ../docs/modules/memory/examples/adding_memory.ipynb:10002
msgid "How to add Memory to an LLMChain"
msgstr ""

#: ../docs/modules/memory/examples/adding_memory.ipynb:10004
msgid "This notebook goes over how to use the Memory class with an LLMChain. For the purposes of this walkthrough, we will add  the `ConversationBufferMemory` class, although this can be any memory class."
msgstr ""

#: ../docs/modules/memory/examples/adding_memory.ipynb:30002
msgid "The most important step is setting up the prompt correctly. In the below prompt, we have two input keys: one for the actual input, another for the input from the Memory class. Importantly, we make sure the keys in the PromptTemplate and the ConversationBufferMemory match up (`chat_history`)."
msgstr ""

#: ../docs/modules/memory/examples/adding_memory_chain_multiple_inputs.ipynb:10002
msgid "How to add memory to a Multi-Input Chain"
msgstr ""

#: ../docs/modules/memory/examples/adding_memory_chain_multiple_inputs.ipynb:10004
msgid "Most memory objects assume a single output. In this notebook, we go over how to add memory to a chain that has multiple outputs. As an example of such a chain, we will add memory to a question/answering chain. This chain takes as inputs both related documents and a user question."
msgstr ""

#: ../docs/modules/memory/examples/agent_with_memory.ipynb:10002
msgid "How to add Memory to an Agent"
msgstr ""

#: ../docs/modules/memory/examples/agent_with_memory.ipynb:10004
msgid "This notebook goes over adding memory to an Agent. Before going through this notebook, please walkthrough the following notebooks, as this will build on top of both of them:"
msgstr ""

#: ../docs/modules/memory/examples/agent_with_memory.ipynb:10006
#: ../docs/modules/memory/examples/agent_with_memory_in_db.ipynb:10006
msgid "[Adding memory to an LLM Chain](adding_memory.ipynb)"
msgstr ""

#: ../docs/modules/memory/examples/agent_with_memory.ipynb:10007
#: ../docs/modules/memory/examples/agent_with_memory_in_db.ipynb:10007
msgid "[Custom Agents](../../agents/examples/custom_agent.ipynb)"
msgstr ""

#: ../docs/modules/memory/examples/agent_with_memory.ipynb:10009
msgid "In order to add a memory to an agent we are going to the the following steps:"
msgstr ""

#: ../docs/modules/memory/examples/agent_with_memory.ipynb:10011
msgid "We are going to create an LLMChain with memory."
msgstr ""

#: ../docs/modules/memory/examples/agent_with_memory.ipynb:10012
msgid "We are going to use that LLMChain to create a custom Agent."
msgstr ""

#: ../docs/modules/memory/examples/agent_with_memory.ipynb:10014
#: ../docs/modules/memory/examples/agent_with_memory_in_db.ipynb:10016
msgid "For the purposes of this exercise, we are going to create a simple custom Agent that has access to a search tool and utilizes the `ConversationBufferMemory` class."
msgstr ""

#: ../docs/modules/memory/examples/agent_with_memory.ipynb:40002
#: ../docs/modules/memory/examples/agent_with_memory_in_db.ipynb:40002
msgid "Notice the usage of the `chat_history` variable in the PromptTemplate, which matches up with the dynamic key name in the ConversationBufferMemory."
msgstr ""

#: ../docs/modules/memory/examples/agent_with_memory.ipynb:110002
#: ../docs/modules/memory/examples/agent_with_memory_in_db.ipynb:130002
msgid "We can see that the agent remembered that the previous question was about Canada, and properly asked Google Search what the name of Canada's national anthem was."
msgstr ""

#: ../docs/modules/memory/examples/agent_with_memory.ipynb:110004
#: ../docs/modules/memory/examples/agent_with_memory_in_db.ipynb:130004
msgid "For fun, let's compare this to an agent that does NOT have memory."
msgstr ""

#: ../docs/modules/memory/examples/agent_with_memory_in_db.ipynb:10002
msgid "Adding Message Memory backed by a database to an Agent"
msgstr ""

#: ../docs/modules/memory/examples/agent_with_memory_in_db.ipynb:10004
msgid "This notebook goes over adding memory to an Agent where the memory uses an external message store. Before going through this notebook, please walkthrough the following notebooks, as this will build on top of both of them:"
msgstr ""

#: ../docs/modules/memory/examples/agent_with_memory_in_db.ipynb:10008
msgid "[Agent with Memory](agetn_with_memory.ipynb)"
msgstr ""

#: ../docs/modules/memory/examples/agent_with_memory_in_db.ipynb:10010
msgid "In order to add a memory with an external message store to an agent we are going to do the following steps:"
msgstr ""

#: ../docs/modules/memory/examples/agent_with_memory_in_db.ipynb:10012
msgid "We are going to create a `RedisChatMessageHistory` to connect to an external database to store the messages in."
msgstr ""

#: ../docs/modules/memory/examples/agent_with_memory_in_db.ipynb:10013
msgid "We are going to create an `LLMChain` using that chat history as memory."
msgstr ""

#: ../docs/modules/memory/examples/agent_with_memory_in_db.ipynb:10014
msgid "We are going to use that `LLMChain` to create a custom Agent."
msgstr ""

#: ../docs/modules/memory/examples/agent_with_memory_in_db.ipynb:60002
msgid "Now we can create the ChatMessageHistory backed by the database."
msgstr ""

#: ../docs/modules/memory/examples/conversational_customization.ipynb:10002
msgid "How to customize conversational memory"
msgstr ""

#: ../docs/modules/memory/examples/conversational_customization.ipynb:10004
msgid "This notebook walks through a few ways to customize conversational memory."
msgstr ""

#: ../docs/modules/memory/examples/conversational_customization.ipynb:30002
msgid "AI Prefix"
msgstr ""

#: ../docs/modules/memory/examples/conversational_customization.ipynb:30004
msgid "The first way to do so is by changing the AI prefix in the conversation summary. By default, this is set to \"AI\", but you can set this to be anything you want. Note that if you change this, you should also change the prompt used in the chain to reflect this naming change. Let's walk through an example of that in the example below."
msgstr ""

#: ../docs/modules/memory/examples/conversational_customization.ipynb:100002
msgid "Human Prefix"
msgstr ""

#: ../docs/modules/memory/examples/conversational_customization.ipynb:100004
msgid "The next way to do so is by changing the Human prefix in the conversation summary. By default, this is set to \"Human\", but you can set this to be anything you want. Note that if you change this, you should also change the prompt used in the chain to reflect this naming change. Let's walk through an example of that in the example below."
msgstr ""

#: ../docs/modules/memory/examples/custom_memory.ipynb:10002
msgid "How to create a custom Memory class"
msgstr ""

#: ../docs/modules/memory/examples/custom_memory.ipynb:10003
msgid "Although there are a few predefined types of memory in LangChain, it is highly possible you will want to add your own type of memory that is optimal for your application. This notebook covers how to do that."
msgstr ""

#: ../docs/modules/memory/examples/custom_memory.ipynb:20002
msgid "For this notebook, we will add a custom memory type to `ConversationChain`. In order to add a custom memory class, we need to import the base memory class and subclass it."
msgstr ""

#: ../docs/modules/memory/examples/custom_memory.ipynb:40002
msgid "In this example, we will write a custom memory class that uses spacy to extract entities and save information about them in a simple hash table. Then, during the conversation, we will look at the input text, extract any entities, and put any information about them into the context."
msgstr ""

#: ../docs/modules/memory/examples/custom_memory.ipynb:40004
msgid "Please note that this implementation is pretty simple and brittle and probably not useful in a production setting. Its purpose is to showcase that you can add custom memory implementations."
msgstr ""

#: ../docs/modules/memory/examples/custom_memory.ipynb:40006
msgid "For this, we will need spacy."
msgstr ""

#: ../docs/modules/memory/examples/custom_memory.ipynb:80002
msgid "We now define a prompt that takes in information about entities as well as user input"
msgstr ""

#: ../docs/modules/memory/examples/custom_memory.ipynb:100002
msgid "And now we put it all together!"
msgstr ""

#: ../docs/modules/memory/examples/custom_memory.ipynb:120002
msgid "In the first example, with no prior knowledge about Harrison, the \"Relevant entity information\" section is empty."
msgstr ""

#: ../docs/modules/memory/examples/custom_memory.ipynb:140002
msgid "Now in the second example, we can see that it pulls in information about Harrison."
msgstr ""

#: ../docs/modules/memory/examples/custom_memory.ipynb:160002
msgid "Again, please note that this implementation is pretty simple and brittle and probably not useful in a production setting. Its purpose is to showcase that you can add custom memory implementations."
msgstr ""

#: ../docs/modules/memory/examples/motorhead_memory.ipynb:10002
msgid "Mot√∂rhead Memory"
msgstr ""

#: ../docs/modules/memory/examples/motorhead_memory.ipynb:10003
msgid "[Mot√∂rhead](https://github.com/getmetal/motorhead) is a memory server implemented in Rust. It automatically handles incremental summarization in the background and allows for stateless applications."
msgstr ""

#: ../docs/modules/memory/examples/motorhead_memory.ipynb:10007
msgid "See instructions at [Mot√∂rhead](https://github.com/getmetal/motorhead) for running the server locally."
msgstr ""

#: ../docs/modules/memory/examples/multiple_memory.ipynb:10002
msgid "How to use multiple memory classes in the same chain"
msgstr ""

#: ../docs/modules/memory/examples/multiple_memory.ipynb:10003
msgid "It is also possible to use multiple memory classes in the same chain. To combine multiple memory classes, we can initialize the `CombinedMemory` class, and then use that."
msgstr ""

#: ../docs/modules/memory/examples/postgres_chat_message_history.ipynb:10002
msgid "Postgres Chat Message History"
msgstr ""

#: ../docs/modules/memory/examples/postgres_chat_message_history.ipynb:10004
msgid "This notebook goes over how to use Postgres to store chat message history."
msgstr ""

#: ../docs/modules/memory/examples/redis_chat_message_history.ipynb:10002
msgid "Redis Chat Message History"
msgstr ""

#: ../docs/modules/memory/examples/redis_chat_message_history.ipynb:10004
msgid "This notebook goes over how to use Redis to store chat message history."
msgstr ""

#: ../docs/modules/memory/getting_started.ipynb:10004
msgid "This notebook walks through how LangChain thinks about memory."
msgstr ""

#: ../docs/modules/memory/getting_started.ipynb:10006
msgid "Memory involves keeping a concept of state around throughout a user's interactions with an language model. A user's interactions with a language model are captured in the concept of ChatMessages, so this boils down to ingesting, capturing, transforming and extracting knowledge from a sequence of chat messages. There are many different ways to do this, each of which exists as its own memory type."
msgstr ""

#: ../docs/modules/memory/getting_started.ipynb:10008
msgid "In general, for each type of memory there are two ways to understanding using memory. These are the standalone functions which extract information from a sequence of messages, and then there is the way you can use this type of memory in a chain."
msgstr ""

#: ../docs/modules/memory/getting_started.ipynb:10010
msgid "Memory can return multiple pieces of information (for example, the most recent N messages and a summary of all previous messages). The returned information can either be a string or a list of messages."
msgstr ""

#: ../docs/modules/memory/getting_started.ipynb:10012
msgid "In this notebook, we will walk through the simplest form of memory: \"buffer\" memory, which just involves keeping a buffer of all prior messages. We will show how to use the modular utility functions here, then show how it can be used in a chain (both returning a string as well as a list of messages)."
msgstr ""

#: ../docs/modules/memory/getting_started.ipynb:10014
msgid "ChatMessageHistory"
msgstr ""

#: ../docs/modules/memory/getting_started.ipynb:10015
msgid "One of the core utility classes underpinning most (if not all) memory modules is the `ChatMessageHistory` class. This is a super lightweight wrapper which exposes convienence methods for saving Human messages, AI messages, and then fetching them all."
msgstr ""

#: ../docs/modules/memory/getting_started.ipynb:10017
msgid "You may want to use this class directly if you are managing memory outside of a chain."
msgstr ""

#: ../docs/modules/memory/getting_started.ipynb:40002
#: ../docs/modules/memory/types/buffer.ipynb:10002
msgid "ConversationBufferMemory"
msgstr ""

#: ../docs/modules/memory/getting_started.ipynb:40004
msgid "We now show how to use this simple concept in a chain. We first showcase `ConversationBufferMemory` which is just a wrapper around ChatMessageHistory that extracts the messages in a variable."
msgstr ""

#: ../docs/modules/memory/getting_started.ipynb:40006
#: ../docs/modules/memory/types/buffer.ipynb:10006
msgid "We can first extract it as a string."
msgstr ""

#: ../docs/modules/memory/getting_started.ipynb:80002
msgid "We can also get the history as a list of messages"
msgstr ""

#: ../docs/modules/memory/getting_started.ipynb:110002
#: ../docs/modules/memory/types/buffer.ipynb:80002
#: ../docs/modules/memory/types/buffer_window.ipynb:80002
#: ../docs/modules/memory/types/entity_summary_memory.ipynb:70002
#: ../docs/modules/memory/types/kg.ipynb:120002
#: ../docs/modules/memory/types/summary.ipynb:100002
#: ../docs/modules/memory/types/summary_buffer.ipynb:90002
#: ../docs/modules/memory/types/token_buffer.ipynb:70002
#: ../docs/modules/memory/types/vectorstore_retriever_memory.ipynb:80002
msgid "Using in a chain"
msgstr ""

#: ../docs/modules/memory/getting_started.ipynb:110003
#: ../docs/modules/memory/types/buffer.ipynb:80003
msgid "Finally, let's take a look at using this in a chain (setting `verbose=True` so we can see the prompt)."
msgstr ""

#: ../docs/modules/memory/getting_started.ipynb:160002
msgid "Saving Message History"
msgstr ""

#: ../docs/modules/memory/getting_started.ipynb:160004
msgid "You may often have to save messages, and then load them to use again. This can be done easily by first converting the messages to normal python dictionaries, saving those (as json or something) and then loading those. Here is an example of doing that."
msgstr ""

#: ../docs/modules/memory/getting_started.ipynb:220002
#: ../docs/modules/memory/types/buffer.ipynb:130002
msgid "And that's it for the getting started! There are plenty of different types of memory, check out our examples to see them all"
msgstr ""

#: ../docs/modules/memory/how_to_guides.rst:5
msgid "Types"
msgstr ""

#: ../docs/modules/memory/how_to_guides.rst:7
msgid "The first set of examples all highlight different types of memory."
msgstr ""

#: ../docs/modules/memory/how_to_guides.rst:20
msgid "The examples here all highlight how to use memory in different ways."
msgstr ""

#: ../docs/modules/memory/types/buffer.ipynb:10004
msgid "This notebook shows how to use `ConversationBufferMemory`. This memory allows for storing of messages and then extracts the messages in a variable."
msgstr ""

#: ../docs/modules/memory/types/buffer.ipynb:50002
#: ../docs/modules/memory/types/buffer_window.ipynb:50002
#: ../docs/modules/memory/types/kg.ipynb:50002
#: ../docs/modules/memory/types/summary.ipynb:50002
#: ../docs/modules/memory/types/summary_buffer.ipynb:50002
#: ../docs/modules/memory/types/token_buffer.ipynb:50002
msgid "We can also get the history as a list of messages (this is useful if you are using this with a chat model)."
msgstr ""

#: ../docs/modules/memory/types/buffer_window.ipynb:10002
msgid "ConversationBufferWindowMemory"
msgstr ""

#: ../docs/modules/memory/types/buffer_window.ipynb:10004
msgid "`ConversationBufferWindowMemory` keeps a list of the interactions of the conversation over time. It only uses the last K interactions. This can be useful for keeping a sliding window of the most recent interactions, so the buffer does not get too large"
msgstr ""

#: ../docs/modules/memory/types/buffer_window.ipynb:10006
#: ../docs/modules/memory/types/summary.ipynb:10005
msgid "Let's first explore the basic functionality of this type of memory."
msgstr ""

#: ../docs/modules/memory/types/buffer_window.ipynb:80003
#: ../docs/modules/memory/types/summary_buffer.ipynb:90003
#: ../docs/modules/memory/types/token_buffer.ipynb:70003
#: ../docs/modules/memory/types/vectorstore_retriever_memory.ipynb:80003
msgid "Let's walk through an example, again setting `verbose=True` so we can see the prompt."
msgstr ""

#: ../docs/modules/memory/types/entity_summary_memory.ipynb:10002
msgid "Entity Memory"
msgstr ""

#: ../docs/modules/memory/types/entity_summary_memory.ipynb:10003
msgid "This notebook shows how to work with a memory module that remembers things about specific entities. It extracts information on entities (using LLMs) and builds up its knowledge about that entity over time (also using LLMs)."
msgstr ""

#: ../docs/modules/memory/types/entity_summary_memory.ipynb:10005
msgid "Let's first walk through using this functionality."
msgstr ""

#: ../docs/modules/memory/types/entity_summary_memory.ipynb:70003
msgid "Let's now use it in a chain!"
msgstr ""

#: ../docs/modules/memory/types/entity_summary_memory.ipynb:150002
msgid "Inspecting the memory store"
msgstr ""

#: ../docs/modules/memory/types/entity_summary_memory.ipynb:150003
msgid "We can also inspect the memory store directly. In the following examaples, we look at it directly, and then go through some examples of adding information and watch how it changes."
msgstr ""

#: ../docs/modules/memory/types/kg.ipynb:10002
msgid "Conversation Knowledge Graph Memory"
msgstr ""

#: ../docs/modules/memory/types/kg.ipynb:10004
msgid "This type of memory uses a knowledge graph to recreate memory."
msgstr ""

#: ../docs/modules/memory/types/kg.ipynb:10006
#: ../docs/modules/memory/types/summary_buffer.ipynb:10006
#: ../docs/modules/memory/types/token_buffer.ipynb:10006
msgid "Let's first walk through how to use the utilities"
msgstr ""

#: ../docs/modules/memory/types/kg.ipynb:80002
msgid "We can also more modularly get current entities from a new message (will use previous messages as context.)"
msgstr ""

#: ../docs/modules/memory/types/kg.ipynb:100002
msgid "We can also more modularly get knowledge triplets from a new message (will use previous messages as context.)"
msgstr ""

#: ../docs/modules/memory/types/kg.ipynb:120003
msgid "Let's now use this in a chain!"
msgstr ""

#: ../docs/modules/memory/types/summary.ipynb:10002
msgid "ConversationSummaryMemory"
msgstr ""

#: ../docs/modules/memory/types/summary.ipynb:10003
msgid "Now let's take a look at using a slightly more complex type of memory - `ConversationSummaryMemory`. This type of memory creates a summary of the conversation over time. This can be useful for condensing information from the conversation over time."
msgstr ""

#: ../docs/modules/memory/types/summary.ipynb:80002
#: ../docs/modules/memory/types/summary_buffer.ipynb:70002
msgid "We can also utilize the `predict_new_summary` method directly."
msgstr ""

#: ../docs/modules/memory/types/summary.ipynb:100003
msgid "Let's walk through an example of using this in a chain, again setting `verbose=True` so we can see the prompt."
msgstr ""

#: ../docs/modules/memory/types/summary_buffer.ipynb:10002
msgid "ConversationSummaryBufferMemory"
msgstr ""

#: ../docs/modules/memory/types/summary_buffer.ipynb:10004
msgid "`ConversationSummaryBufferMemory` combines the last two ideas. It keeps a buffer of recent interactions in memory, but rather than just completely flushing old interactions it compiles them into a summary and uses both. Unlike the previous implementation though, it uses token length rather than number of interactions to determine when to flush interactions."
msgstr ""

#: ../docs/modules/memory/types/token_buffer.ipynb:10002
msgid "ConversationTokenBufferMemory"
msgstr ""

#: ../docs/modules/memory/types/token_buffer.ipynb:10004
msgid "`ConversationTokenBufferMemory` keeps a buffer of recent interactions in memory, and uses token length rather than number of interactions to determine when to flush interactions."
msgstr ""

#: ../docs/modules/memory/types/vectorstore_retriever_memory.ipynb:10002
msgid "VectorStore-Backed Memory"
msgstr ""

#: ../docs/modules/memory/types/vectorstore_retriever_memory.ipynb:10004
msgid "`VectorStoreRetrieverMemory` stores memories in a VectorDB and queries the top-K most \"salient\" docs every time it is called."
msgstr ""

#: ../docs/modules/memory/types/vectorstore_retriever_memory.ipynb:10006
msgid "This differs from most of the other Memory classes in that it doesn't explicitly track the order of interactions."
msgstr ""

#: ../docs/modules/memory/types/vectorstore_retriever_memory.ipynb:10008
msgid "In this case, the \"docs\" are previous conversation snippets. This can be useful to refer to relevant pieces of information that the AI was told earlier in the conversation."
msgstr ""

#: ../docs/modules/memory/types/vectorstore_retriever_memory.ipynb:30002
msgid "Initialize your VectorStore"
msgstr ""

#: ../docs/modules/memory/types/vectorstore_retriever_memory.ipynb:30004
msgid "Depending on the store you choose, this step may look different. Consult the relevant VectorStore documentation for more details."
msgstr ""

#: ../docs/modules/memory/types/vectorstore_retriever_memory.ipynb:50002
msgid "Create your the VectorStoreRetrieverMemory"
msgstr ""

#: ../docs/modules/memory/types/vectorstore_retriever_memory.ipynb:50004
msgid "The memory object is instantiated from any VectorStoreRetriever."
msgstr ""

#: ../docs/modules/models.rst:2
msgid "Models"
msgstr ""

#: ../docs/modules/models.rst:5
msgid "`Conceptual Guide <https://docs.langchain.com/docs/components/models>`_"
msgstr ""

#: ../docs/modules/models.rst:8
msgid "This section of the documentation deals with different types of models that are used in LangChain. On this page we will go over the model types at a high level, but we have individual pages for each model type. The pages contain more detailed \"how-to\" guides for working with that model, as well as a list of different model providers."
msgstr ""

#: ../docs/modules/models.rst:14
msgid "**LLMs**"
msgstr ""

#: ../docs/modules/models.rst:16
msgid "Large Language Models (LLMs) are the first type of models we cover. These models take a text string as input, and return a text string as output."
msgstr ""

#: ../docs/modules/models.rst:20
msgid "**Chat Models**"
msgstr ""

#: ../docs/modules/models.rst:22
msgid "Chat Models are the second type of models we cover. These models are usually backed by a language model, but their APIs are more structured. Specifically, these models take a list of Chat Messages as input, and return a Chat Message."
msgstr ""

#: ../docs/modules/models.rst:26
msgid "**Text Embedding Models**"
msgstr ""

#: ../docs/modules/models.rst:28
msgid "The third type of models we cover are text embedding models. These models take text as input and return a list of floats."
msgstr ""

#: ../docs/modules/models/chat.rst:2
msgid "Chat Models"
msgstr ""

#: ../docs/modules/models/chat.rst:5
msgid "`Conceptual Guide <https://docs.langchain.com/docs/components/models/chat-model>`_"
msgstr ""

#: ../docs/modules/models/chat.rst:8
msgid "Chat models are a variation on language models. While chat models use language models under the hood, the interface they expose is a bit different. Rather than expose a \"text in, text out\" API, they expose an interface where \"chat messages\" are the inputs and outputs."
msgstr ""

#: ../docs/modules/models/chat.rst:12
msgid "Chat model APIs are fairly new, so we are still figuring out the correct abstractions."
msgstr ""

#: ../docs/modules/models/chat.rst:16
msgid "`Getting Started <./chat/getting_started.html>`_: An overview of all the functionality the LangChain LLM class provides."
msgstr ""

#: ../docs/modules/models/chat.rst:18
msgid "`How-To Guides <./chat/how_to_guides.html>`_: A collection of how-to guides. These highlight how to accomplish various objectives with our LLM class (streaming, async, etc)."
msgstr ""

#: ../docs/modules/models/chat.rst:20
msgid "`Integrations <./chat/integrations.html>`_: A collection of examples on how to integrate different LLM providers with LangChain (OpenAI, Hugging Face, etc)."
msgstr ""

#: ../docs/modules/models/chat/examples/few_shot_examples.ipynb:10002
msgid "How to use few shot examples"
msgstr ""

#: ../docs/modules/models/chat/examples/few_shot_examples.ipynb:10004
msgid "This notebook covers how to use few shot examples in chat models."
msgstr ""

#: ../docs/modules/models/chat/examples/few_shot_examples.ipynb:10006
msgid "There does not appear to be solid consensus on how best to do few shot prompting. As a result, we are not solidifying any abstractions around this yet but rather using existing abstractions."
msgstr ""

#: ../docs/modules/models/chat/examples/few_shot_examples.ipynb:20002
msgid "Alternating Human/AI messages"
msgstr ""

#: ../docs/modules/models/chat/examples/few_shot_examples.ipynb:20003
msgid "The first way of doing few shot prompting relies on using alternating human/ai messages. See an example of this below."
msgstr ""

#: ../docs/modules/models/chat/examples/few_shot_examples.ipynb:70002
msgid "System Messages"
msgstr ""

#: ../docs/modules/models/chat/examples/few_shot_examples.ipynb:70004
msgid "OpenAI provides an optional `name` parameter that they also recommend using in conjunction with system messages to do few shot prompting. Here is an example of how to do that below."
msgstr ""

#: ../docs/modules/models/chat/examples/streaming.ipynb:10002
msgid "How to stream responses"
msgstr ""

#: ../docs/modules/models/chat/examples/streaming.ipynb:10004
msgid "This notebook goes over how to use streaming with a chat model."
msgstr ""

#: ../docs/modules/models/chat/getting_started.ipynb:10004
msgid "This notebook covers how to get started with chat models. The interface is based around messages rather than raw text."
msgstr ""

#: ../docs/modules/models/chat/getting_started.ipynb:40002
msgid "You can get chat completions by passing one or more messages to the chat model. The response will be a message. The types of messages currently supported in LangChain are `AIMessage`, `HumanMessage`, `SystemMessage`, and `ChatMessage` -- `ChatMessage` takes in an arbitrary role parameter. Most of the time, you'll just be dealing with `HumanMessage`, `AIMessage`, and `SystemMessage`"
msgstr ""

#: ../docs/modules/models/chat/getting_started.ipynb:60002
msgid "OpenAI's chat model supports multiple messages as input. See [here](https://platform.openai.com/docs/guides/chat/chat-vs-completions) for more information. Here is an example of sending a system and user message to the chat model:"
msgstr ""

#: ../docs/modules/models/chat/getting_started.ipynb:80002
msgid "You can go one step further and generate completions for multiple sets of messages using `generate`. This returns an `LLMResult` with an additional `message` parameter."
msgstr ""

#: ../docs/modules/models/chat/getting_started.ipynb:100002
msgid "You can recover things like token usage from this LLMResult"
msgstr ""

#: ../docs/modules/models/chat/getting_started.ipynb:120002
msgid "PromptTemplates"
msgstr ""

#: ../docs/modules/models/chat/getting_started.ipynb:130002
#: ../docs/modules/models/chat/integrations/openai.ipynb:50002
#: ../docs/modules/prompts/chat_prompt_template.ipynb:30002
msgid "You can make use of templating by using a `MessagePromptTemplate`. You can build a `ChatPromptTemplate` from one or more `MessagePromptTemplates`. You can use `ChatPromptTemplate`'s `format_prompt` -- this returns a `PromptValue`, which you can convert to a string or Message object, depending on whether you want to use the formatted value as input to an llm or chat model."
msgstr ""

#: ../docs/modules/models/chat/getting_started.ipynb:130004
#: ../docs/modules/models/chat/integrations/openai.ipynb:50004
msgid "For convience, there is a `from_template` method exposed on the template. If you were to use this template, this is what it would look like:"
msgstr ""

#: ../docs/modules/models/chat/getting_started.ipynb:160002
#: ../docs/modules/prompts/chat_prompt_template.ipynb:60002
msgid "If you wanted to construct the MessagePromptTemplate more directly, you could create a PromptTemplate outside and then pass it in, eg:"
msgstr ""

#: ../docs/modules/models/chat/getting_started.ipynb:180002
msgid "LLMChain"
msgstr ""

#: ../docs/modules/models/chat/getting_started.ipynb:180003
msgid "You can use the existing LLMChain in a very similar way to before - provide a prompt and a model."
msgstr ""

#: ../docs/modules/models/chat/getting_started.ipynb:210002
msgid "Streaming"
msgstr ""

#: ../docs/modules/models/chat/getting_started.ipynb:210004
msgid "Streaming is supported for `ChatOpenAI` through callback handling."
msgstr ""

#: ../docs/modules/models/chat/how_to_guides.rst:4
msgid "The examples here all address certain \"how-to\" guides for working with chat models."
msgstr ""

#: ../docs/modules/models/chat/integrations.rst:2
#: ../docs/modules/models/llms/integrations.rst:2
msgid "Integrations"
msgstr ""

#: ../docs/modules/models/chat/integrations.rst:4
msgid "The examples here all highlight how to integrate with different chat models."
msgstr ""

#: ../docs/modules/models/chat/integrations/anthropic.ipynb:10002
msgid "Anthropic"
msgstr ""

#: ../docs/modules/models/chat/integrations/anthropic.ipynb:10004
msgid "This notebook covers how to get started with Anthropic chat models."
msgstr ""

#: ../docs/modules/models/chat/integrations/anthropic.ipynb:50002
msgid "`ChatAnthropic` also supports async and streaming functionality:"
msgstr ""

#: ../docs/modules/models/chat/integrations/azure_chat_openai.ipynb:10002
msgid "Azure"
msgstr ""

#: ../docs/modules/models/chat/integrations/azure_chat_openai.ipynb:10004
msgid "This notebook goes over how to connect to an Azure hosted OpenAI endpoint"
msgstr ""

#: ../docs/modules/models/chat/integrations/openai.ipynb:10002
#: ../docs/modules/models/llms/integrations/openai.ipynb:10002
#: ../docs/modules/models/text_embedding/examples/openai.ipynb:10002
msgid "OpenAI"
msgstr ""

#: ../docs/modules/models/chat/integrations/openai.ipynb:10004
msgid "This notebook covers how to get started with OpenAI chat models."
msgstr ""

#: ../docs/modules/models/chat/integrations/promptlayer_chatopenai.ipynb:10002
msgid "PromptLayer ChatOpenAI"
msgstr ""

#: ../docs/modules/models/chat/integrations/promptlayer_chatopenai.ipynb:10004
msgid "This example showcases how to connect to [PromptLayer](https://www.promptlayer.com) to start recording your ChatOpenAI requests."
msgstr ""

#: ../docs/modules/models/chat/integrations/promptlayer_chatopenai.ipynb:20002
#: ../docs/modules/models/llms/integrations/promptlayer_openai.ipynb:20002
msgid "Install PromptLayer"
msgstr ""

#: ../docs/modules/models/chat/integrations/promptlayer_chatopenai.ipynb:20003
#: ../docs/modules/models/llms/integrations/promptlayer_openai.ipynb:20003
msgid "The `promptlayer` package is required to use PromptLayer with OpenAI. Install `promptlayer` using pip."
msgstr ""

#: ../docs/modules/models/chat/integrations/promptlayer_chatopenai.ipynb:40002
#: ../docs/modules/models/llms/integrations/cerebriumai_example.ipynb:40002
#: ../docs/modules/models/llms/integrations/deepinfra_example.ipynb:20002
#: ../docs/modules/models/llms/integrations/forefrontai_example.ipynb:20002
#: ../docs/modules/models/llms/integrations/gooseai_example.ipynb:40002
#: ../docs/modules/models/llms/integrations/petals_example.ipynb:40002
#: ../docs/modules/models/llms/integrations/promptlayer_openai.ipynb:40002
msgid "Imports"
msgstr ""

#: ../docs/modules/models/chat/integrations/promptlayer_chatopenai.ipynb:60002
#: ../docs/modules/models/llms/integrations/cerebriumai_example.ipynb:60002
#: ../docs/modules/models/llms/integrations/deepinfra_example.ipynb:40002
#: ../docs/modules/models/llms/integrations/forefrontai_example.ipynb:40002
#: ../docs/modules/models/llms/integrations/gooseai_example.ipynb:60002
#: ../docs/modules/models/llms/integrations/petals_example.ipynb:60002
#: ../docs/modules/models/llms/integrations/promptlayer_openai.ipynb:60002
msgid "Set the Environment API Key"
msgstr ""

#: ../docs/modules/models/chat/integrations/promptlayer_chatopenai.ipynb:60003
#: ../docs/modules/models/llms/integrations/promptlayer_openai.ipynb:60003
msgid "You can create a PromptLayer API Key at [www.promptlayer.com](https://www.promptlayer.com) by clicking the settings cog in the navbar."
msgstr ""

#: ../docs/modules/models/chat/integrations/promptlayer_chatopenai.ipynb:60005
#: ../docs/modules/models/llms/integrations/promptlayer_openai.ipynb:60005
msgid "Set it as an environment variable called `PROMPTLAYER_API_KEY`."
msgstr ""

#: ../docs/modules/models/chat/integrations/promptlayer_chatopenai.ipynb:80002
#: ../docs/modules/models/llms/integrations/promptlayer_openai.ipynb:110002
msgid "Use the PromptLayerOpenAI LLM like normal"
msgstr ""

#: ../docs/modules/models/chat/integrations/promptlayer_chatopenai.ipynb:80003
#: ../docs/modules/models/llms/integrations/promptlayer_openai.ipynb:110003
msgid "*You can optionally pass in `pl_tags` to track your requests with PromptLayer's tagging feature.*"
msgstr ""

#: ../docs/modules/models/chat/integrations/promptlayer_chatopenai.ipynb:100002
#: ../docs/modules/models/llms/integrations/promptlayer_openai.ipynb:130002
msgid "**The above request should now appear on your [PromptLayer dashboard](https://www.promptlayer.com).**"
msgstr ""

#: ../docs/modules/models/chat/integrations/promptlayer_chatopenai.ipynb:120002
#: ../docs/modules/models/llms/integrations/promptlayer_openai.ipynb:140002
msgid "Using PromptLayer Track"
msgstr ""

#: ../docs/modules/models/chat/integrations/promptlayer_chatopenai.ipynb:120003
#: ../docs/modules/models/llms/integrations/promptlayer_openai.ipynb:140003
msgid "If you would like to use any of the [PromptLayer tracking features](https://magniv.notion.site/Track-4deee1b1f7a34c1680d085f82567dab9), you need to pass the argument `return_pl_id` when instantializing the PromptLayer LLM to get the request id."
msgstr ""

#: ../docs/modules/models/chat/integrations/promptlayer_chatopenai.ipynb:140002
#: ../docs/modules/models/llms/integrations/promptlayer_openai.ipynb:160002
msgid "Using this allows you to track the performance of your model in the PromptLayer dashboard. If you are using a prompt template, you can attach a template to a request as well. Overall, this gives you the opportunity to track the performance of different templates and models in the PromptLayer dashboard."
msgstr ""

#: ../docs/modules/models/llms.rst:2
msgid "LLMs"
msgstr ""

#: ../docs/modules/models/llms.rst:5
msgid "`Conceptual Guide <https://docs.langchain.com/docs/components/models/language-model>`_"
msgstr ""

#: ../docs/modules/models/llms.rst:8
msgid "Large Language Models (LLMs) are a core component of LangChain. LangChain is not a provider of LLMs, but rather provides a standard interface through which you can interact with a variety of LLMs."
msgstr ""

#: ../docs/modules/models/llms.rst:14
msgid "`Getting Started <./llms/getting_started.html>`_: An overview of all the functionality the LangChain LLM class provides."
msgstr ""

#: ../docs/modules/models/llms.rst:16
msgid "`How-To Guides <./llms/how_to_guides.html>`_: A collection of how-to guides. These highlight how to accomplish various objectives with our LLM class (streaming, async, etc)."
msgstr ""

#: ../docs/modules/models/llms.rst:18
msgid "`Integrations <./llms/integrations.html>`_: A collection of examples on how to integrate different LLM providers with LangChain (OpenAI, Hugging Face, etc)."
msgstr ""

#: ../docs/modules/models/llms.rst:20
msgid "`Reference <../../reference/modules/llms.html>`_: API reference documentation for all LLM classes."
msgstr ""

#: ../docs/modules/models/llms/examples/async_llm.ipynb:10002
msgid "How to use the async API for LLMs"
msgstr ""

#: ../docs/modules/models/llms/examples/async_llm.ipynb:10004
msgid "LangChain provides async support for LLMs by leveraging the [asyncio](https://docs.python.org/3/library/asyncio.html) library."
msgstr ""

#: ../docs/modules/models/llms/examples/async_llm.ipynb:10006
msgid "Async support is particularly useful for calling multiple LLMs concurrently, as these calls are network-bound. Currently, `OpenAI`, `PromptLayerOpenAI`, `ChatOpenAI` and `Anthropic` are supported, but async support for other LLMs is on the roadmap."
msgstr ""

#: ../docs/modules/models/llms/examples/async_llm.ipynb:10008
msgid "You can use the `agenerate` method to call an OpenAI LLM asynchronously."
msgstr ""

#: ../docs/modules/models/llms/examples/custom_llm.ipynb:10002
msgid "How to write a custom LLM wrapper"
msgstr ""

#: ../docs/modules/models/llms/examples/custom_llm.ipynb:10004
msgid "This notebook goes over how to create a custom LLM wrapper, in case you want to use your own LLM or a different wrapper than one that is supported in LangChain."
msgstr ""

#: ../docs/modules/models/llms/examples/custom_llm.ipynb:10006
msgid "There is only one required thing that a custom LLM needs to implement:"
msgstr ""

#: ../docs/modules/models/llms/examples/custom_llm.ipynb:10008
msgid "A `_call` method that takes in a string, some optional stop words, and returns a string"
msgstr ""

#: ../docs/modules/models/llms/examples/custom_llm.ipynb:10010
msgid "There is a second optional thing it can implement:"
msgstr ""

#: ../docs/modules/models/llms/examples/custom_llm.ipynb:10012
msgid "An `_identifying_params` property that is used to help with printing of this class. Should return a dictionary."
msgstr ""

#: ../docs/modules/models/llms/examples/custom_llm.ipynb:10014
msgid "Let's implement a very simple custom LLM that just returns the first N characters of the input."
msgstr ""

#: ../docs/modules/models/llms/examples/custom_llm.ipynb:40002
msgid "We can now use this as an any other LLM."
msgstr ""

#: ../docs/modules/models/llms/examples/custom_llm.ipynb:70002
#: ../docs/modules/models/llms/integrations/azure_openai_example.ipynb:60002
msgid "We can also print the LLM and see its custom print."
msgstr ""

#: ../docs/modules/models/llms/examples/fake_llm.ipynb:10002
msgid "How (and why) to use the fake LLM"
msgstr ""

#: ../docs/modules/models/llms/examples/fake_llm.ipynb:10003
msgid "We expose a fake LLM class that can be used for testing. This allows you to mock out calls to the LLM and simulate what would happen if the LLM responded in a certain way."
msgstr ""

#: ../docs/modules/models/llms/examples/fake_llm.ipynb:10005
msgid "In this notebook we go over how to use this."
msgstr ""

#: ../docs/modules/models/llms/examples/fake_llm.ipynb:10007
msgid "We start this with using the FakeLLM in an agent."
msgstr ""

#: ../docs/modules/models/llms/examples/llm_caching.ipynb:10002
msgid "How to cache LLM calls"
msgstr ""

#: ../docs/modules/models/llms/examples/llm_caching.ipynb:10003
msgid "This notebook covers how to cache results of individual LLM calls."
msgstr ""

#: ../docs/modules/models/llms/examples/llm_caching.ipynb:30002
msgid "In Memory Cache"
msgstr ""

#: ../docs/modules/models/llms/examples/llm_caching.ipynb:80002
msgid "SQLite Cache"
msgstr ""

#: ../docs/modules/models/llms/examples/llm_caching.ipynb:130002
msgid "Redis Cache"
msgstr ""

#: ../docs/modules/models/llms/examples/llm_caching.ipynb:170002
msgid "GPTCache"
msgstr ""

#: ../docs/modules/models/llms/examples/llm_caching.ipynb:170004
msgid "We can use [GPTCache](https://github.com/zilliztech/GPTCache) for exact match caching OR to cache results based on semantic similarity"
msgstr ""

#: ../docs/modules/models/llms/examples/llm_caching.ipynb:170006
msgid "Let's first start with an example of exact match"
msgstr ""

#: ../docs/modules/models/llms/examples/llm_caching.ipynb:210002
msgid "Let's now show an example of similarity caching"
msgstr ""

#: ../docs/modules/models/llms/examples/llm_caching.ipynb:260002
msgid "SQLAlchemy Cache"
msgstr ""

#: ../docs/modules/models/llms/examples/llm_caching.ipynb:280002
msgid "Custom SQLAlchemy Schemas"
msgstr ""

#: ../docs/modules/models/llms/examples/llm_caching.ipynb:300002
msgid "Optional Caching"
msgstr ""

#: ../docs/modules/models/llms/examples/llm_caching.ipynb:300003
msgid "You can also turn off caching for specific LLMs should you choose. In the example below, even though global caching is enabled, we turn it off for a specific LLM"
msgstr ""

#: ../docs/modules/models/llms/examples/llm_caching.ipynb:340002
msgid "Optional Caching in Chains"
msgstr ""

#: ../docs/modules/models/llms/examples/llm_caching.ipynb:340003
msgid "You can also turn off caching for particular nodes in chains. Note that because of certain interfaces, its often easier to construct the chain first, and then edit the LLM afterwards."
msgstr ""

#: ../docs/modules/models/llms/examples/llm_caching.ipynb:340005
msgid "As an example, we will load a summarizer map-reduce chain. We will cache results for the map-step, but then not freeze it for the combine step."
msgstr ""

#: ../docs/modules/models/llms/examples/llm_caching.ipynb:410002
msgid "When we run it again, we see that it runs substantially faster but the final answer is different. This is due to caching at the map steps, but not at the reduce step."
msgstr ""

#: ../docs/modules/models/llms/examples/llm_serialization.ipynb:10002
msgid "How to serialize LLM classes"
msgstr ""

#: ../docs/modules/models/llms/examples/llm_serialization.ipynb:10004
msgid "This notebook walks through how to write and read an LLM Configuration to and from disk. This is useful if you want to save the configuration for a given LLM (e.g., the provider, the temperature, etc)."
msgstr ""

#: ../docs/modules/models/llms/examples/llm_serialization.ipynb:30002
msgid "Loading"
msgstr ""

#: ../docs/modules/models/llms/examples/llm_serialization.ipynb:30003
msgid "First, lets go over loading an LLM from disk. LLMs can be saved on disk in two formats: json or yaml. No matter the extension, they are loaded in the same way."
msgstr ""

#: ../docs/modules/models/llms/examples/llm_serialization.ipynb:80002
msgid "Saving"
msgstr ""

#: ../docs/modules/models/llms/examples/llm_serialization.ipynb:80003
msgid "If you want to go from an LLM in memory to a serialized version of it, you can do so easily by calling the `.save` method. Again, this supports both json and yaml."
msgstr ""

#: ../docs/modules/models/llms/examples/streaming_llm.ipynb:10002
msgid "How to stream LLM and Chat Model responses"
msgstr ""

#: ../docs/modules/models/llms/examples/streaming_llm.ipynb:10004
msgid "LangChain provides streaming support for LLMs. Currently, we support streaming for the `OpenAI`, `ChatOpenAI`. and `Anthropic` implementations, but streaming support for other LLM implementations is on the roadmap. To utilize streaming, use a [`CallbackHandler`](https://github.com/hwchase17/langchain/blob/master/langchain/callbacks/base.py) that implements `on_llm_new_token`. In this example, we are using [`StreamingStdOutCallbackHandler`]()."
msgstr ""

#: ../docs/modules/models/llms/examples/streaming_llm.ipynb:40002
msgid "We still have access to the end `LLMResult` if using `generate`. However, `token_usage` is not currently supported for streaming."
msgstr ""

#: ../docs/modules/models/llms/examples/streaming_llm.ipynb:60002
msgid "Here's an example with the `ChatOpenAI` chat model implementation:"
msgstr ""

#: ../docs/modules/models/llms/examples/streaming_llm.ipynb:80002
msgid "Here is an example with the `Anthropic` LLM implementation, which uses their `claude` model."
msgstr ""

#: ../docs/modules/models/llms/examples/token_usage_tracking.ipynb:10002
msgid "How to track token usage"
msgstr ""

#: ../docs/modules/models/llms/examples/token_usage_tracking.ipynb:10004
msgid "This notebook goes over how to track your token usage for specific calls. It is currently only implemented for the OpenAI API."
msgstr ""

#: ../docs/modules/models/llms/examples/token_usage_tracking.ipynb:10006
msgid "Let's first look at an extremely simple example of tracking token usage for a single LLM call."
msgstr ""

#: ../docs/modules/models/llms/examples/token_usage_tracking.ipynb:50002
msgid "Anything inside the context manager will get tracked. Here's an example of using it to track multiple calls in sequence."
msgstr ""

#: ../docs/modules/models/llms/examples/token_usage_tracking.ipynb:70002
msgid "If a chain or agent with multiple steps in it is used, it will track all those steps."
msgstr ""

#: ../docs/modules/models/llms/getting_started.ipynb:10004
msgid "This notebook goes over how to use the LLM class in LangChain."
msgstr ""

#: ../docs/modules/models/llms/getting_started.ipynb:10006
msgid "The LLM class is a class designed for interfacing with LLMs. There are lots of LLM providers (OpenAI, Cohere, Hugging Face, etc) - this class is designed to provide a standard interface for all of them. In this part of the documentation, we will focus on generic LLM functionality. For details on working with a specific LLM wrapper, please see the examples in the [How-To section](how_to_guides.rst)."
msgstr ""

#: ../docs/modules/models/llms/getting_started.ipynb:10008
msgid "For this notebook, we will work with an OpenAI LLM wrapper, although the functionalities highlighted are generic for all LLM types."
msgstr ""

#: ../docs/modules/models/llms/getting_started.ipynb:40002
msgid "**Generate Text:** The most basic functionality an LLM has is just the ability to call it, passing in a string and getting back a string."
msgstr ""

#: ../docs/modules/models/llms/getting_started.ipynb:60002
msgid "**Generate:** More broadly, you can call it with a list of inputs, getting back a more complete response than just the text. This complete response includes things like multiple top responses, as well as LLM provider specific information"
msgstr ""

#: ../docs/modules/models/llms/getting_started.ipynb:110002
msgid "You can also access provider specific information that is returned. This information is NOT standardized across providers."
msgstr ""

#: ../docs/modules/models/llms/getting_started.ipynb:130002
msgid "**Number of Tokens:** You can also estimate how many tokens a piece of text will be in that model. This is useful because models have a context length (and cost more for more tokens), which means you need to be aware of how long the text you are passing in is."
msgstr ""

#: ../docs/modules/models/llms/getting_started.ipynb:130004
msgid "Notice that by default the tokens are estimated using [tiktoken](https://github.com/openai/tiktoken) (except for legacy version <3.8, where a Hugging Face tokenizer is used)"
msgstr ""

#: ../docs/modules/models/llms/how_to_guides.rst:2
msgid "Generic Functionality"
msgstr ""

#: ../docs/modules/models/llms/how_to_guides.rst:4
msgid "The examples here all address certain \"how-to\" guides for working with LLMs."
msgstr ""

#: ../docs/modules/models/llms/integrations.rst:4
msgid "The examples here are all \"how-to\" guides for how to integrate with various LLM providers."
msgstr ""

#: ../docs/modules/models/llms/integrations/ai21.ipynb:10002
msgid "AI21"
msgstr ""

#: ../docs/modules/models/llms/integrations/ai21.ipynb:10004
msgid "[AI21 Studio](https://docs.ai21.com/) provides API access to `Jurassic-2` large language models."
msgstr ""

#: ../docs/modules/models/llms/integrations/ai21.ipynb:10006
msgid "This example goes over how to use LangChain to interact with [AI21 models](https://docs.ai21.com/docs/jurassic-2-models)."
msgstr ""

#: ../docs/modules/models/llms/integrations/aleph_alpha.ipynb:10002
#: ../docs/modules/models/text_embedding/examples/aleph_alpha.ipynb:10002
msgid "Aleph Alpha"
msgstr ""

#: ../docs/modules/models/llms/integrations/aleph_alpha.ipynb:10004
msgid "[The Luminous series](https://docs.aleph-alpha.com/docs/introduction/luminous/) is a family of large language models."
msgstr ""

#: ../docs/modules/models/llms/integrations/aleph_alpha.ipynb:10006
msgid "This example goes over how to use LangChain to interact with Aleph Alpha models"
msgstr ""

#: ../docs/modules/models/llms/integrations/azure_openai_example.ipynb:10002
msgid "Azure OpenAI"
msgstr ""

#: ../docs/modules/models/llms/integrations/azure_openai_example.ipynb:10004
msgid "This notebook goes over how to use Langchain with [Azure OpenAI](https://aka.ms/azure-openai)."
msgstr ""

#: ../docs/modules/models/llms/integrations/azure_openai_example.ipynb:10006
msgid "The Azure OpenAI API is compatible with OpenAI's API.  The `openai` Python package makes it easy to use both OpenAI and Azure OpenAI.  You can call Azure OpenAI the same way you call OpenAI with the exceptions noted below."
msgstr ""

#: ../docs/modules/models/llms/integrations/azure_openai_example.ipynb:10008
msgid "API configuration"
msgstr ""

#: ../docs/modules/models/llms/integrations/azure_openai_example.ipynb:10009
msgid "You can configure the `openai` package to use Azure OpenAI using environment variables.  The following is for `bash`:"
msgstr ""

#: ../docs/modules/models/llms/integrations/azure_openai_example.ipynb:10022
msgid "Alternatively, you can configure the API right within your running Python environment:"
msgstr ""

#: ../docs/modules/models/llms/integrations/azure_openai_example.ipynb:10030
msgid "Deployments"
msgstr ""

#: ../docs/modules/models/llms/integrations/azure_openai_example.ipynb:10031
msgid "With Azure OpenAI, you set up your own deployments of the common GPT-3 and Codex models.  When calling the API, you need to specify the deployment you want to use."
msgstr ""

#: ../docs/modules/models/llms/integrations/azure_openai_example.ipynb:10033
msgid "Let's say your deployment name is `text-davinci-002-prod`.  In the `openai` Python API, you can specify this deployment with the `engine` parameter.  For example:"
msgstr ""

#: ../docs/modules/models/llms/integrations/banana.ipynb:10002
msgid "Banana"
msgstr ""

#: ../docs/modules/models/llms/integrations/banana.ipynb:10005
msgid "[Banana](https://www.banana.dev/about-us) is focused on building the machine learning infrastructure."
msgstr ""

#: ../docs/modules/models/llms/integrations/banana.ipynb:10007
msgid "This example goes over how to use LangChain to interact with Banana models"
msgstr ""

#: ../docs/modules/models/llms/integrations/cerebriumai_example.ipynb:10002
msgid "CerebriumAI"
msgstr ""

#: ../docs/modules/models/llms/integrations/cerebriumai_example.ipynb:10004
msgid "`Cerebrium` is an AWS Sagemaker alternative. It also provides API access to [several LLM models](https://docs.cerebrium.ai/cerebrium/prebuilt-models/deployment)."
msgstr ""

#: ../docs/modules/models/llms/integrations/cerebriumai_example.ipynb:10006
msgid "This notebook goes over how to use Langchain with [CerebriumAI](https://docs.cerebrium.ai/introduction)."
msgstr ""

#: ../docs/modules/models/llms/integrations/cerebriumai_example.ipynb:20002
msgid "Install cerebrium"
msgstr ""

#: ../docs/modules/models/llms/integrations/cerebriumai_example.ipynb:20003
msgid "The `cerebrium` package is required to use the `CerebriumAI` API. Install `cerebrium` using `pip3 install cerebrium`."
msgstr ""

#: ../docs/modules/models/llms/integrations/cerebriumai_example.ipynb:60003
msgid "Make sure to get your API key from CerebriumAI. See [here](https://dashboard.cerebrium.ai/login). You are given a 1 hour free of serverless GPU compute to test different models."
msgstr ""

#: ../docs/modules/models/llms/integrations/cerebriumai_example.ipynb:80002
msgid "Create the CerebriumAI instance"
msgstr ""

#: ../docs/modules/models/llms/integrations/cerebriumai_example.ipynb:80003
msgid "You can specify different parameters such as the model endpoint url, max length, temperature, etc. You must provide an endpoint url."
msgstr ""

#: ../docs/modules/models/llms/integrations/cerebriumai_example.ipynb:100002
#: ../docs/modules/models/llms/integrations/deepinfra_example.ipynb:90002
#: ../docs/modules/models/llms/integrations/forefrontai_example.ipynb:90002
#: ../docs/modules/models/llms/integrations/gooseai_example.ipynb:110002
#: ../docs/modules/models/llms/integrations/petals_example.ipynb:110002
msgid "Create a Prompt Template"
msgstr ""

#: ../docs/modules/models/llms/integrations/cerebriumai_example.ipynb:100003
#: ../docs/modules/models/llms/integrations/deepinfra_example.ipynb:90003
#: ../docs/modules/models/llms/integrations/forefrontai_example.ipynb:90003
#: ../docs/modules/models/llms/integrations/gooseai_example.ipynb:110003
#: ../docs/modules/models/llms/integrations/petals_example.ipynb:110003
msgid "We will create a prompt template for Question and Answer."
msgstr ""

#: ../docs/modules/models/llms/integrations/cerebriumai_example.ipynb:120002
#: ../docs/modules/models/llms/integrations/deepinfra_example.ipynb:110002
#: ../docs/modules/models/llms/integrations/forefrontai_example.ipynb:110002
#: ../docs/modules/models/llms/integrations/gooseai_example.ipynb:130002
#: ../docs/modules/models/llms/integrations/petals_example.ipynb:130002
msgid "Initiate the LLMChain"
msgstr ""

#: ../docs/modules/models/llms/integrations/cerebriumai_example.ipynb:140002
#: ../docs/modules/models/llms/integrations/deepinfra_example.ipynb:130002
#: ../docs/modules/models/llms/integrations/forefrontai_example.ipynb:130002
#: ../docs/modules/models/llms/integrations/gooseai_example.ipynb:150002
#: ../docs/modules/models/llms/integrations/petals_example.ipynb:150002
msgid "Run the LLMChain"
msgstr ""

#: ../docs/modules/models/llms/integrations/cerebriumai_example.ipynb:140003
#: ../docs/modules/models/llms/integrations/deepinfra_example.ipynb:130003
#: ../docs/modules/models/llms/integrations/forefrontai_example.ipynb:130003
#: ../docs/modules/models/llms/integrations/gooseai_example.ipynb:150003
#: ../docs/modules/models/llms/integrations/petals_example.ipynb:150003
msgid "Provide a question and run the LLMChain."
msgstr ""

#: ../docs/modules/models/llms/integrations/cohere.ipynb:10002
#: ../docs/modules/models/text_embedding/examples/cohere.ipynb:10002
msgid "Cohere"
msgstr ""

#: ../docs/modules/models/llms/integrations/cohere.ipynb:10004
msgid "[Cohere](https://cohere.ai/about) is a Canadian startup that provides natural language processing models that help companies improve human-machine interactions."
msgstr ""

#: ../docs/modules/models/llms/integrations/cohere.ipynb:10006
msgid "This example goes over how to use LangChain to interact with `Cohere` [models](https://docs.cohere.ai/docs/generation-card)."
msgstr ""

#: ../docs/modules/models/llms/integrations/deepinfra_example.ipynb:10002
msgid "DeepInfra"
msgstr ""

#: ../docs/modules/models/llms/integrations/deepinfra_example.ipynb:10004
msgid "`DeepInfra` provides [several LLMs](https://deepinfra.com/models)."
msgstr ""

#: ../docs/modules/models/llms/integrations/deepinfra_example.ipynb:10006
msgid "This notebook goes over how to use Langchain with [DeepInfra](https://deepinfra.com)."
msgstr ""

#: ../docs/modules/models/llms/integrations/deepinfra_example.ipynb:40003
msgid "Make sure to get your API key from DeepInfra. You have to [Login](https://deepinfra.com/login?from=%2Fdash) and get a new token."
msgstr ""

#: ../docs/modules/models/llms/integrations/deepinfra_example.ipynb:40005
msgid "You are given a 1 hour free of serverless GPU compute to test different models. (see [here](https://github.com/deepinfra/deepctl#deepctl)) You can print your token with `deepctl auth token`"
msgstr ""

#: ../docs/modules/models/llms/integrations/deepinfra_example.ipynb:70002
msgid "Create the DeepInfra instance"
msgstr ""

#: ../docs/modules/models/llms/integrations/deepinfra_example.ipynb:70003
msgid "Make sure to deploy your model first via `deepctl deploy create -m google/flat-t5-xl` (see [here](https://github.com/deepinfra/deepctl#deepctl))"
msgstr ""

#: ../docs/modules/models/llms/integrations/forefrontai_example.ipynb:10002
msgid "ForefrontAI"
msgstr ""

#: ../docs/modules/models/llms/integrations/forefrontai_example.ipynb:10005
msgid "The `Forefront` platform gives you the ability to fine-tune and use [open source large language models](https://docs.forefront.ai/forefront/master/models)."
msgstr ""

#: ../docs/modules/models/llms/integrations/forefrontai_example.ipynb:10007
msgid "This notebook goes over how to use Langchain with [ForefrontAI](https://www.forefront.ai/)."
msgstr ""

#: ../docs/modules/models/llms/integrations/forefrontai_example.ipynb:40003
msgid "Make sure to get your API key from ForefrontAI. You are given a 5 day free trial to test different models."
msgstr ""

#: ../docs/modules/models/llms/integrations/forefrontai_example.ipynb:70002
msgid "Create the ForefrontAI instance"
msgstr ""

#: ../docs/modules/models/llms/integrations/forefrontai_example.ipynb:70003
msgid "You can specify different parameters such as the model endpoint url, length, temperature, etc. You must provide an endpoint url."
msgstr ""

#: ../docs/modules/models/llms/integrations/gooseai_example.ipynb:10002
msgid "GooseAI"
msgstr ""

#: ../docs/modules/models/llms/integrations/gooseai_example.ipynb:10004
msgid "`GooseAI` is a fully managed NLP-as-a-Service, delivered via API. GooseAI provides access to [these models](https://goose.ai/docs/models)."
msgstr ""

#: ../docs/modules/models/llms/integrations/gooseai_example.ipynb:10006
msgid "This notebook goes over how to use Langchain with [GooseAI](https://goose.ai/)."
msgstr ""

#: ../docs/modules/models/llms/integrations/gooseai_example.ipynb:20002
msgid "Install openai"
msgstr ""

#: ../docs/modules/models/llms/integrations/gooseai_example.ipynb:20003
msgid "The `openai` package is required to use the GooseAI API. Install `openai` using `pip3 install openai`."
msgstr ""

#: ../docs/modules/models/llms/integrations/gooseai_example.ipynb:60003
msgid "Make sure to get your API key from GooseAI. You are given $10 in free credits to test different models."
msgstr ""

#: ../docs/modules/models/llms/integrations/gooseai_example.ipynb:90002
msgid "Create the GooseAI instance"
msgstr ""

#: ../docs/modules/models/llms/integrations/gooseai_example.ipynb:90003
msgid "You can specify different parameters such as the model name, max tokens generated, temperature, etc."
msgstr ""

#: ../docs/modules/models/llms/integrations/gpt4all.ipynb:10002
msgid "GPT4All"
msgstr ""

#: ../docs/modules/models/llms/integrations/gpt4all.ipynb:10004
msgid "[GitHub:nomic-ai/gpt4all](https://github.com/nomic-ai/gpt4all) an ecosystem of open-source chatbots trained on a massive collections of clean assistant data including code, stories and dialogue."
msgstr ""

#: ../docs/modules/models/llms/integrations/gpt4all.ipynb:10006
msgid "This example goes over how to use LangChain to interact with `GPT4All` models."
msgstr ""

#: ../docs/modules/models/llms/integrations/gpt4all.ipynb:50002
msgid "Specify Model"
msgstr ""

#: ../docs/modules/models/llms/integrations/gpt4all.ipynb:50004
msgid "To run locally, download a compatible ggml-formatted model. For more info, visit https://github.com/nomic-ai/pyllamacpp"
msgstr ""

#: ../docs/modules/models/llms/integrations/gpt4all.ipynb:50006
msgid "For full installation instructions go [here](https://gpt4all.io/index.html)."
msgstr ""

#: ../docs/modules/models/llms/integrations/gpt4all.ipynb:50008
msgid "The GPT4All Chat installer needs to decompress a 3GB LLM model during the installation process!"
msgstr ""

#: ../docs/modules/models/llms/integrations/gpt4all.ipynb:50010
msgid "Note that new models are uploaded regularly - check the link above for the most recent `.bin` URL"
msgstr ""

#: ../docs/modules/models/llms/integrations/gpt4all.ipynb:70002
msgid "Uncomment the below block to download a model. You may want to update `url` to a new version."
msgstr ""

#: ../docs/modules/models/llms/integrations/huggingface_hub.ipynb:10002
#: ../docs/modules/models/text_embedding/examples/huggingfacehub.ipynb:10002
msgid "Hugging Face Hub"
msgstr ""

#: ../docs/modules/models/llms/integrations/huggingface_hub.ipynb:10004
msgid "The [Hugging Face Hub](https://huggingface.co/docs/hub/index) is a platform with over 120k models, 20k datasets, and 50k demo apps (Spaces), all open source and publicly available, in an online platform where people can easily collaborate and build ML together."
msgstr ""

#: ../docs/modules/models/llms/integrations/huggingface_hub.ipynb:10006
msgid "This example showcases how to connect to the Hugging Face Hub."
msgstr ""

#: ../docs/modules/models/llms/integrations/huggingface_hub.ipynb:20002
msgid "To use, you should have the ``huggingface_hub`` python [package installed](https://huggingface.co/docs/huggingface_hub/installation)."
msgstr ""

#: ../docs/modules/models/llms/integrations/huggingface_hub.ipynb:60002
msgid "**Select a Model**"
msgstr ""

#: ../docs/modules/models/llms/integrations/huggingface_hub.ipynb:90004
msgid "Below are some examples of models you can access through the Hugging Face Hub integration."
msgstr ""

#: ../docs/modules/models/llms/integrations/huggingface_hub.ipynb:100002
msgid "StableLM, by Stability AI"
msgstr ""

#: ../docs/modules/models/llms/integrations/huggingface_hub.ipynb:100004
msgid "See [Stability AI's](https://huggingface.co/stabilityai) organization page for a list of available models."
msgstr ""

#: ../docs/modules/models/llms/integrations/huggingface_hub.ipynb:140002
msgid "Dolly, by DataBricks"
msgstr ""

#: ../docs/modules/models/llms/integrations/huggingface_hub.ipynb:140004
msgid "See [DataBricks](https://huggingface.co/databricks) organization page for a list of available models."
msgstr ""

#: ../docs/modules/models/llms/integrations/huggingface_hub.ipynb:170002
msgid "Camel, by Writer"
msgstr ""

#: ../docs/modules/models/llms/integrations/huggingface_hub.ipynb:170004
msgid "See [Writer's](https://huggingface.co/Writer) organization page for a list of available models."
msgstr ""

#: ../docs/modules/models/llms/integrations/huggingface_hub.ipynb:200002
msgid "**And many more!**"
msgstr ""

#: ../docs/modules/models/llms/integrations/huggingface_pipelines.ipynb:10002
msgid "Hugging Face Local Pipelines"
msgstr ""

#: ../docs/modules/models/llms/integrations/huggingface_pipelines.ipynb:10004
msgid "Hugging Face models can be run locally through the `HuggingFacePipeline` class."
msgstr ""

#: ../docs/modules/models/llms/integrations/huggingface_pipelines.ipynb:10006
msgid "The [Hugging Face Model Hub](https://huggingface.co/models) hosts over 120k models, 20k datasets, and 50k demo apps (Spaces), all open source and publicly available, in an online platform where people can easily collaborate and build ML together."
msgstr ""

#: ../docs/modules/models/llms/integrations/huggingface_pipelines.ipynb:10008
msgid "These can be called from LangChain either through this local pipeline wrapper or by calling their hosted inference endpoints through the HuggingFaceHub class. For more information on the hosted pipelines, see the [HuggingFaceHub](huggingface_hub.ipynb) notebook."
msgstr ""

#: ../docs/modules/models/llms/integrations/huggingface_pipelines.ipynb:20002
msgid "To use, you should have the ``transformers`` python [package installed](https://pypi.org/project/transformers/)."
msgstr ""

#: ../docs/modules/models/llms/integrations/huggingface_pipelines.ipynb:40002
msgid "Load the model"
msgstr ""

#: ../docs/modules/models/llms/integrations/huggingface_pipelines.ipynb:60002
msgid "Integrate the model in an LLMChain"
msgstr ""

#: ../docs/modules/models/llms/integrations/llamacpp.ipynb:10002
#: ../docs/modules/models/text_embedding/examples/llamacpp.ipynb:10002
msgid "Llama-cpp"
msgstr ""

#: ../docs/modules/models/llms/integrations/llamacpp.ipynb:10004
msgid "[llama-cpp](https://github.com/abetlen/llama-cpp-python) is a Python binding for [llama.cpp](https://github.com/ggerganov/llama.cpp).  It supports [several LLMs](https://github.com/ggerganov/llama.cpp)."
msgstr ""

#: ../docs/modules/models/llms/integrations/llamacpp.ipynb:10007
msgid "This notebook goes over how to run `llama-cpp` within LangChain."
msgstr ""

#: ../docs/modules/models/llms/integrations/llamacpp.ipynb:30002
msgid "Make sure you are following all instructions to [install all necessary model files](https://github.com/ggerganov/llama.cpp)."
msgstr ""

#: ../docs/modules/models/llms/integrations/llamacpp.ipynb:30004
msgid "You don't need an `API_TOKEN`!"
msgstr ""

#: ../docs/modules/models/llms/integrations/manifest.ipynb:10002
msgid "Manifest"
msgstr ""

#: ../docs/modules/models/llms/integrations/manifest.ipynb:10004
msgid "This notebook goes over how to use Manifest and LangChain."
msgstr ""

#: ../docs/modules/models/llms/integrations/manifest.ipynb:20002
msgid "For more detailed information on `manifest`, and how to use it with local hugginface models like in this example, see https://github.com/HazyResearch/manifest"
msgstr ""

#: ../docs/modules/models/llms/integrations/manifest.ipynb:20004
msgid "Another example of [using Manifest with Langchain](https://github.com/HazyResearch/manifest/blob/main/examples/langchain_chatgpt.ipynb)."
msgstr ""

#: ../docs/modules/models/llms/integrations/manifest.ipynb:90002
msgid "Compare HF Models"
msgstr ""

#: ../docs/modules/models/llms/integrations/modal.ipynb:10002
msgid "Modal"
msgstr ""

#: ../docs/modules/models/llms/integrations/modal.ipynb:10004
msgid "The [Modal Python Library](https://modal.com/docs/guide) provides convenient, on-demand access to serverless cloud compute from Python scripts on your local computer.  The `Modal` itself does not provide any LLMs but only the infrastructure."
msgstr ""

#: ../docs/modules/models/llms/integrations/modal.ipynb:10007
msgid "This example goes over how to use LangChain to interact with `Modal`."
msgstr ""

#: ../docs/modules/models/llms/integrations/modal.ipynb:10009
msgid "[Here](https://modal.com/docs/guide/ex/potus_speech_qanda) is another example how to use LangChain to interact with `Modal`."
msgstr ""

#: ../docs/modules/models/llms/integrations/modal.ipynb:40002
msgid "Follow [these instructions](https://modal.com/docs/guide/secrets) to deal with secrets."
msgstr ""

#: ../docs/modules/models/llms/integrations/nlpcloud.ipynb:10002
msgid "NLP Cloud"
msgstr ""

#: ../docs/modules/models/llms/integrations/nlpcloud.ipynb:10004
msgid "The [NLP Cloud](https://nlpcloud.io) serves high performance pre-trained or custom models for NER, sentiment-analysis, classification, summarization, paraphrasing, grammar and spelling correction, keywords and keyphrases extraction, chatbot, product description and ad generation, intent classification, text generation, image generation, blog post generation, code generation, question answering, automatic speech recognition, machine translation, language detection, semantic search, semantic similarity, tokenization, POS tagging, embeddings, and dependency parsing. It is ready for production, served through a REST API."
msgstr ""

#: ../docs/modules/models/llms/integrations/nlpcloud.ipynb:10007
msgid "This example goes over how to use LangChain to interact with `NLP Cloud` [models](https://docs.nlpcloud.com/#models)."
msgstr ""

#: ../docs/modules/models/llms/integrations/openai.ipynb:10004
msgid "[OpenAI](https://platform.openai.com/docs/introduction) offers a spectrum of models with different levels of power suitable for different tasks."
msgstr ""

#: ../docs/modules/models/llms/integrations/openai.ipynb:10006
msgid "This example goes over how to use LangChain to interact with `OpenAI` [models](https://platform.openai.com/docs/models)"
msgstr ""

#: ../docs/modules/models/llms/integrations/petals_example.ipynb:10002
msgid "Petals"
msgstr ""

#: ../docs/modules/models/llms/integrations/petals_example.ipynb:10004
msgid "`Petals` runs 100B+ language models at home, BitTorrent-style."
msgstr ""

#: ../docs/modules/models/llms/integrations/petals_example.ipynb:10006
msgid "This notebook goes over how to use Langchain with [Petals](https://github.com/bigscience-workshop/petals)."
msgstr ""

#: ../docs/modules/models/llms/integrations/petals_example.ipynb:20002
msgid "Install petals"
msgstr ""

#: ../docs/modules/models/llms/integrations/petals_example.ipynb:20003
msgid "The `petals` package is required to use the Petals API. Install `petals` using `pip3 install petals`."
msgstr ""

#: ../docs/modules/models/llms/integrations/petals_example.ipynb:60003
msgid "Make sure to get [your API key](https://huggingface.co/docs/api-inference/quicktour#get-your-api-token) from Huggingface."
msgstr ""

#: ../docs/modules/models/llms/integrations/petals_example.ipynb:90002
msgid "Create the Petals instance"
msgstr ""

#: ../docs/modules/models/llms/integrations/petals_example.ipynb:90003
msgid "You can specify different parameters such as the model name, max new tokens, temperature, etc."
msgstr ""

#: ../docs/modules/models/llms/integrations/predictionguard.ipynb:10002
msgid "PredictionGuard"
msgstr ""

#: ../docs/modules/models/llms/integrations/predictionguard.ipynb:10004
msgid "How to use PredictionGuard wrapper"
msgstr ""

#: ../docs/modules/models/llms/integrations/predictionguard.ipynb:40002
msgid "Basic LLM usage"
msgstr ""

#: ../docs/modules/models/llms/integrations/predictionguard.ipynb:70002
msgid "Chaining"
msgstr ""

#: ../docs/modules/models/llms/integrations/promptlayer_openai.ipynb:10002
msgid "PromptLayer OpenAI"
msgstr ""

#: ../docs/modules/models/llms/integrations/promptlayer_openai.ipynb:10004
msgid "`PromptLayer` is the first platform that allows you to track, manage, and share your GPT prompt engineering. `PromptLayer` acts a middleware between your code and `OpenAI‚Äôs` python library."
msgstr ""

#: ../docs/modules/models/llms/integrations/promptlayer_openai.ipynb:10006
msgid "`PromptLayer` records all your `OpenAI API` requests, allowing you to search and explore request history in the `PromptLayer` dashboard."
msgstr ""

#: ../docs/modules/models/llms/integrations/promptlayer_openai.ipynb:10009
msgid "This example showcases how to connect to [PromptLayer](https://www.promptlayer.com) to start recording your OpenAI requests."
msgstr ""

#: ../docs/modules/models/llms/integrations/promptlayer_openai.ipynb:10011
msgid "Another example is [here](https://python.langchain.com/en/latest/ecosystem/promptlayer.html)."
msgstr ""

#: ../docs/modules/models/llms/integrations/promptlayer_openai.ipynb:60007
msgid "You also need an OpenAI Key, called `OPENAI_API_KEY`."
msgstr ""

#: ../docs/modules/models/llms/integrations/replicate.ipynb:10002
msgid "Replicate"
msgstr ""

#: ../docs/modules/models/llms/integrations/replicate.ipynb:10004
msgid "[Replicate](https://replicate.com/blog/machine-learning-needs-better-tools) runs machine learning models in the cloud. We have a library of open-source models that you can run with a few lines of code. If you're building your own machine learning models, Replicate makes it easy to deploy them at scale."
msgstr ""

#: ../docs/modules/models/llms/integrations/replicate.ipynb:10006
msgid "This example goes over how to use LangChain to interact with `Replicate` [models](https://replicate.com/explore)"
msgstr ""

#: ../docs/modules/models/llms/integrations/replicate.ipynb:30002
msgid "To run this notebook, you'll need to create a [replicate](https://replicate.com) account and install the [replicate python client](https://github.com/replicate/replicate-python)."
msgstr ""

#: ../docs/modules/models/llms/integrations/replicate.ipynb:80002
msgid "Calling a model"
msgstr ""

#: ../docs/modules/models/llms/integrations/replicate.ipynb:80004
msgid "Find a model on the [replicate explore page](https://replicate.com/explore), and then paste in the model name and version in this format: model_name/version"
msgstr ""

#: ../docs/modules/models/llms/integrations/replicate.ipynb:80006
msgid "For example, for this [dolly model](https://replicate.com/replicate/dolly-v2-12b), click on the API tab. The model name/version would be: `replicate/dolly-v2-12b:ef0e1aefc61f8e096ebe4db6b2bacc297daf2ef6899f0f7e001ec445893500e5`"
msgstr ""

#: ../docs/modules/models/llms/integrations/replicate.ipynb:80008
msgid "Only the `model` param is required, but we can add other model params when initializing."
msgstr ""

#: ../docs/modules/models/llms/integrations/replicate.ipynb:80010
msgid "For example, if we were running stable diffusion and wanted to change the image dimensions:"
msgstr ""

#: ../docs/modules/models/llms/integrations/replicate.ipynb:80016
msgid "*Note that only the first output of a model will be returned.*"
msgstr ""

#: ../docs/modules/models/llms/integrations/replicate.ipynb:110002
msgid "We can call any replicate model using this syntax. For example, we can call stable diffusion."
msgstr ""

#: ../docs/modules/models/llms/integrations/replicate.ipynb:140002
msgid "The model spits out a URL. Let's render it."
msgstr ""

#: ../docs/modules/models/llms/integrations/replicate.ipynb:160002
msgid "Chaining Calls"
msgstr ""

#: ../docs/modules/models/llms/integrations/replicate.ipynb:160003
msgid "The whole point of langchain is to... chain! Here's an example of how do that."
msgstr ""

#: ../docs/modules/models/llms/integrations/replicate.ipynb:180002
msgid "First, let's define the LLM for this model as a flan-5, and text2image as a stable diffusion model."
msgstr ""

#: ../docs/modules/models/llms/integrations/replicate.ipynb:200002
msgid "First prompt in the chain"
msgstr ""

#: ../docs/modules/models/llms/integrations/replicate.ipynb:220002
msgid "Second prompt to get the logo for company description"
msgstr ""

#: ../docs/modules/models/llms/integrations/replicate.ipynb:240002
msgid "Third prompt, let's create the image based on the description output from prompt 2"
msgstr ""

#: ../docs/modules/models/llms/integrations/replicate.ipynb:260002
msgid "Now let's run it!"
msgstr ""

#: ../docs/modules/models/llms/integrations/runhouse.ipynb:10002
msgid "Runhouse"
msgstr ""

#: ../docs/modules/models/llms/integrations/runhouse.ipynb:10004
msgid "The [Runhouse](https://github.com/run-house/runhouse) allows remote compute and data across environments and users. See the [Runhouse docs](https://runhouse-docs.readthedocs-hosted.com/en/latest/)."
msgstr ""

#: ../docs/modules/models/llms/integrations/runhouse.ipynb:10006
msgid "This example goes over how to use LangChain and [Runhouse](https://github.com/run-house/runhouse) to interact with models hosted on your own GPU, or on-demand GPUs on AWS, GCP, AWS, or Lambda."
msgstr ""

#: ../docs/modules/models/llms/integrations/runhouse.ipynb:10008
msgid "**Note**: Code uses `SelfHosted` name instead of the `Runhouse`."
msgstr ""

#: ../docs/modules/models/llms/integrations/runhouse.ipynb:90002
msgid "You can also load more custom models through the SelfHostedHuggingFaceLLM interface:"
msgstr ""

#: ../docs/modules/models/llms/integrations/runhouse.ipynb:120002
msgid "Using a custom load function, we can load a custom pipeline directly on the remote hardware:"
msgstr ""

#: ../docs/modules/models/llms/integrations/runhouse.ipynb:160002
msgid "You can send your pipeline directly over the wire to your model, but this will only work for small models (<2 Gb), and will be pretty slow:"
msgstr ""

#: ../docs/modules/models/llms/integrations/runhouse.ipynb:180002
msgid "Instead, we can also send it to the hardware's filesystem, which will be much faster."
msgstr ""

#: ../docs/modules/models/llms/integrations/sagemaker.ipynb:10002
msgid "SageMakerEndpoint"
msgstr ""

#: ../docs/modules/models/llms/integrations/sagemaker.ipynb:10004
msgid "[Amazon SageMaker](https://aws.amazon.com/sagemaker/) is a system that can build, train, and deploy machine learning (ML) models for any use case with fully managed infrastructure, tools, and workflows."
msgstr ""

#: ../docs/modules/models/llms/integrations/sagemaker.ipynb:10006
msgid "This notebooks goes over how to use an LLM hosted on a `SageMaker endpoint`."
msgstr ""

#: ../docs/modules/models/llms/integrations/sagemaker.ipynb:30002
msgid "Set up"
msgstr ""

#: ../docs/modules/models/llms/integrations/sagemaker.ipynb:40002
msgid "You have to set up following required parameters of the `SagemakerEndpoint` call:"
msgstr ""

#: ../docs/modules/models/llms/integrations/sagemaker.ipynb:40003
msgid "`endpoint_name`: The name of the endpoint from the deployed Sagemaker model.   Must be unique within an AWS Region."
msgstr ""

#: ../docs/modules/models/llms/integrations/sagemaker.ipynb:40005
msgid "`credentials_profile_name`: The name of the profile in the ~/.aws/credentials or ~/.aws/config files, which   has either access keys or role information specified.   If not specified, the default credential profile or, if on an EC2 instance,   credentials from IMDS will be used.   See: https://boto3.amazonaws.com/v1/documentation/api/latest/guide/credentials.html"
msgstr ""

#: ../docs/modules/models/llms/integrations/stochasticai.ipynb:10002
msgid "StochasticAI"
msgstr ""

#: ../docs/modules/models/llms/integrations/stochasticai.ipynb:10004
msgid "[Stochastic Acceleration Platform](https://docs.stochastic.ai/docs/introduction/) aims to simplify the life cycle of a Deep Learning model. From uploading and versioning the model, through training, compression and acceleration to putting it into production."
msgstr ""

#: ../docs/modules/models/llms/integrations/stochasticai.ipynb:10006
msgid "This example goes over how to use LangChain to interact with `StochasticAI` models."
msgstr ""

#: ../docs/modules/models/llms/integrations/stochasticai.ipynb:20002
msgid "You have to get the API_KEY and the API_URL [here](https://app.stochastic.ai/workspace/profile/settings?tab=profile)."
msgstr ""

#: ../docs/modules/models/llms/integrations/writer.ipynb:10002
msgid "Writer"
msgstr ""

#: ../docs/modules/models/llms/integrations/writer.ipynb:10004
msgid "[Writer](https://writer.com/) is a platform to generate different language content."
msgstr ""

#: ../docs/modules/models/llms/integrations/writer.ipynb:10006
msgid "This example goes over how to use LangChain to interact with `Writer` [models](https://dev.writer.com/docs/models)."
msgstr ""

#: ../docs/modules/models/llms/integrations/writer.ipynb:10008
msgid "You have to get the WRITER_API_KEY [here](https://dev.writer.com/docs)."
msgstr ""

#: ../docs/modules/models/text_embedding.rst:2
msgid "Text Embedding Models"
msgstr ""

#: ../docs/modules/models/text_embedding.rst:5
msgid "`Conceptual Guide <https://docs.langchain.com/docs/components/models/text-embedding-model>`_"
msgstr ""

#: ../docs/modules/models/text_embedding.rst:8
msgid "This documentation goes over how to use the Embedding class in LangChain."
msgstr ""

#: ../docs/modules/models/text_embedding.rst:10
msgid "The Embedding class is a class designed for interfacing with embeddings. There are lots of Embedding providers (OpenAI, Cohere, Hugging Face, etc) - this class is designed to provide a standard interface for all of them."
msgstr ""

#: ../docs/modules/models/text_embedding.rst:12
msgid "Embeddings create a vector representation of a piece of text. This is useful because it means we can think about text in the vector space, and do things like semantic search where we look for pieces of text that are most similar in the vector space."
msgstr ""

#: ../docs/modules/models/text_embedding.rst:14
msgid "The base Embedding class in LangChain exposes two methods: `embed_documents` and `embed_query`. The largest difference is that these two methods have different interfaces: one works over multiple documents, while the other works over a single document. Besides this, another reason for having these as two separate methods is that some embedding providers have different embedding methods for documents (to be searched over) vs queries (the search query itself)."
msgstr ""

#: ../docs/modules/models/text_embedding.rst:16
msgid "The following integrations exist for text embeddings."
msgstr ""

#: ../docs/modules/models/text_embedding/examples/aleph_alpha.ipynb:10004
msgid "There are two possible ways to use Aleph Alpha's semantic embeddings. If you have texts with a dissimilar structure (e.g. a Document and a Query) you would want to use asymmetric embeddings. Conversely, for texts with comparable structures, symmetric embeddings are the suggested approach."
msgstr ""

#: ../docs/modules/models/text_embedding/examples/aleph_alpha.ipynb:20002
msgid "Asymmetric"
msgstr ""

#: ../docs/modules/models/text_embedding/examples/aleph_alpha.ipynb:80002
msgid "Symmetric"
msgstr ""

#: ../docs/modules/models/text_embedding/examples/azureopenai.ipynb:10002
msgid "AzureOpenAI"
msgstr ""

#: ../docs/modules/models/text_embedding/examples/azureopenai.ipynb:10004
msgid "Let's load the OpenAI Embedding class with environment variables set to indicate to use Azure endpoints."
msgstr ""

#: ../docs/modules/models/text_embedding/examples/cohere.ipynb:10004
msgid "Let's load the Cohere Embedding class."
msgstr ""

#: ../docs/modules/models/text_embedding/examples/fake.ipynb:10002
msgid "Fake Embeddings"
msgstr ""

#: ../docs/modules/models/text_embedding/examples/fake.ipynb:10004
msgid "LangChain also provides a fake embedding class. You can use this to test your pipelines."
msgstr ""

#: ../docs/modules/models/text_embedding/examples/huggingfacehub.ipynb:10003
msgid "Let's load the Hugging Face Embedding class."
msgstr ""

#: ../docs/modules/models/text_embedding/examples/instruct_embeddings.ipynb:10002
msgid "InstructEmbeddings"
msgstr ""

#: ../docs/modules/models/text_embedding/examples/instruct_embeddings.ipynb:10003
msgid "Let's load the HuggingFace instruct Embeddings class."
msgstr ""

#: ../docs/modules/models/text_embedding/examples/jina.ipynb:10002
msgid "Jina"
msgstr ""

#: ../docs/modules/models/text_embedding/examples/jina.ipynb:10004
msgid "Let's load the Jina Embedding class."
msgstr ""

#: ../docs/modules/models/text_embedding/examples/jina.ipynb:70002
msgid "In the above example, `ViT-B-32::openai`, OpenAI's pretrained `ViT-B-32` model is used. For a full list of models, see [here](https://cloud.jina.ai/user/inference/model/63dca9df5a0da83009d519cd)."
msgstr ""

#: ../docs/modules/models/text_embedding/examples/llamacpp.ipynb:10004
msgid "This notebook goes over how to use Llama-cpp embeddings within LangChain"
msgstr ""

#: ../docs/modules/models/text_embedding/examples/openai.ipynb:10004
msgid "Let's load the OpenAI Embedding class."
msgstr ""

#: ../docs/modules/models/text_embedding/examples/openai.ipynb:70002
msgid "Let's load the OpenAI Embedding class with first generation models (e.g. text-search-ada-doc-001/text-search-ada-query-001). Note: These are not recommended models - see [here](https://platform.openai.com/docs/guides/embeddings/what-are-embeddings)"
msgstr ""

#: ../docs/modules/models/text_embedding/examples/sagemaker-endpoint.ipynb:10002
msgid "SageMaker Endpoint Embeddings"
msgstr ""

#: ../docs/modules/models/text_embedding/examples/sagemaker-endpoint.ipynb:10004
msgid "Let's load the SageMaker Endpoints Embeddings class. The class can be used if you host, e.g. your own Hugging Face model on SageMaker."
msgstr ""

#: ../docs/modules/models/text_embedding/examples/sagemaker-endpoint.ipynb:10006
msgid "For instructions on how to do this, please see [here](https://www.philschmid.de/custom-inference-huggingface-sagemaker). **Note**: In order to handle batched requests, you will need to adjust the return line in the `predict_fn()` function within the custom `inference.py` script:"
msgstr ""

#: ../docs/modules/models/text_embedding/examples/sagemaker-endpoint.ipynb:10008
msgid "Change from"
msgstr ""

#: ../docs/modules/models/text_embedding/examples/sagemaker-endpoint.ipynb:10010
msgid "`return {\"vectors\": sentence_embeddings[0].tolist()}`"
msgstr ""

#: ../docs/modules/models/text_embedding/examples/sagemaker-endpoint.ipynb:10012
msgid "to:"
msgstr ""

#: ../docs/modules/models/text_embedding/examples/sagemaker-endpoint.ipynb:10014
msgid "`return {\"vectors\": sentence_embeddings.tolist()}`."
msgstr ""

#: ../docs/modules/models/text_embedding/examples/self-hosted.ipynb:10002
msgid "Self Hosted Embeddings"
msgstr ""

#: ../docs/modules/models/text_embedding/examples/self-hosted.ipynb:10003
msgid "Let's load the SelfHostedEmbeddings, SelfHostedHuggingFaceEmbeddings, and SelfHostedHuggingFaceInstructEmbeddings classes."
msgstr ""

#: ../docs/modules/models/text_embedding/examples/self-hosted.ipynb:70002
msgid "And similarly for SelfHostedHuggingFaceInstructEmbeddings:"
msgstr ""

#: ../docs/modules/models/text_embedding/examples/self-hosted.ipynb:90002
msgid "Now let's load an embedding model with a custom load function:"
msgstr ""

#: ../docs/modules/models/text_embedding/examples/sentence_transformers.ipynb:10002
msgid "Sentence Transformers Embeddings"
msgstr ""

#: ../docs/modules/models/text_embedding/examples/sentence_transformers.ipynb:10004
msgid "[SentenceTransformers](https://www.sbert.net/) embeddings are called using the `HuggingFaceEmbeddings` integration. We have also added an alias for `SentenceTransformerEmbeddings` for users who are more familiar with directly using that package."
msgstr ""

#: ../docs/modules/models/text_embedding/examples/sentence_transformers.ipynb:10006
msgid "SentenceTransformers is a python package that can generate text and image embeddings, originating from [Sentence-BERT](https://arxiv.org/abs/1908.10084)"
msgstr ""

#: ../docs/modules/models/text_embedding/examples/tensorflowhub.ipynb:10002
msgid "TensorflowHub"
msgstr ""

#: ../docs/modules/models/text_embedding/examples/tensorflowhub.ipynb:10003
msgid "Let's load the TensorflowHub Embedding class."
msgstr ""

#: ../docs/modules/prompts.rst:2
#: ../docs/modules/prompts/prompt_templates/examples/connecting_to_a_feature_store.ipynb:50002
#: ../docs/modules/prompts/prompt_templates/examples/connecting_to_a_feature_store.ipynb:200002
msgid "Prompts"
msgstr ""

#: ../docs/modules/prompts.rst:5
msgid "`Conceptual Guide <https://docs.langchain.com/docs/components/prompts>`_"
msgstr ""

#: ../docs/modules/prompts.rst:8
msgid "The new way of programming models is through prompts. A \"prompt\" refers to the input to the model. This input is rarely hard coded, but rather is often constructed from multiple components. A PromptTemplate is responsible for the construction of this input. LangChain provides several classes and functions to make constructing and working with prompts easy."
msgstr ""

#: ../docs/modules/prompts.rst:14
msgid "This section of documentation is split into four sections:"
msgstr ""

#: ../docs/modules/prompts.rst:16
msgid "**LLM Prompt Templates**"
msgstr ""

#: ../docs/modules/prompts.rst:18
msgid "How to use PromptTemplates to prompt Language Models."
msgstr ""

#: ../docs/modules/prompts.rst:20
msgid "**Chat Prompt Templates**"
msgstr ""

#: ../docs/modules/prompts.rst:22
msgid "How to use PromptTemplates to prompt Chat Models."
msgstr ""

#: ../docs/modules/prompts.rst:24
msgid "**Example Selectors**"
msgstr ""

#: ../docs/modules/prompts.rst:26
msgid "Often times it is useful to include examples in prompts. These examples can be hardcoded, but it is often more powerful if they are dynamically selected. This section goes over example selection."
msgstr ""

#: ../docs/modules/prompts.rst:31
msgid "**Output Parsers**"
msgstr ""

#: ../docs/modules/prompts.rst:33
msgid "Language models (and Chat Models) output text. But many times you may want to get more structured information than just text back. This is where output parsers come in. Output Parsers are responsible for (1) instructing the model how output should be formatted, (2) parsing output into the desired formatting (including retrying if necessary)."
msgstr ""

#: ../docs/modules/prompts/chat_prompt_template.ipynb:10002
msgid "Chat Prompt Template"
msgstr ""

#: ../docs/modules/prompts/chat_prompt_template.ipynb:10004
msgid "Chat Models takes a list of chat messages as input - this list commonly referred to as a prompt. Typically this is not simply a hardcoded list of messages but rather a combination of a template, some examples, and user input. LangChain provides several classes and functions to make constructing and working with prompts easy."
msgstr ""

#: ../docs/modules/prompts/chat_prompt_template.ipynb:30004
msgid "For convenience, there is a `from_template` method exposed on the template. If you were to use this template, this is what it would look like:"
msgstr ""

#: ../docs/modules/prompts/example_selectors.rst:2
msgid "Example Selectors"
msgstr ""

#: ../docs/modules/prompts/example_selectors.rst:5
msgid "`Conceptual Guide <https://docs.langchain.com/docs/components/prompts/example-selectors>`_"
msgstr ""

#: ../docs/modules/prompts/example_selectors.rst:8
msgid "If you have a large number of examples, you may need to select which ones to include in the prompt. The ExampleSelector is the class responsible for doing so."
msgstr ""

#: ../docs/modules/prompts/example_selectors.rst:10
msgid "The base interface is defined as below::"
msgstr ""

#: ../docs/modules/prompts/example_selectors.rst:20
msgid "The only method it needs to expose is a ``select_examples`` method. This takes in the input variables and then returns a list of examples. It is up to each specific implementation as to how those examples are selected. Let's take a look at some below."
msgstr ""

#: ../docs/modules/prompts/example_selectors.rst:22
msgid "See below for a list of example selectors."
msgstr ""

#: ../docs/modules/prompts/example_selectors/examples/custom_example_selector.md:1
msgid "How to create a custom example selector"
msgstr ""

#: ../docs/modules/prompts/example_selectors/examples/custom_example_selector.md:3
msgid "In this tutorial, we'll create a custom example selector that selects every alternate example from a given list of examples."
msgstr ""

#: ../docs/modules/prompts/example_selectors/examples/custom_example_selector.md:5
msgid "An `ExampleSelector` must implement two methods:"
msgstr ""

#: ../docs/modules/prompts/example_selectors/examples/custom_example_selector.md:7
msgid "An `add_example` method which takes in an example and adds it into the ExampleSelector"
msgstr ""

#: ../docs/modules/prompts/example_selectors/examples/custom_example_selector.md:8
msgid "A `select_examples` method which takes in input variables (which are meant to be user input) and returns a list of examples to use in the few shot prompt."
msgstr ""

#: ../docs/modules/prompts/example_selectors/examples/custom_example_selector.md:10
msgid "Let's implement a custom `ExampleSelector` that just selects two examples at random."
msgstr ""

#: ../docs/modules/prompts/example_selectors/examples/custom_example_selector.md:13
msgid "Take a look at the current set of example selector implementations supported in LangChain [here](../../prompt_templates/getting_started.md)."
msgstr ""

#: ../docs/modules/prompts/example_selectors/examples/custom_example_selector.md:18
msgid "Implement custom example selector"
msgstr ""

#: ../docs/modules/prompts/example_selectors/examples/custom_example_selector.md:42
msgid "Use custom example selector"
msgstr ""

#: ../docs/modules/prompts/example_selectors/examples/length_based.ipynb:10002
msgid "LengthBased ExampleSelector"
msgstr ""

#: ../docs/modules/prompts/example_selectors/examples/length_based.ipynb:10004
msgid "This ExampleSelector selects which examples to use based on length. This is useful when you are worried about constructing a prompt that will go over the length of the context window. For longer inputs, it will select fewer examples to include, while for shorter inputs it will select more."
msgstr ""

#: ../docs/modules/prompts/example_selectors/examples/mmr.ipynb:10002
msgid "Maximal Marginal Relevance ExampleSelector"
msgstr ""

#: ../docs/modules/prompts/example_selectors/examples/mmr.ipynb:10004
msgid "The MaxMarginalRelevanceExampleSelector selects examples based on a combination of which examples are most similar to the inputs, while also optimizing for diversity. It does this by finding the examples with the embeddings that have the greatest cosine similarity with the inputs, and then iteratively adding them while penalizing them for closeness to already selected examples."
msgstr ""

#: ../docs/modules/prompts/example_selectors/examples/ngram_overlap.ipynb:10002
msgid "NGram Overlap ExampleSelector"
msgstr ""

#: ../docs/modules/prompts/example_selectors/examples/ngram_overlap.ipynb:10004
msgid "The NGramOverlapExampleSelector selects and orders examples based on which examples are most similar to the input, according to an ngram overlap score. The ngram overlap score is a float between 0.0 and 1.0, inclusive."
msgstr ""

#: ../docs/modules/prompts/example_selectors/examples/ngram_overlap.ipynb:10006
msgid "The selector allows for a threshold score to be set. Examples with an ngram overlap score less than or equal to the threshold are excluded. The threshold is set to -1.0, by default, so will not exclude any examples, only reorder them. Setting the threshold to 0.0 will exclude examples that have no ngram overlaps with the input."
msgstr ""

#: ../docs/modules/prompts/example_selectors/examples/similarity.ipynb:10002
msgid "Similarity ExampleSelector"
msgstr ""

#: ../docs/modules/prompts/example_selectors/examples/similarity.ipynb:10004
msgid "The SemanticSimilarityExampleSelector selects examples based on which examples are most similar to the inputs. It does this by finding the examples with the embeddings that have the greatest cosine similarity with the inputs."
msgstr ""

#: ../docs/modules/prompts/output_parsers.rst:2
#: ../docs/modules/prompts/output_parsers/getting_started.ipynb:10002
msgid "Output Parsers"
msgstr ""

#: ../docs/modules/prompts/output_parsers.rst:5
msgid "`Conceptual Guide <https://docs.langchain.com/docs/components/prompts/output-parser>`_"
msgstr ""

#: ../docs/modules/prompts/output_parsers.rst:8
#: ../docs/modules/prompts/output_parsers/getting_started.ipynb:10004
msgid "Language models output text. But many times you may want to get more structured information than just text back. This is where output parsers come in."
msgstr ""

#: ../docs/modules/prompts/output_parsers.rst:10
#: ../docs/modules/prompts/output_parsers/getting_started.ipynb:10006
msgid "Output parsers are classes that help structure language model responses. There are two main methods an output parser must implement:"
msgstr ""

#: ../docs/modules/prompts/output_parsers.rst:12
msgid "``get_format_instructions() -> str``: A method which returns a string containing instructions for how the output of a language model should be formatted."
msgstr ""

#: ../docs/modules/prompts/output_parsers.rst:13
msgid "``parse(str) -> Any``: A method which takes in a string (assumed to be the response from a language model) and parses it into some structure."
msgstr ""

#: ../docs/modules/prompts/output_parsers.rst:15
#: ../docs/modules/prompts/output_parsers/getting_started.ipynb:10011
msgid "And then one optional one:"
msgstr ""

#: ../docs/modules/prompts/output_parsers.rst:17
msgid "``parse_with_prompt(str) -> Any``: A method which takes in a string (assumed to be the response from a language model) and a prompt (assumed to the prompt that generated such a response) and parses it into some structure. The prompt is largely provided in the event the OutputParser wants to retry or fix the output in some way, and needs information from the prompt to do so."
msgstr ""

#: ../docs/modules/prompts/output_parsers.rst:19
msgid "To start, we recommend familiarizing yourself with the Getting Started section"
msgstr ""

#: ../docs/modules/prompts/output_parsers.rst:26
msgid "After that, we provide deep dives on all the different types of output parsers."
msgstr ""

#: ../docs/modules/prompts/output_parsers/examples/comma_separated.ipynb:10002
msgid "CommaSeparatedListOutputParser"
msgstr ""

#: ../docs/modules/prompts/output_parsers/examples/comma_separated.ipynb:10004
msgid "Here's another parser strictly less powerful than Pydantic/JSON parsing."
msgstr ""

#: ../docs/modules/prompts/output_parsers/examples/output_fixing_parser.ipynb:10002
msgid "OutputFixingParser"
msgstr ""

#: ../docs/modules/prompts/output_parsers/examples/output_fixing_parser.ipynb:10004
msgid "This output parser wraps another output parser and tries to fix any mmistakes"
msgstr ""

#: ../docs/modules/prompts/output_parsers/examples/output_fixing_parser.ipynb:10006
msgid "The Pydantic guardrail simply tries to parse the LLM response. If it does not parse correctly, then it errors."
msgstr ""

#: ../docs/modules/prompts/output_parsers/examples/output_fixing_parser.ipynb:10008
msgid "But we can do other things besides throw errors. Specifically, we can pass the misformatted output, along with the formatted instructions, to the model and ask it to fix it."
msgstr ""

#: ../docs/modules/prompts/output_parsers/examples/output_fixing_parser.ipynb:10010
msgid "For this example, we'll use the above OutputParser. Here's what happens if we pass it a result that does not comply with the schema:"
msgstr ""

#: ../docs/modules/prompts/output_parsers/examples/output_fixing_parser.ipynb:60002
msgid "Now we can construct and use a `OutputFixingParser`. This output parser takes as an argument another output parser but also an LLM with which to try to correct any formatting mistakes."
msgstr ""

#: ../docs/modules/prompts/output_parsers/examples/pydantic.ipynb:10002
msgid "PydanticOutputParser"
msgstr ""

#: ../docs/modules/prompts/output_parsers/examples/pydantic.ipynb:10003
msgid "This output parser allows users to specify an arbitrary JSON schema and query LLMs for JSON outputs that conform to that schema."
msgstr ""

#: ../docs/modules/prompts/output_parsers/examples/pydantic.ipynb:10005
msgid "Keep in mind that large language models are leaky abstractions! You'll have to use an LLM with sufficient capacity to generate well-formed JSON. In the OpenAI family, DaVinci can do reliably but Curie's ability already drops off dramatically."
msgstr ""

#: ../docs/modules/prompts/output_parsers/examples/pydantic.ipynb:10007
msgid "Use Pydantic to declare your data model. Pydantic's BaseModel like a Python dataclass, but with actual type checking + coercion."
msgstr ""

#: ../docs/modules/prompts/output_parsers/examples/retry.ipynb:10002
msgid "RetryOutputParser"
msgstr ""

#: ../docs/modules/prompts/output_parsers/examples/retry.ipynb:10004
msgid "While in some cases it is possible to fix any parsing mistakes by only looking at the output, in other cases it can't. An example of this is when the output is not just in the incorrect format, but is partially complete. Consider the below example."
msgstr ""

#: ../docs/modules/prompts/output_parsers/examples/retry.ipynb:70002
msgid "If we try to parse this response as is, we will get an error"
msgstr ""

#: ../docs/modules/prompts/output_parsers/examples/retry.ipynb:90002
msgid "If we try to use the `OutputFixingParser` to fix this error, it will be confused - namely, it doesn't know what to actually put for action input."
msgstr ""

#: ../docs/modules/prompts/output_parsers/examples/retry.ipynb:120002
msgid "Instead, we can use the RetryOutputParser, which passes in the prompt (as well as the original output) to try again to get a better response."
msgstr ""

#: ../docs/modules/prompts/output_parsers/examples/structured.ipynb:10002
msgid "Structured Output Parser"
msgstr ""

#: ../docs/modules/prompts/output_parsers/examples/structured.ipynb:10004
msgid "While the Pydantic/JSON parser is more powerful, we initially experimented data structures having text fields only."
msgstr ""

#: ../docs/modules/prompts/output_parsers/examples/structured.ipynb:30002
msgid "Here we define the response schema we want to receive."
msgstr ""

#: ../docs/modules/prompts/output_parsers/examples/structured.ipynb:50002
msgid "We now get a string that contains instructions for how the response should be formatted, and we then insert that into our prompt."
msgstr ""

#: ../docs/modules/prompts/output_parsers/examples/structured.ipynb:70002
msgid "We can now use this to format a prompt to send to the language model, and then parse the returned result."
msgstr ""

#: ../docs/modules/prompts/output_parsers/examples/structured.ipynb:110002
msgid "And here's an example of using this in a chat model"
msgstr ""

#: ../docs/modules/prompts/output_parsers/getting_started.ipynb:10008
msgid "`get_format_instructions() -> str`: A method which returns a string containing instructions for how the output of a language model should be formatted."
msgstr ""

#: ../docs/modules/prompts/output_parsers/getting_started.ipynb:10009
msgid "`parse(str) -> Any`: A method which takes in a string (assumed to be the response from a language model) and parses it into some structure."
msgstr ""

#: ../docs/modules/prompts/output_parsers/getting_started.ipynb:10013
msgid "`parse_with_prompt(str, PromptValue) -> Any`: A method which takes in a string (assumed to be the response from a language model) and a prompt (assumed to the prompt that generated such a response) and parses it into some structure. The prompt is largely provided in the event the OutputParser wants to retry or fix the output in some way, and needs information from the prompt to do so."
msgstr ""

#: ../docs/modules/prompts/output_parsers/getting_started.ipynb:10016
msgid "Below we go over the main type of output parser, the `PydanticOutputParser`. See the `examples` folder for other options."
msgstr ""

#: ../docs/modules/prompts/output_parsers/how_to_guides.rst:4
#: ../docs/modules/prompts/prompt_templates/how_to_guides.rst:4
msgid "If you're new to the library, you may want to start with the `Quickstart <./getting_started.html>`_."
msgstr ""

#: ../docs/modules/prompts/output_parsers/how_to_guides.rst:6
msgid "The user guide here shows different types of output parsers."
msgstr ""

#: ../docs/modules/prompts/prompt_templates.rst:22
#: ../docs/modules/prompts/prompt_templates.rst:2
msgid "Prompt Templates"
msgstr ""

#: ../docs/modules/prompts/prompt_templates.rst:5
msgid "`Conceptual Guide <https://docs.langchain.com/docs/components/prompts/prompt-template>`_"
msgstr ""

#: ../docs/modules/prompts/prompt_templates.rst:8
msgid "Language models take text as input - that text is commonly referred to as a prompt. Typically this is not simply a hardcoded string but rather a combination of a template, some examples, and user input. LangChain provides several classes and functions to make constructing and working with prompts easy."
msgstr ""

#: ../docs/modules/prompts/prompt_templates.rst:14
msgid "`Getting Started <./prompt_templates/getting_started.html>`_: An overview of all the functionality LangChain provides for working with and constructing prompts."
msgstr ""

#: ../docs/modules/prompts/prompt_templates.rst:16
msgid "`How-To Guides <./prompt_templates/how_to_guides.html>`_: A collection of how-to guides. These highlight how to accomplish various objectives with our prompt class."
msgstr ""

#: ../docs/modules/prompts/prompt_templates.rst:18
msgid "`Reference <../../reference/prompts.html>`_: API reference documentation for all prompt classes."
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/connecting_to_a_feature_store.ipynb:10002
msgid "Connecting to a Feature Store"
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/connecting_to_a_feature_store.ipynb:10004
msgid "Feature stores are a concept from traditional machine learning that make sure data fed into models is up-to-date and relevant. For more on this, see [here](https://www.tecton.ai/blog/what-is-a-feature-store/)."
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/connecting_to_a_feature_store.ipynb:10006
msgid "This concept is extremely relevant when considering putting LLM applications in production. In order to personalize LLM applications, you may want to combine LLMs with up-to-date information about particular users. Feature stores can be a great way to keep that data fresh, and LangChain provides an easy way to combine that data with LLMs."
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/connecting_to_a_feature_store.ipynb:10008
msgid "In this notebook we will show how to connect prompt templates to feature stores. The basic idea is to call a feature store from inside a prompt template to retrieve values that are then formatted into the prompt."
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/connecting_to_a_feature_store.ipynb:20002
msgid "Feast"
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/connecting_to_a_feature_store.ipynb:20004
msgid "To start, we will use the popular open source feature store framework [Feast](https://github.com/feast-dev/feast)."
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/connecting_to_a_feature_store.ipynb:20006
msgid "This assumes you have already run the steps in the README around getting started. We will build of off that example in getting started, and create and LLMChain to write a note to a specific driver regarding their up-to-date statistics."
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/connecting_to_a_feature_store.ipynb:30002
msgid "Load Feast Store"
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/connecting_to_a_feature_store.ipynb:30004
msgid "Again, this should be set up according to the instructions in the Feast README"
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/connecting_to_a_feature_store.ipynb:50004
msgid "Here we will set up a custom FeastPromptTemplate. This prompt template will take in a driver id, look up their stats, and format those stats into a prompt."
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/connecting_to_a_feature_store.ipynb:50006
msgid "Note that the input to this prompt template is just `driver_id`, since that is the only user defined piece (all other variables are looked up inside the prompt template)."
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/connecting_to_a_feature_store.ipynb:110002
#: ../docs/modules/prompts/prompt_templates/examples/connecting_to_a_feature_store.ipynb:260002
msgid "Use in a chain"
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/connecting_to_a_feature_store.ipynb:110004
msgid "We can now use this in a chain, successfully creating a chain that achieves personalization backed by a feature store"
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/connecting_to_a_feature_store.ipynb:160002
msgid "Tecton"
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/connecting_to_a_feature_store.ipynb:160004
msgid "Above, we showed how you could use Feast, a popular open source and self-managed feature store, with LangChain. Our examples below will show a similar integration using Tecton. Tecton is a fully managed feature platform built to orchestrate the complete ML feature lifecycle, from transformation to online serving, with enterprise-grade SLAs."
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/connecting_to_a_feature_store.ipynb:170004
msgid "Tecton Deployment (sign up at [https://tecton.ai](https://tecton.ai))"
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/connecting_to_a_feature_store.ipynb:170005
msgid "`TECTON_API_KEY` environment variable set to a valid Service Account key"
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/connecting_to_a_feature_store.ipynb:180002
msgid "Define and Load Features"
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/connecting_to_a_feature_store.ipynb:180004
msgid "We will use the user_transaction_counts Feature View from the [Tecton tutorial](https://docs.tecton.ai/docs/tutorials/tecton-fundamentals) as part of a Feature Service. For simplicity, we are only using a single Feature View; however, more sophisticated applications may require more feature views to retrieve the features needed for its prompt."
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/connecting_to_a_feature_store.ipynb:180013
msgid "The above Feature Service is expected to be [applied to a live workspace](https://docs.tecton.ai/docs/applying-feature-repository-changes-to-a-workspace). For this example, we will be using the \"prod\" workspace."
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/connecting_to_a_feature_store.ipynb:200004
msgid "Here we will set up a custom TectonPromptTemplate. This prompt template will take in a user_id , look up their stats, and format those stats into a prompt."
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/connecting_to_a_feature_store.ipynb:200006
msgid "Note that the input to this prompt template is just `user_id`, since that is the only user defined piece (all other variables are looked up inside the prompt template)."
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/connecting_to_a_feature_store.ipynb:260004
msgid "We can now use this in a chain, successfully creating a chain that achieves personalization backed by the Tecton Feature Platform"
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/custom_prompt_template.ipynb:10002
msgid "How to create a custom prompt template"
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/custom_prompt_template.ipynb:10004
msgid "Let's suppose we want the LLM to generate English language explanations of a function given its name. To achieve this task, we will create a custom prompt template that takes in the function name as input, and formats the prompt template to provide the source code of the function."
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/custom_prompt_template.ipynb:10006
msgid "Why are custom prompt templates needed?"
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/custom_prompt_template.ipynb:10008
msgid "LangChain provides a set of default prompt templates that can be used to generate prompts for a variety of tasks. However, there may be cases where the default prompt templates do not meet your needs. For example, you may want to create a prompt template with specific dynamic instructions for your language model. In such cases, you can create a custom prompt template."
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/custom_prompt_template.ipynb:10010
msgid "Take a look at the current set of default prompt templates [here](../getting_started.md)."
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/custom_prompt_template.ipynb:20002
msgid "Creating a Custom Prompt Template"
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/custom_prompt_template.ipynb:20004
msgid "There are essentially two distinct prompt templates available - string prompt templates and chat prompt templates. String prompt templates provides a simple prompt in string format, while chat prompt templates produces a more structured prompt to be used with a chat API."
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/custom_prompt_template.ipynb:20006
msgid "In this guide, we will create a custom prompt using a string prompt template."
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/custom_prompt_template.ipynb:20008
msgid "To create a custom string prompt template, there are two requirements:"
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/custom_prompt_template.ipynb:20009
msgid "It has an input_variables attribute that exposes what input variables the prompt template expects."
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/custom_prompt_template.ipynb:20010
msgid "It exposes a format method that takes in keyword arguments corresponding to the expected input_variables and returns the formatted prompt."
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/custom_prompt_template.ipynb:20012
msgid "We will create a custom prompt template that takes in the function name as input and formats the prompt to provide the source code of the function. To achieve this, let's first create a function that will return the source code of a function given its name."
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/custom_prompt_template.ipynb:40002
msgid "Next, we'll create a custom prompt template that takes in the function name as input, and formats the prompt template to provide the source code of the function."
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/custom_prompt_template.ipynb:60002
msgid "Use the custom prompt template"
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/custom_prompt_template.ipynb:60004
msgid "Now that we have created a custom prompt template, we can use it to generate prompts for our task."
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/few_shot_examples.ipynb:10002
msgid "How to create a prompt template that uses few shot examples"
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/few_shot_examples.ipynb:10004
msgid "In this tutorial, we'll learn how to create a prompt template that uses few shot examples."
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/few_shot_examples.ipynb:10006
msgid "We'll use the `FewShotPromptTemplate` class to create a prompt template that uses few shot examples. This class either takes in a set of examples, or an `ExampleSelector` object. In this tutorial, we'll go over both options."
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/few_shot_examples.ipynb:10008
msgid "Use Case"
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/few_shot_examples.ipynb:10010
msgid "In this tutorial, we'll configure few shot examples for self-ask with search."
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/few_shot_examples.ipynb:20002
msgid "Using an example set"
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/few_shot_examples.ipynb:30002
msgid "Create the example set"
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/few_shot_examples.ipynb:30004
msgid "To get started, create a list of few shot examples. Each example should be a dictionary with the keys being the input variables and the values being the values for those input variables."
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/few_shot_examples.ipynb:50002
msgid "Create a formatter for the few shot examples"
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/few_shot_examples.ipynb:50004
msgid "Configure a formatter that will format the few shot examples into a string. This formatter should be a `PromptTemplate` object."
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/few_shot_examples.ipynb:70002
msgid "Feed examples and formatter to `FewShotPromptTemplate`"
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/few_shot_examples.ipynb:70004
msgid "Finally, create a `FewShotPromptTemplate` object. This object takes in the few shot examples and the formatter for the few shot examples."
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/few_shot_examples.ipynb:90002
msgid "Using an example selector"
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/few_shot_examples.ipynb:90004
msgid "Feed examples into `ExampleSelector`"
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/few_shot_examples.ipynb:90006
msgid "We will reuse the example set and the formatter from the previous section. However, instead of feeding the examples directly into the `FewShotPromptTemplate` object, we will feed them into an `ExampleSelector` object."
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/few_shot_examples.ipynb:90009
msgid "In this tutorial, we will use the `SemanticSimilarityExampleSelector` class. This class selects few shot examples based on their similarity to the input. It uses an embedding model to compute the similarity between the input and the few shot examples, as well as a vector store to perform the nearest neighbor search."
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/few_shot_examples.ipynb:110002
msgid "Feed example selector into `FewShotPromptTemplate`"
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/few_shot_examples.ipynb:110004
msgid "Finally, create a `FewShotPromptTemplate` object. This object takes in the example selector and the formatter for the few shot examples."
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/partial.ipynb:10002
msgid "How to work with partial Prompt Templates"
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/partial.ipynb:10004
msgid "A prompt template is a class with a `.format` method which takes in a key-value map and returns a string (a prompt) to pass to the language model. Like other methods, it can make sense to \"partial\" a prompt template - eg pass in a subset of the required values, as to create a new prompt template which expects only the remaining subset of values."
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/partial.ipynb:10006
msgid "LangChain supports this in two ways: we allow for partially formatted prompts (1) with string values, (2) with functions that return string values. These two different ways support different use cases. In the documentation below we go over the motivations for both use cases as well as how to do it in LangChain."
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/partial.ipynb:10008
msgid "Partial With Strings"
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/partial.ipynb:10010
msgid "One common use case for wanting to partial a prompt template is if you get some of the variables before others. For example, suppose you have a prompt template that requires two variables, `foo` and `baz`. If you get the `foo` value early on in the chain, but the `baz` value later, it can be annoying to wait until you have both variables in the same place to pass them to the prompt template. Instead, you can partial the prompt template with the `foo` value, and then pass the partialed prompt template along and just use that. Below is an example of doing this:"
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/partial.ipynb:40002
msgid "You can also just initialize the prompt with the partialed variables."
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/partial.ipynb:60002
msgid "Partial With Functions"
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/partial.ipynb:60004
msgid "The other common use is to partial with a function. The use case for this is when you have a variable you know that you always want to fetch in a common way. A prime example of this is with date or time. Imagine you have a prompt which you always want to have the current date. You can't hard code it in the prompt, and passing it along with the other input variables is a bit annoying. In this case, it's very handy to be able to partial the prompt with a function that always returns the current date."
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/partial.ipynb:90002
msgid "You can also just initialize the prompt with the partialed variables, which often makes more sense in this workflow."
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/prompt_serialization.ipynb:10002
msgid "How to serialize prompts"
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/prompt_serialization.ipynb:10004
msgid "It is often preferrable to store prompts not as python code but as files. This can make it easy to share, store, and version prompts. This notebook covers how to do that in LangChain, walking through all the different types of prompts and the different serialization options."
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/prompt_serialization.ipynb:10006
msgid "At a high level, the following design principles are applied to serialization:"
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/prompt_serialization.ipynb:10008
msgid "Both JSON and YAML are supported. We want to support serialization methods that are human readable on disk, and YAML and JSON are two of the most popular methods for that. Note that this rule applies to prompts. For other assets, like Examples, different serialization methods may be supported."
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/prompt_serialization.ipynb:10010
msgid "We support specifying everything in one file, or storing different components (templates, examples, etc) in different files and referencing them. For some cases, storing everything in file makes the most sense, but for others it is preferrable to split up some of the assets (long templates, large examples, reusable components). LangChain supports both."
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/prompt_serialization.ipynb:10012
msgid "There is also a single entry point to load prompts from disk, making it easy to load any type of prompt."
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/prompt_serialization.ipynb:30002
msgid "PromptTemplate"
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/prompt_serialization.ipynb:30004
msgid "This section covers examples for loading a PromptTemplate."
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/prompt_serialization.ipynb:40002
#: ../docs/modules/prompts/prompt_templates/examples/prompt_serialization.ipynb:200002
msgid "Loading from YAML"
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/prompt_serialization.ipynb:40003
msgid "This shows an example of loading a PromptTemplate from YAML."
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/prompt_serialization.ipynb:70002
#: ../docs/modules/prompts/prompt_templates/examples/prompt_serialization.ipynb:260002
msgid "Loading from JSON"
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/prompt_serialization.ipynb:70003
msgid "This shows an example of loading a PromptTemplate from JSON."
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/prompt_serialization.ipynb:100002
msgid "Tell me a funny joke about chickens."
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/prompt_serialization.ipynb:110002
msgid "Loading Template from a File"
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/prompt_serialization.ipynb:110003
msgid "This shows an example of storing the template in a separate file and then referencing it in the config. Notice that the key changes from `template` to `template_path`."
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/prompt_serialization.ipynb:150002
msgid "FewShotPromptTemplate"
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/prompt_serialization.ipynb:150004
msgid "This section covers examples for loading few shot prompt templates."
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/prompt_serialization.ipynb:160003
msgid "This shows an example of what examples stored as json might look like."
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/prompt_serialization.ipynb:180002
msgid "And here is what the same examples stored as yaml might look like."
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/prompt_serialization.ipynb:200003
msgid "This shows an example of loading a few shot example from YAML."
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/prompt_serialization.ipynb:230002
msgid "The same would work if you loaded examples from the yaml file."
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/prompt_serialization.ipynb:260003
msgid "This shows an example of loading a few shot example from JSON."
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/prompt_serialization.ipynb:290002
msgid "Examples in the Config"
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/prompt_serialization.ipynb:290003
msgid "This shows an example of referencing the examples directly in the config."
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/prompt_serialization.ipynb:320002
msgid "Example Prompt from a File"
msgstr ""

#: ../docs/modules/prompts/prompt_templates/examples/prompt_serialization.ipynb:320003
msgid "This shows an example of loading the PromptTemplate that is used to format the examples from a separate file. Note that the key changes from `example_prompt` to `example_prompt_path`."
msgstr ""

#: ../docs/modules/prompts/prompt_templates/getting_started.md:3
msgid "In this tutorial, we will learn about:"
msgstr ""

#: ../docs/modules/prompts/prompt_templates/getting_started.md:4
msgid "what a prompt template is, and why it is needed,"
msgstr ""

#: ../docs/modules/prompts/prompt_templates/getting_started.md:5
msgid "how to create a prompt template,"
msgstr ""

#: ../docs/modules/prompts/prompt_templates/getting_started.md:6
msgid "how to pass few shot examples to a prompt template,"
msgstr ""

#: ../docs/modules/prompts/prompt_templates/getting_started.md:7
msgid "how to select examples for a prompt template."
msgstr ""

#: ../docs/modules/prompts/prompt_templates/getting_started.md:9
msgid "What is a prompt template?"
msgstr ""

#: ../docs/modules/prompts/prompt_templates/getting_started.md:11
msgid "A prompt template refers to a reproducible way to generate a prompt. It contains a text string (\"the template\"), that can take in a set of parameters from the end user and generate a prompt."
msgstr ""

#: ../docs/modules/prompts/prompt_templates/getting_started.md:13
msgid "The prompt template may contain:"
msgstr ""

#: ../docs/modules/prompts/prompt_templates/getting_started.md:14
msgid "instructions to the language model,"
msgstr ""

#: ../docs/modules/prompts/prompt_templates/getting_started.md:15
msgid "a set of few shot examples to help the language model generate a better response,"
msgstr ""

#: ../docs/modules/prompts/prompt_templates/getting_started.md:16
msgid "a question to the language model."
msgstr ""

#: ../docs/modules/prompts/prompt_templates/getting_started.md:18
msgid "The following code snippet contains an example of a prompt template:"
msgstr ""

#: ../docs/modules/prompts/prompt_templates/getting_started.md:39
msgid "Create a prompt template"
msgstr ""

#: ../docs/modules/prompts/prompt_templates/getting_started.md:41
msgid "You can create simple hardcoded prompts using the `PromptTemplate` class. Prompt templates can take any number of input variables, and can be formatted to generate a prompt."
msgstr ""

#: ../docs/modules/prompts/prompt_templates/getting_started.md:66
msgid "If you do not wish to specify `input_variables` manually, you can also create a `PromptTemplate` using `from_template` class method. `langchain` will automatically infer the `input_variables` based on the `template` passed."
msgstr ""

#: ../docs/modules/prompts/prompt_templates/getting_started.md:78
msgid "You can create custom prompt templates that format the prompt in any way you want. For more information, see [Custom Prompt Templates](examples/custom_prompt_template.ipynb)."
msgstr ""

#: ../docs/modules/prompts/prompt_templates/getting_started.md:83
msgid "Template formats"
msgstr ""

#: ../docs/modules/prompts/prompt_templates/getting_started.md:85
msgid "By default, `PromptTemplate` will treat the provided template as a Python f-string. You can specify other template format through `template_format` argument:"
msgstr ""

#: ../docs/modules/prompts/prompt_templates/getting_started.md:97
msgid "Currently, `PromptTemplate` only supports `jinja2` and `f-string` templating format. If there is any other templating format that you would like to use, feel free to open an issue in the [Github](https://github.com/hwchase17/langchain/issues) page."
msgstr ""

#: ../docs/modules/prompts/prompt_templates/getting_started.md:99
msgid "Validate template"
msgstr ""

#: ../docs/modules/prompts/prompt_templates/getting_started.md:101
msgid "By default, `PromptTemplate` will validate the `template` string by checking whether the `input_variables` match the variables defined in `template`. You can disable this behavior by setting `validate_template` to `False`"
msgstr ""

#: ../docs/modules/prompts/prompt_templates/getting_started.md:114
msgid "Serialize prompt template"
msgstr ""

#: ../docs/modules/prompts/prompt_templates/getting_started.md:116
msgid "You can save your `PromptTemplate` into a file in your local filesystem. `langchain` will automatically infer the file format through the file extension name. Currently, `langchain` supports saving template to YAML and JSON file."
msgstr ""

#: ../docs/modules/prompts/prompt_templates/getting_started.md:129
msgid "`langchain` also supports loading prompt template from LangChainHub, which contains a collection of useful prompts you can use in your project. You can read more about LangChainHub and the prompts available with it [here](https://github.com/hwchase17/langchain-hub)."
msgstr ""

#: ../docs/modules/prompts/prompt_templates/getting_started.md:139
msgid "You can learn more about serializing prompt template in [How to serialize prompts](examples/prompt_serialization.ipynb)."
msgstr ""

#: ../docs/modules/prompts/prompt_templates/getting_started.md:142
msgid "Pass few shot examples to a prompt template"
msgstr ""

#: ../docs/modules/prompts/prompt_templates/getting_started.md:144
msgid "Few shot examples are a set of examples that can be used to help the language model generate a better response."
msgstr ""

#: ../docs/modules/prompts/prompt_templates/getting_started.md:146
msgid "To generate a prompt with few shot examples, you can use the `FewShotPromptTemplate`. This class takes in a `PromptTemplate` and a list of few shot examples. It then formats the prompt template with the few shot examples."
msgstr ""

#: ../docs/modules/prompts/prompt_templates/getting_started.md:148
msgid "In this example, we'll create a prompt to generate word antonyms."
msgstr ""

#: ../docs/modules/prompts/prompt_templates/getting_started.md:203
msgid "Select examples for a prompt template"
msgstr ""

#: ../docs/modules/prompts/prompt_templates/getting_started.md:205
msgid "If you have a large number of examples, you can use the `ExampleSelector` to select a subset of examples that will be most informative for the Language Model. This will help you generate a prompt that is more likely to generate a good response."
msgstr ""

#: ../docs/modules/prompts/prompt_templates/getting_started.md:207
msgid "Below, we'll use the `LengthBasedExampleSelector`, which selects examples based on the length of the input. This is useful when you are worried about constructing a prompt that will go over the length of the context window. For longer inputs, it will select fewer examples to include, while for shorter inputs it will select more."
msgstr ""

#: ../docs/modules/prompts/prompt_templates/getting_started.md:209
msgid "We'll continue with the example from the previous section, but this time we'll use the `LengthBasedExampleSelector` to select the examples."
msgstr ""

#: ../docs/modules/prompts/prompt_templates/getting_started.md:269
msgid "In contrast, if we provide a very long input, the `LengthBasedExampleSelector` will select fewer examples to include in the prompt."
msgstr ""

#: ../docs/modules/prompts/prompt_templates/getting_started.md:284
msgid "LangChain comes with a few example selectors that you can use. For more details on how to use them, see [Example Selectors](../example_selectors.rst)."
msgstr ""

#: ../docs/modules/prompts/prompt_templates/getting_started.md:286
msgid "You can create custom example selectors that select examples based on any criteria you want. For more details on how to do this, see [Creating a custom example selector](../example_selectors/examples/custom_example_selector.md)."
msgstr ""

#: ../docs/modules/prompts/prompt_templates/how_to_guides.rst:6
msgid "The user guide here shows more advanced workflows and how to use the library in different ways."
msgstr ""
