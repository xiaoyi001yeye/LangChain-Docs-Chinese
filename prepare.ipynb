{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1XdaY-gnAdoXUPhZdWkT8EZUNimENQZ7I",
      "authorship_tag": "ABX9TyN8Lojzlichb99l935XI2QN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xiaoyi001yeye/LangChain-Docs-Chinese/blob/main/prepare.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ChOL23v8fayo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b041ce3-e817-4984-85ed-16aa6b35d464"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'langchain'...\n",
            "remote: Enumerating objects: 21141, done.\u001b[K\n",
            "remote: Counting objects: 100% (3606/3606), done.\u001b[K\n",
            "remote: Compressing objects: 100% (989/989), done.\u001b[K\n",
            "remote: Total 21141 (delta 2983), reused 2998 (delta 2605), pack-reused 17535\u001b[K\n",
            "Receiving objects: 100% (21141/21141), 28.70 MiB | 21.32 MiB/s, done.\n",
            "Resolving deltas: 100% (15103/15103), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/hwchase17/langchain.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "pip install \"jinja2>=2.11,<3.1\" autodoc_pydantic myst_nb sphinx sphinx_copybutton sphinx_panels openai requests"
      ],
      "metadata": {
        "id": "7zAmXjmhgq5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sphinx-build -b gettext /content/langchain/docs/ /content/langchain/docs_gettext/"
      ],
      "metadata": {
        "id": "6nnfzQWvgl01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "rm -rf /content/LangChain-Docs-Chinese\n",
        "git clone https://github.com/xiaoyi001yeye/LangChain-Docs-Chinese.git /content/LangChain-Docs-Chinese\n",
        "cp -r /content/langchain/docs_gettext/ /content/LangChain-Docs-Chinese/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHJcP-SdnQIw",
        "outputId": "1d4778ee-f04a-4a50-d8e2-bd79539980f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Cloning into '/content/LangChain-Docs-Chinese'...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "# https://mlocati.github.io/articles/gettext-iconv-windows.html\n",
        "msgcat.exe .\\deployments.pot .\\ecosystem.pot .\\gallery.pot .\\getting_started.pot .\\glossary.pot .\\index.pot .\\model_laboratory.pot .\\reference.pot .\\tracing.pot .\\use_cases.pot .\\youtube.pot -o messages.PO"
      ],
      "metadata": {
        "id": "tFyMJFPWwGQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "# cd /content/LangChain-Docs-Chinese\n",
        "\n",
        "f=$(date +%Y%m%d-%H%M%S)\n",
        "git checkout -b feature/$f\n",
        "# git remote add origin https://github.com/xiaoyi001yeye/LangChain-Docs-Chinese.git\n",
        "git add ./docs_gettext\n",
        "git commit -m \"update docs\"\n",
        "# git push https://github.com/xiaoyi001yeye/LangChain-Docs-Chinese.git feature/$f\n",
        "\n",
        "git push -u origin feature/$f"
      ],
      "metadata": {
        "id": "Gmdow3v8rQIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "triplets = []\n",
        "\n",
        "with open('/content/LangChain-Docs-Chinese/docs_gettext/youtube.pot', 'r', encoding='UTF-8') as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "    # Iterate over each line of the file\n",
        "    i = 0\n",
        "    while i < len(lines):\n",
        "        line = lines[i].strip()\n",
        "\n",
        "        # Check if it's the start of a new message definition\n",
        "        if line.startswith('#:'):\n",
        "            comment = line[2:].strip()\n",
        "            msgid = ''\n",
        "            msgstr = ''\n",
        "\n",
        "            # Look for the msgid and msgstr lines\n",
        "            while i < len(lines) - 1:\n",
        "                i += 1\n",
        "                if lines[i].startswith('msgid \"'):\n",
        "                    msgid = lines[i].strip()[7:-1]\n",
        "                elif lines[i].startswith('msgstr \"'):\n",
        "                    msgstr = lines[i].strip()[8:-1]\n",
        "                    break\n",
        "            \n",
        "            # Append the triplet if both msgid and msgstr are nonempty\n",
        "            if msgid:\n",
        "                triplets.append([comment, msgid, msgstr])\n",
        "\n",
        "        i += 1\n",
        "        \n",
        "# print(triplets)\n",
        "\n",
        "import openai\n",
        "import time\n",
        "openai.api_key = \"anything\"\n",
        "openai.api_base =\"https://free.churchless.tech/v1\"\n",
        "\n",
        "import requests\n",
        "\n",
        "\n",
        "# def translate_text(text):\n",
        "\n",
        "#     url = 'https://free.churchless.tech/v1/chat/completions'\n",
        "#     headers = {\n",
        "#         'Content-Type': 'application/json'\n",
        "#     }\n",
        "#     data = {\n",
        "#     # 'model': 'gpt-3.5-turbo',\n",
        "#     'model': 'text-davinci-003',\n",
        "#     'prompt': f'请将以下英文翻译成中文:\\n{text}',\n",
        "#     'temperature': 0.7,\n",
        "#     'max_tokens': 256,\n",
        "#     # 'stop': ['Human:', 'AI:']\n",
        "#     }\n",
        "#     print(data)\n",
        "#     response = requests.post(url, headers=headers, json=data)\n",
        "#     print(response.json())\n",
        "#     translate_text = response.json().get('choices')[0].get('message').get('content').strip()\n",
        "#     return translate_text\n",
        "def translate_text(text):\n",
        "    url = f'http://fanyi.youdao.com/translate?&doctype=json&type=EN2ZH_CN&i={text}'\n",
        "    response = requests.get(url)\n",
        "    print(response.text)\n",
        "    data = json.loads(response.text)\n",
        "    return data['translateResult'][0][0]['tgt']\n",
        "for t in triplets:\n",
        "    t[2]=translate_text(t[1])\n",
        "    print(t[2])\n",
        "    time.sleep(2)\n",
        "    \n",
        "\n",
        "import csv\n",
        "filename = 'output.csv'\n",
        "with open(filename, 'w', newline='', encoding='UTF-8') as f:\n",
        "    writer = csv.writer(f)\n",
        "    \n",
        "    # Write the header row\n",
        "    # writer.writerow(fieldnames)\n",
        "\n",
        "    # Write each triplet as a row in the CSV file\n",
        "    for triplet in triplets:\n",
        "        writer.writerow(triplet)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        },
        "id": "q7MlV6MBOfMG",
        "outputId": "2f259a27-98f6-44b2-a64b-3071abc57c14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                          {\"type\":\"EN2ZH_CN\",\"errorCode\":0,\"elapsedTime\":0,\"translateResult\":[[{\"src\":\"YouTube\",\"tgt\":\"YouTube\"}]]}\n",
            "\n",
            "YouTube\n",
            "                          {\"type\":\"EN2ZH_CN\",\"errorCode\":0,\"elapsedTime\":0,\"translateResult\":[[{\"src\":\"This is a collection of `LangChain` tutorials and videos on `YouTube`.\",\"tgt\":\"这是一个收集的LangChain教程和视频\\u201CYouTube\\u201D。\"}]]}\n",
            "\n",
            "这是一个收集的LangChain教程和视频“YouTube”。\n",
            "                          {\"type\":\"EN2ZH_CN\",\"errorCode\":0,\"elapsedTime\":1,\"translateResult\":[[{\"src\":\"Introduction to LangChain with Harrison Chase, creator of LangChain\",\"tgt\":\"介绍与哈里森LangChain追逐,LangChain的创造者\"}]]}\n",
            "\n",
            "介绍与哈里森LangChain追逐,LangChain的创造者\n",
            "                          {\"type\":\"EN2ZH_CN\",\"errorCode\":0,\"elapsedTime\":0,\"translateResult\":[[{\"src\":\"[Building the Future with LLMs, `LangChain`,\",\"tgt\":\"(与llm建立未来,\\u201CLangChain\\u201D,\"}]]}\n",
            "\n",
            "(与llm建立未来,“LangChain”,\n",
            "                          {\"type\":\"EN2ZH_CN\",\"errorCode\":0,\"elapsedTime\":0,\"translateResult\":[[{\"src\":\"[LangChain and Weaviate with Harrison Chase and Bob van Luijt - Weaviate Podcast\",\"tgt\":\"[LangChain和Weaviate哈里森追逐和Bob van Luijt Weaviate播客\"}]]}\n",
            "\n",
            "[LangChain和Weaviate哈里森追逐和Bob van Luijt Weaviate播客\n",
            "                          {\"type\":\"EN2ZH_CN\",\"errorCode\":0,\"elapsedTime\":0,\"translateResult\":[[{\"src\":\"[LangChain Demo   Q\",\"tgt\":\"[LangChain演示问\"}]]}\n",
            "\n",
            "[LangChain演示问\n",
            "                          {\"type\":\"EN2ZH_CN\",\"errorCode\":0,\"elapsedTime\":0,\"translateResult\":[[{\"src\":\"Tutorials\",\"tgt\":\"教程\"}]]}\n",
            "\n",
            "教程\n",
            "                          {\"type\":\"EN2ZH_CN\",\"errorCode\":0,\"elapsedTime\":0,\"translateResult\":[[{\"src\":\"[LangChain Crash Course - Build apps with language models](https:\\/\\/youtu.be\\/LbT1yp6quS8) by [Patrick Loeber](https:\\/\\/www.youtube.com\\/@patloeber)\",\"tgt\":\"[LangChain速成班,与语言模型构建的应用程序)(https:\\/\\/youtu.be\\/LbT1yp6quS8) (Patrick loeb) (https:\\/\\/www.youtube.com\\/@patloeber)\"}]]}\n",
            "\n",
            "[LangChain速成班,与语言模型构建的应用程序)(https://youtu.be/LbT1yp6quS8) (Patrick loeb) (https://www.youtube.com/@patloeber)\n",
            "                          {\"type\":\"EN2ZH_CN\",\"errorCode\":0,\"elapsedTime\":0,\"translateResult\":[[{\"src\":\"[LangChain for Gen AI and LLMs](https:\\/\\/www.youtube.com\\/playlist?list=PLIUOU7oqGTLieV9uTIFMm6_4PXg-hlN6F) by [James Briggs](https:\\/\\/www.youtube.com\\/@jamesbriggs):\",\"tgt\":\"[LangChain创AI llm) (https:\\/\\/www.youtube.com\\/playlist?list=PLIUOU7oqGTLieV9uTIFMm6_4PXg-hlN6F)(詹姆斯·布里格斯)(https:\\/\\/www.youtube.com\\/@jamesbriggs):\"}]]}\n",
            "\n",
            "[LangChain创AI llm) (https://www.youtube.com/playlist?list=PLIUOU7oqGTLieV9uTIFMm6_4PXg-hlN6F)(詹姆斯·布里格斯)(https://www.youtube.com/@jamesbriggs):\n",
            " {\"type\":null,\"errorCode\":$!webResult.getErrorCode(),\"elapsedTime\":0}\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "JSONDecodeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-43c18d4dc018>\u001b[0m in \u001b[0;36m<cell line: 67>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'translateResult'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tgt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtriplets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranslate_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-39-43c18d4dc018>\u001b[0m in \u001b[0;36mtranslate_text\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'translateResult'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tgt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtriplets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 27 (char 26)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "deepl_api_url = \"https://deepl-translator.p.rapidapi.com/translate\"\n",
        "deepl_headers = {\n",
        "    \"content-type\": \"application/json\",\n",
        "    \"X-RapidAPI-Key\": \"\",\n",
        "    \"X-RapidAPI-Host\": \"deepl-translator.p.rapidapi.com\",\n",
        "}\n",
        "payload = {\"text\": 'text', \"source\": \"EN\", \"target\": \"ZH\"}\n",
        "response = requests.request(\"POST\", deepl_api_url, headers=deepl_headers, json=json.dumps(payload))\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-prObBjUR4l",
        "outputId": "9a310eba-f65b-496f-abe7-d22bb11b56a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Response [401]>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "\n",
        "def translate_text(text):\n",
        "    \n",
        "\n",
        "    # 设置请求的URL\n",
        "    url = f'http://fanyi.youdao.com/translate?&doctype=json&type=EN2ZH_CN&i={text}'\n",
        "#  {\"type\":\"EN2ZH_CN\",\"errorCode\":0,\"elapsedTime\":1,\"translateResult\":[[{\"src\":\"calculate\",\"tgt\":\"计算\"}]]}\n",
        "    \n",
        "\n",
        "    # 发送POST请求并获取响应\n",
        "    response = requests.get(url)\n",
        "    #print(response)\n",
        "    # 解析JSON格式的响应数据\n",
        "    data = json.loads(response.text)\n",
        "    print(data)\n",
        "    # 返回翻译结果\n",
        "    return data['translateResult'][0][0]['tgt']\n",
        "\n",
        "\n",
        "print(translate_text(\"I love U\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcIYg1XCWplZ",
        "outputId": "ef0bcb38-1fa7-4ec5-c1f1-9dd92a01dea4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'type': 'EN2ZH_CN', 'errorCode': 0, 'elapsedTime': 1, 'translateResult': [[{'src': 'I love U', 'tgt': '我爱你'}]]}\n",
            "我爱你\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "curl --location 'https://free.churchless.tech/v1/chat/completions' \\\n",
        "--header 'Content-Type: application/json' \\\n",
        "--data '{\n",
        "    \"model\": \"gpt-3.5-turbo\",\n",
        "    \"prompt\": \"请将以下英文翻译成中文\\\\nHello,What is your name\",\n",
        "    \"temperature\": 1.0,\n",
        "    \"max_tokens\": 256\n",
        "    \n",
        "}'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cr0Pb6z8PIRd",
        "outputId": "797669ed-fc56-4605-fec4-4b3e1870a31f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"id\":\"chatcmpl-QXlha2FBbmROaXhpZUFyZUF3ZXNvbWUK\",\"object\":\"chat.completion\",\"created\":0,\"model\":\"gpt-3.5-turbo-0301\",\"usage\":{\"prompt_tokens\":0,\"completion_tokens\":0,\"total_tokens\":0},\"choices\":[{\"index\":0,\"message\":{\"role\":\"assistant\",\"content\":\"\\n\\nHello! How can I assist you today?\"},\"finish_reason\":\"stop\"}]}"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100   161    0     0  100   161      0    130  0:00:01  0:00:01 --:--:--   130\r100   161    0     0  100   161      0     72  0:00:02  0:00:02 --:--:--    72\r100   161    0     0  100   161      0     49  0:00:03  0:00:03 --:--:--    49\r100   161    0     0  100   161      0     37  0:00:04  0:00:04 --:--:--    37\r100   475    0   314  100   161     63     32  0:00:05  0:00:04  0:00:01    96\r100   475    0   314  100   161     63     32  0:00:05  0:00:04  0:00:01    84\n"
          ]
        }
      ]
    }
  ]
}